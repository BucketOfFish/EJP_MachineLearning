{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to open some data, and fit it to the model y = p[0]\\*x1 + p[1]\\*exp(x2/p[2]). Here the p values are parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(open(\"Files/data.csv\"), delimiter=' ', header=None).values\n",
    "x1_data = data[0]\n",
    "x2_data = data[1]\n",
    "y_data = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = [np.random.normal(), np.random.normal(), np.random.normal()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set learning rate and number of epochs. This is how we would train using stochastic gradient descent, with one data sample at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch_n in range(n_epochs):\n",
    "    for iteration_n, (x1, x2, y) in enumerate(zip(x1_data, x2_data, y_data)):\n",
    "        # calculate output using model\n",
    "        y_predicted = p[0] * x1 + p[1] * (x2 + p[2])\n",
    "        # calculate loss\n",
    "        loss = (y_predicted - y)**2\n",
    "        # find gradients\n",
    "        p_gradient[0] = 2*(y_predicted - y) * x1\n",
    "        p_gradient[1] = 2*(y_predicted - y) * (x2 + p[2])\n",
    "        p_gradient[2] = 2*(y_predicted - y) * p[1]\n",
    "        # update parameters\n",
    "        p[0] -= learning_rate * p_gradient[0]\n",
    "        p[1] -= learning_rate * p_gradient[1]\n",
    "        p[2] -= learning_rate * p_gradient[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the batch size, reset the parameters, and train using minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "p = [np.random.normal(), np.random.normal(), np.random.normal()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Iteration 100 - loss is 364224.209643 - parameters are 6.67018104965 6.7836947113 0.0607817021789\n",
      "Iteration 200 - loss is 34714.7865834 - parameters are 4.70531879887 5.76452645684 -0.110133853597\n",
      "Iteration 300 - loss is 9485.75743724 - parameters are 4.24900553602 6.0661056621 -0.112731877682\n",
      "Iteration 400 - loss is 7845.13161321 - parameters are 4.020367644 6.55425174605 -0.0974336963759\n",
      "Iteration 500 - loss is 6059.06838296 - parameters are 3.8167990201 7.02112508457 -0.0774228789883\n",
      "Iteration 600 - loss is 3776.30180294 - parameters are 3.37782089262 7.08000145658 -0.094672154214\n",
      "Iteration 700 - loss is 2669.20839428 - parameters are 3.37365342601 7.46276424346 -0.064500117562\n",
      "Iteration 800 - loss is 1729.92500023 - parameters are 3.1578363251 7.54843710901 -0.0646481518585\n",
      "Iteration 900 - loss is 1374.79146222 - parameters are 2.9919333428 7.6668263452 -0.0591136801569\n",
      "Iteration 1000 - loss is 900.954103218 - parameters are 2.90862030891 7.77922067751 -0.0483208642514\n",
      "Epoch 2\n",
      "Iteration 100 - loss is 758.57650708 - parameters are 2.79105226368 7.83998020202 -0.0428016960775\n",
      "Iteration 200 - loss is 633.627636494 - parameters are 2.75829216725 7.95801079655 -0.027129922645\n",
      "Iteration 300 - loss is 468.592682215 - parameters are 2.62990662342 7.95977219996 -0.0282337683318\n",
      "Iteration 400 - loss is 377.195677142 - parameters are 2.61815086033 8.05349778626 -0.0158265772509\n",
      "Iteration 500 - loss is 336.058622539 - parameters are 2.57319763228 8.11593766412 -0.007648816171\n",
      "Iteration 600 - loss is 304.364474197 - parameters are 2.52780469829 8.14196910996 -9.4072460353e-05\n",
      "Iteration 700 - loss is 263.503364988 - parameters are 2.52831781827 8.20529906639 0.0122724103746\n",
      "Iteration 800 - loss is 276.823120994 - parameters are 2.49438981419 8.22593553327 0.0205224627466\n",
      "Iteration 900 - loss is 253.605419259 - parameters are 2.4489848996 8.23016050644 0.0264222919217\n",
      "Iteration 1000 - loss is 254.518084257 - parameters are 2.45762384035 8.27175548536 0.0390297225796\n",
      "Epoch 3\n",
      "Iteration 100 - loss is 276.790700273 - parameters are 2.38862361893 8.23434377661 0.0415044039993\n",
      "Iteration 200 - loss is 288.380449896 - parameters are 2.41616098673 8.27930517723 0.0574741867529\n",
      "Iteration 300 - loss is 199.926431888 - parameters are 2.37377568822 8.26235728481 0.0609630092564\n",
      "Iteration 400 - loss is 193.043758546 - parameters are 2.38759172337 8.2853755198 0.0712550005124\n",
      "Iteration 500 - loss is 185.124172066 - parameters are 2.36998314381 8.28559788617 0.0771629862918\n",
      "Iteration 600 - loss is 227.490818884 - parameters are 2.38659624745 8.30601136756 0.0891072346554\n",
      "Iteration 700 - loss is 193.171964009 - parameters are 2.38769081643 8.31824814489 0.0979342460996\n",
      "Iteration 800 - loss is 224.415764147 - parameters are 2.38287931174 8.32866097789 0.107522771846\n",
      "Iteration 900 - loss is 213.641635404 - parameters are 2.35694709154 8.31486140256 0.113362309416\n",
      "Iteration 1000 - loss is 227.729826791 - parameters are 2.37993791871 8.3448978689 0.126077148921\n",
      "Epoch 4\n",
      "Iteration 100 - loss is 257.415374361 - parameters are 2.31940153607 8.29250242487 0.127969546274\n",
      "Iteration 200 - loss is 274.205359572 - parameters are 2.35604954702 8.32549610683 0.143736367336\n",
      "Iteration 300 - loss is 183.817725735 - parameters are 2.32768374626 8.30582824906 0.147903526392\n",
      "Iteration 400 - loss is 184.021499936 - parameters are 2.34537385204 8.3175661472 0.157688399014\n",
      "Iteration 500 - loss is 175.252571287 - parameters are 2.33216992253 8.30784454218 0.163108176463\n",
      "Iteration 600 - loss is 220.670769277 - parameters are 2.35844693859 8.32729988223 0.175586365815\n",
      "Iteration 700 - loss is 184.435193681 - parameters are 2.3595369122 8.3312654951 0.183685480503\n",
      "Iteration 800 - loss is 214.220245628 - parameters are 2.35939409439 8.34004014971 0.193336985248\n",
      "Iteration 900 - loss is 204.715463059 - parameters are 2.33687759123 8.32354486951 0.199058717896\n",
      "Iteration 1000 - loss is 219.20664253 - parameters are 2.36186052569 8.35144290031 0.211599980932\n",
      "Epoch 5\n",
      "Iteration 100 - loss is 248.591314139 - parameters are 2.30337959712 8.29728778281 0.213340014669\n",
      "Iteration 200 - loss is 265.285772317 - parameters are 2.34098782468 8.32802955666 0.228832661949\n",
      "Iteration 300 - loss is 176.681459254 - parameters are 2.31516982159 8.3081688029 0.233024224542\n",
      "Iteration 400 - loss is 177.777180016 - parameters are 2.33329331775 8.31809689654 0.242580320264\n",
      "Iteration 500 - loss is 169.238035761 - parameters are 2.3208271545 8.30674168199 0.247809190275\n",
      "Iteration 600 - loss is 213.409834734 - parameters are 2.34843383506 8.32596838433 0.260195391397\n",
      "Iteration 700 - loss is 177.841312611 - parameters are 2.34943506561 8.32849494588 0.268032679359\n",
      "Iteration 800 - loss is 206.402307681 - parameters are 2.35005773515 8.33698478218 0.277543292443\n",
      "Iteration 900 - loss is 197.379218071 - parameters are 2.32839532284 8.32023179942 0.283141339664\n",
      "Iteration 1000 - loss is 211.785706279 - parameters are 2.35340678517 8.34749338495 0.295468566358\n",
      "Epoch 6\n",
      "Iteration 100 - loss is 240.133107851 - parameters are 2.29594578228 8.2936719472 0.297127259134\n",
      "Iteration 200 - loss is 256.304548434 - parameters are 2.33322405099 8.32371030235 0.312339978455\n",
      "Iteration 300 - loss is 170.383758244 - parameters are 2.30812110445 8.30405350559 0.316453297978\n",
      "Iteration 400 - loss is 171.555859955 - parameters are 2.32613379452 8.31367974463 0.325828935047\n",
      "Iteration 500 - loss is 163.548147271 - parameters are 2.31381976623 8.30201513404 0.330917202142\n",
      "Iteration 600 - loss is 206.034826734 - parameters are 2.34143152438 8.32112698617 0.343115348234\n",
      "Iteration 700 - loss is 171.599367524 - parameters are 2.34233446043 8.32330757141 0.350769148746\n",
      "Iteration 800 - loss is 199.091750552 - parameters are 2.34309914034 8.3317261333 0.360109728049\n",
      "Iteration 900 - loss is 190.437788895 - parameters are 2.32187663359 8.31510082682 0.36558577557\n",
      "Iteration 1000 - loss is 204.721810583 - parameters are 2.34660910117 8.34196904734 0.377696747829\n",
      "Epoch 7\n",
      "Iteration 100 - loss is 231.964778503 - parameters are 2.28998997011 8.28880446277 0.379287086214\n",
      "Iteration 200 - loss is 247.574723915 - parameters are 2.32674079984 8.31838904738 0.394224076314\n",
      "Iteration 300 - loss is 164.400568923 - parameters are 2.30205591815 8.29899623322 0.398244969098\n",
      "Iteration 400 - loss is 165.528589198 - parameters are 2.31987378853 8.30856007609 0.40745106281\n",
      "Iteration 500 - loss is 158.079357662 - parameters are 2.30761836555 8.29679951679 0.412409461992\n",
      "Iteration 600 - loss is 198.875927505 - parameters are 2.3350269861 8.31581387911 0.424408029023\n",
      "Iteration 700 - loss is 165.611631585 - parameters are 2.33583334969 8.31782667866 0.431894371474\n",
      "Iteration 800 - loss is 192.095166933 - parameters are 2.3366398418 8.32620760226 0.441063646976\n",
      "Iteration 900 - loss is 183.781736111 - parameters are 2.31578501273 8.30976864169 0.446420435156\n",
      "Iteration 1000 - loss is 197.937998378 - parameters are 2.34019465642 8.33628636525 0.458318865788\n",
      "Epoch 8\n",
      "Iteration 100 - loss is 224.101264452 - parameters are 2.28437642834 8.28382042146 0.459844525484\n",
      "Iteration 200 - loss is 239.162566086 - parameters are 2.32057624295 8.31299432879 0.474511386818\n",
      "Iteration 300 - loss is 158.660170742 - parameters are 2.29625720312 8.2938722794 0.478439695569\n",
      "Iteration 400 - loss is 159.728526489 - parameters are 2.31386934495 8.30341115312 0.487481066094\n",
      "Iteration 500 - loss is 152.819774619 - parameters are 2.30165756033 8.2915913634 0.492313961226\n",
      "Iteration 600 - loss is 191.982219227 - parameters are 2.32883260162 8.31051055428 0.504114774219\n",
      "Iteration 700 - loss is 159.859121557 - parameters are 2.32954572151 8.31238780778 0.511439630666\n",
      "Iteration 800 - loss is 185.37483705 - parameters are 2.3303773256 8.32073633688 0.5204406837\n",
      "Iteration 900 - loss is 177.386703115 - parameters are 2.30987253687 8.30449042705 0.525681036091\n",
      "Iteration 1000 - loss is 191.414030101 - parameters are 2.33395742598 8.33066864037 0.537371462361\n",
      "Epoch 9\n",
      "Iteration 100 - loss is 216.534958052 - parameters are 2.27892127083 8.27889852206 0.538834581235\n",
      "Iteration 200 - loss is 231.067598278 - parameters are 2.31457405412 8.30767201509 0.553237000358\n",
      "Iteration 300 - loss is 153.143598113 - parameters are 2.29060772119 8.28881910943 0.557074733576\n",
      "Iteration 400 - loss is 154.152886577 - parameters are 2.30801481339 8.29833829395 0.565955139501\n",
      "Iteration 500 - loss is 147.760569213 - parameters are 2.29584422883 8.28646777121 0.570665801905\n",
      "Iteration 600 - loss is 185.351902141 - parameters are 2.32278353972 8.30529182064 0.582272710813\n",
      "Iteration 700 - loss is 154.330727672 - parameters are 2.32340687317 8.30704237194 0.589440344291\n",
      "Iteration 800 - loss is 178.915301616 - parameters are 2.32426023082 8.31535928165 0.598276856438\n",
      "Iteration 900 - loss is 171.239817474 - parameters are 2.3040966904 8.29930489644 0.603403537216\n",
      "Iteration 1000 - loss is 185.137737719 - parameters are 2.32786146475 8.32514946988 0.614890518239\n",
      "Epoch 10\n",
      "Iteration 100 - loss is 209.254353052 - parameters are 2.27359234508 8.27406541649 0.616292935343\n",
      "Iteration 200 - loss is 223.278689458 - parameters are 2.30870633422 8.30244355627 0.630436486152\n",
      "Iteration 300 - loss is 147.840100514 - parameters are 2.28508589002 8.2838568611 0.634185933057\n",
      "Iteration 400 - loss is 148.793322442 - parameters are 2.30229042236 8.29335655011 0.642908881563\n",
      "Iteration 500 - loss is 142.893383237 - parameters are 2.29016058538 8.28143918823 0.647500330959\n",
      "Iteration 600 - loss is 178.975442895 - parameters are 2.3168664979 8.30016783353 0.658917413516\n",
      "Iteration 700 - loss is 149.016818077 - parameters are 2.3174034087 8.3017966676 0.665931713911\n",
      "Iteration 800 - loss is 172.704990827 - parameters are 2.31827731167 8.3100820417 0.674607371953\n",
      "Iteration 900 - loss is 165.330354612 - parameters are 2.29844778649 8.29421638533 0.679623067296\n",
      "Iteration 1000 - loss is 179.098601558 - parameters are 2.32189803147 8.31973232834 0.690911061034\n",
      "Epoch 11\n",
      "Iteration 100 - loss is 202.247796109 - parameters are 2.26838176867 8.26932362143 0.692254515892\n",
      "Iteration 200 - loss is 215.783527664 - parameters are 2.30296574474 8.29731065833 0.706144633137\n",
      "Iteration 300 - loss is 142.740569983 - parameters are 2.27968546448 8.27898704992 0.709808066109\n",
      "Iteration 400 - loss is 143.640981568 - parameters are 2.29669018396 8.28846666054 0.71837694567\n",
      "Iteration 500 - loss is 138.210239015 - parameters are 2.28460094543 8.27650551 0.722852086558\n",
      "Iteration 600 - loss is 172.842514131 - parameters are 2.31107648261 8.29513850515 0.734083365729\n",
      "Iteration 700 - loss is 143.908353928 - parameters are 2.31153021166 8.29664986649 0.740948066624\n",
      "Iteration 800 - loss is 166.733371442 - parameters are 2.31242381613 8.30490369336 0.749466470879\n",
      "Iteration 900 - loss is 159.648326282 - parameters are 2.29292146742 8.28922380799 0.754373788737\n",
      "Iteration 1000 - loss is 173.286757105 - parameters are 2.31606282039 8.31441594561 0.765467136157\n",
      "Epoch 12\n",
      "Iteration 100 - loss is 195.504061471 - parameters are 2.2632856202 8.26467185911 0.766753302594\n",
      "Iteration 200 - loss is 208.570097428 - parameters are 2.29734831999 8.29227192803 0.780395281807\n",
      "Iteration 300 - loss is 137.836498316 - parameters are 2.27440273769 8.27420827001 0.783974911317\n",
      "Iteration 400 - loss is 138.687279565 - parameters are 2.29121040209 8.28366712821 0.792393015685\n",
      "Iteration 500 - loss is 133.703524229 - parameters are 2.2791616483 8.27166499876 0.796754661774\n",
      "Iteration 600 - loss is 166.943068517 - parameters are 2.30540991963 8.29020215941 0.807804063853\n",
      "Iteration 700 - loss is 138.996737747 - parameters are 2.30578358492 8.29160005373 0.814522780702\n",
      "Iteration 800 - loss is 160.990476388 - parameters are 2.30669612602 8.2998223199 0.822887433521\n",
      "Iteration 900 - loss is 154.184242981 - parameters are 2.28751431929 8.28432526142 0.82768890601\n",
      "Iteration 1000 - loss is 167.692820279 - parameters are 2.31035232962 8.30919834158 0.838591832011\n",
      "Epoch 13\n",
      "Iteration 100 - loss is 189.012416802 - parameters are 2.25830070005 8.26010829086 0.839822325569\n",
      "Iteration 200 - loss is 201.626887352 - parameters are 2.29185072498 8.28732551882 0.853221326905\n",
      "Iteration 300 - loss is 133.11979545 - parameters are 2.26923449827 8.26951869063 0.856719296519\n",
      "Iteration 400 - loss is 133.924002492 - parameters are 2.28584783737 8.27895613948 0.86498983117\n",
      "Iteration 500 - loss is 129.365975206 - parameters are 2.27383944794 8.26691570049 0.869240711915\n",
      "Iteration 600 - loss is 161.267487075 - parameters are 2.29986355259 8.28535690778 0.880112062763\n",
      "Iteration 700 - loss is 134.273772171 - parameters are 2.30016015337 8.28664518636 0.8866883024\n",
      "Iteration 800 - loss is 155.466809802 - parameters are 2.30109089912 8.29483589067 0.894902609314\n",
      "Iteration 900 - loss is 148.929057447 - parameters are 2.28222316937 8.27951875619 0.899600695391\n",
      "Iteration 1000 - loss is 162.30784075 - parameters are 2.3047632785 8.30407746673 0.910317312249\n",
      "Epoch 14\n",
      "Iteration 100 - loss is 182.762611635 - parameters are 2.25342401064 8.25563103023 0.911493693298\n",
      "Iteration 200 - loss is 194.942899491 - parameters are 2.28646981473 8.28246955064 0.924654745823\n",
      "Iteration 300 - loss is 128.582744315 - parameters are 2.26417770114 8.26491645234 0.928073133492\n",
      "Iteration 400 - loss is 129.343305995 - parameters are 2.28059941098 8.27433186825 0.936199219149\n",
      "Iteration 500 - loss is 125.190659547 - parameters are 2.26863125281 8.26225566901 0.940341983335\n",
      "Iteration 600 - loss is 155.806582972 - parameters are 2.29443426371 8.28060086705 0.95103901056\n",
      "Iteration 700 - loss is 129.731636531 - parameters are 2.29465668521 8.28178324445 0.957476175994\n",
      "Iteration 800 - loss is 150.153312458 - parameters are 2.29560492859 8.28994239981 0.965543448747\n",
      "Iteration 900 - loss is 143.87413722 - parameters are 2.2770449705 8.27480233147 0.970140536827\n",
      "Iteration 1000 - loss is 157.123276309 - parameters are 2.29929251094 8.29905130271 0.980674847891\n",
      "Epoch 15\n",
      "Iteration 100 - loss is 176.744855181 - parameters are 2.24865266997 8.25123822335 0.981798623971\n",
      "Iteration 200 - loss is 188.507628943 - parameters are 2.28120256039 8.27770217556 0.994726629873\n",
      "Iteration 300 - loss is 124.217978142 - parameters are 2.25922941157 8.26039972896 0.998067450133\n",
      "Iteration 400 - loss is 124.937699429 - parameters are 2.27546215388 8.2697925233 1.00605212571\n",
      "Iteration 500 - loss is 121.170959332 - parameters are 2.26353408079 8.25768300038 1.01008934446\n",
      "Iteration 600 - loss is 150.551583674 - parameters are 2.28911904171 8.27593219291 1.02061568043\n",
      "Iteration 700 - loss is 125.362867144 - parameters are 2.28927005974 8.27701225394 1.02691707474\n",
      "Iteration 800 - loss is 145.041337853 - parameters are 2.29023511686 8.285139887 1.0348405345\n",
      "Iteration 900 - loss is 139.011242752 - parameters are 2.27197677905 8.27017407205 1.03933894497\n",
      "Iteration 1000 - loss is 152.130971566 - parameters are 2.29393697647 8.29411787723 1.04969484827\n",
      "Epoch 16\n",
      "Iteration 100 - loss is 170.949793635 - parameters are 2.24398389444 8.24692806057 1.05076747623\n",
      "Iteration 200 - loss is 182.311040001 - parameters are 2.27604603403 8.27302158731 1.06346721486\n",
      "Iteration 300 - loss is 120.018462188 - parameters are 2.25438679279 8.2559667364 1.0667324211\n",
      "Iteration 400 - loss is 120.700028535 - parameters are 2.27043319533 8.26533635483 1.07457864648\n",
      "Iteration 500 - loss is 117.300555197 - parameters are 2.25854504862 8.25319583721 1.07851281603\n",
      "Iteration 600 - loss is 145.494110734 - parameters are 2.28391497332 8.27134908423 1.08887200092\n",
      "Iteration 700 - loss is 121.160339095 - parameters are 2.28399725865 8.27233028898 1.09504083087\n",
      "Iteration 800 - loss is 140.122631012 - parameters are 2.28497846793 8.28042643961 1.10282361137\n",
      "Iteration 900 - loss is 134.332507379 - parameters are 2.26701574809 8.26563210991 1.10722559898\n",
      "Iteration 1000 - loss is 147.323138313 - parameters are 2.28869372373 8.28927526526 1.11740689071\n",
      "Epoch 17\n",
      "Iteration 100 - loss is 165.368488497 - parameters are 2.23941499289 8.2426987772 1.11842977871\n",
      "Iteration 200 - loss is 176.34354292 - parameters are 2.27099740286 8.26842602178 1.1309059105\n",
      "Iteration 300 - loss is 115.97747699 - parameters are 2.24964710084 8.25161573311 1.13409739714\n",
      "Iteration 400 - loss is 116.623458727 - parameters are 2.26550975781 8.26096165453 1.14180805577\n",
      "Iteration 500 - loss is 113.573411295 - parameters are 2.25366136689 8.24879236818 1.14564160019\n",
      "Iteration 600 - loss is 140.626160196 - parameters are 2.27881923869 8.2668497828 1.15583708491\n",
      "Iteration 700 - loss is 117.117249103 - parameters are 2.27883536127 8.26773547123 1.16187646439\n",
      "Iteration 800 - loss is 135.389308722 - parameters are 2.27983208278 8.27580019192 1.16952161491\n",
      "Iteration 900 - loss is 129.830418522 - parameters are 2.26215912303 8.26117462328 1.17382937111\n",
      "Iteration 1000 - loss is 142.692337067 - parameters are 2.28355989614 8.28452158811 1.18383974893\n",
      "Epoch 18\n",
      "Iteration 100 - loss is 159.992396053 - parameters are 2.23494336249 8.23854865252 1.18481425838\n",
      "Iteration 200 - loss is 170.595971866 - parameters are 2.26605392514 8.26391375614 1.19707132857\n",
      "Iteration 300 - loss is 112.088602637 - parameters are 2.24500768064 8.24734501914 1.20019093318\n",
      "Iteration 400 - loss is 112.701459253 - parameters are 2.2606891531 8.25666675464 1.20776883462\n",
      "Iteration 500 - loss is 109.9837611 - parameters are 2.24888033616 8.24447082684 1.21150410834\n",
      "Iteration 600 - loss is 135.940084 - parameters are 2.27382910762 8.26243257219 1.22153925737\n",
      "Iteration 700 - loss is 113.22709937 - parameters are 2.27378154057 8.26322596854 1.22745221072\n",
      "Iteration 800 - loss is 130.833840902 - parameters are 2.2747931554 8.27125932383 1.23496269896\n",
      "Iteration 900 - loss is 125.497799962 - parameters are 2.25740423791 8.2567998354 1.23917835406\n",
      "Iteration 1000 - loss is 138.231459654 - parameters are 2.27853272816 8.27985501225 1.24902142034\n",
      "Epoch 19\n",
      "Iteration 100 - loss is 154.813347978 - parameters are 2.23056648514 8.23447600858 1.24994886774\n",
      "Iteration 200 - loss is 165.059564064 - parameters are 2.26121294657 8.25948310783 1.26199130994\n",
      "Iteration 300 - loss is 108.345703926 - parameters are 2.24046596247 8.24315293509 1.26504081526\n",
      "Iteration 400 - loss is 108.927788226 - parameters are 2.25596877875 8.25245002688 1.2724886976\n",
      "Iteration 500 - loss is 106.526094006 - parameters are 2.24419934336 8.24022949036 1.27612798785\n",
      "Iteration 600 - loss is 131.428572406 - parameters are 2.26894193596 8.25809577673 1.28600608197\n",
      "Iteration 700 - loss is 109.483682336 - parameters are 2.26883305947 8.25879999369 1.29179554709\n",
      "Iteration 800 - loss is 126.449033026 - parameters are 2.26985896911 8.26680205961 1.29917426194\n",
      "Iteration 900 - loss is 121.327795105 - parameters are 2.25274851184 8.25250601325 1.30329988724\n",
      "Iteration 1000 - loss is 133.933712773 - parameters are 2.27360954163 8.27527374801 1.31297915213\n",
      "Epoch 20\n",
      "Iteration 100 - loss is 149.82353301 - parameters are 2.2262819241 8.23047920896 1.31386081079\n",
      "Iteration 200 - loss is 159.725940094 - parameters are 2.25647189677 8.25513243344 1.32569295048\n",
      "Iteration 300 - loss is 104.742916343 - parameters are 2.23601945852 8.23903786102 1.32867408634\n",
      "Iteration 400 - loss is 105.296478468 - parameters are 2.25134611466 8.24830988139 1.3359946185\n",
      "Iteration 500 - loss is 103.195142678 - parameters are 2.2396158584 8.23606667827 1.33954014768\n",
      "Iteration 600 - loss is 127.084637388 - parameters are 2.26415516234 8.25383776036 1.34926438658\n",
      "Iteration 700 - loss is 105.881066277 - parameters are 2.2639872673 8.2544558031 1.35493321799\n",
      "Iteration 800 - loss is 122.228009518 - parameters are 2.26502689309 8.26242666665 1.36218297216\n",
      "Iteration 900 - loss is 117.313851173 - parameters are 2.24818944568 8.24829146627 1.36622058199\n",
      "Iteration 1000 - loss is 129.792602466 - parameters are 2.26878774241 8.27077604844 1.37573946632\n",
      "Epoch 21\n",
      "Iteration 100 - loss is 145.015479612 - parameters are 2.22208732077 8.22655665762 1.37657656807\n",
      "Iteration 200 - loss is 154.587085257 - parameters are 2.25182828608 8.2508601277 1.3882026259\n",
      "Iteration 300 - loss is 101.274632815 - parameters are 2.23166575977 8.23499821539 1.39111707108\n",
      "Iteration 400 - loss is 101.801824138 - parameters are 2.24681871991 8.24424476572 1.39831285506\n",
      "Iteration 500 - loss is 99.9858710926 - parameters are 2.23512743091 8.23198075127 1.40176678297\n",
      "Iteration 600 - loss is 122.901596931 - parameters are 2.2594663049 8.24965692553 1.41134028774\n",
      "Iteration 700 - loss is 102.413581706 - parameters are 2.25924159646 8.25019169562 1.41689125946\n",
      "Iteration 800 - loss is 118.164198069 - parameters are 2.26029437896 8.25813145423 1.42401479202\n",
      "Iteration 900 - loss is 113.449704276 - parameters are 2.24372461885 8.24415454519 1.42796634566\n",
      "Iteration 1000 - loss is 125.801919448 - parameters are 2.26406481711 8.26636020807 1.43732818383\n",
      "Epoch 22\n",
      "Iteration 100 - loss is 140.382039587 - parameters are 2.21798039158 8.22270679771 1.43812192059\n",
      "Iteration 200 - loss is 149.635331954 - parameters are 2.24727970235 8.24666462247 1.44954601557\n",
      "Iteration 300 - loss is 97.9354911839 - parameters are 2.22740253292 8.23103245403 1.4523953996\n",
      "Iteration 400 - loss is 98.4383680719 - parameters are 2.24238422967 8.24025316378 1.45946897259\n",
      "Iteration 500 - loss is 96.8934632433 - parameters are 2.23073168718 8.22797011003 1.46283339859\n",
      "Iteration 600 - loss is 118.873060188 - parameters are 2.25487295831 8.24555171221 1.47225921417\n",
      "Iteration 700 - loss is 99.0758085235 - parameters are 2.25459355923 8.2460060113 1.4776950225\n",
      "Iteration 800 - loss is 114.251314804 - parameters are 2.25565895768 8.25391477236 1.4846950013\n",
      "Iteration 900 - loss is 109.729365295 - parameters are 2.23935168629 8.24009364081 1.48856240483\n",
      "Iteration 1000 - loss is 121.955725232 - parameters are 2.25943833 8.26202456182 1.49777044751\n",
      "Epoch 23\n",
      "Iteration 100 - loss is 135.916372554 - parameters are 2.21395892512 8.2189281105 1.49852197284\n",
      "Iteration 200 - loss is 144.863343015 - parameters are 2.24282380801 8.24254438575 1.50974812542\n",
      "Iteration 300 - loss is 94.720362359 - parameters are 2.22322751741 8.22713906913 1.51253403026\n",
      "Iteration 400 - loss is 95.2008898153 - parameters are 2.23804035227 8.23633359487 1.5194878667\n",
      "Iteration 500 - loss is 93.9133124553 - parameters are 2.22642632718 8.22403319405 1.52276483179\n",
      "Iteration 600 - loss is 114.99291343 - parameters are 2.2503727908 8.24152059681 1.53204592926\n",
      "Iteration 700 - loss is 95.8625638608 - parameters are 2.25004074469 8.24189713028 1.53736919544\n",
      "Iteration 800 - loss is 110.483350267 - parameters are 2.25111823645 8.24977501061 1.54424821946\n",
      "Iteration 900 - loss is 106.147106528 - parameters are 2.23506837557 8.23610718291 1.54803332757\n",
      "Iteration 1000 - loss is 118.248339014 - parameters are 2.25490592003 8.25776748388 1.55709074432\n",
      "Epoch 24\n",
      "Iteration 100 - loss is 131.611931277 - parameters are 2.21002077929 8.21521911424 1.55780117485\n",
      "Iteration 200 - loss is 140.264095919 - parameters are 2.2384583372 8.2384979207 1.56883330987\n",
      "Iteration 300 - loss is 91.6243391102 - parameters are 2.21913852274 8.22331658827 1.57155727157\n",
      "Iteration 400 - loss is 92.0843942902 - parameters are 2.23378486644 8.23248461275 1.57839378513\n",
      "Iteration 500 - loss is 91.0410112843 - parameters are 2.22220912177 8.22016848061 1.58158527389\n",
      "Iteration 600 - loss is 111.255306758 - parameters are 2.24596354141 8.23756209127 1.59072455275\n",
      "Iteration 700 - loss is 92.7688905935 - parameters are 2.24558081581 8.23786347162 1.59593782552\n",
      "Iteration 800 - loss is 106.854556155 - parameters are 2.24666989584 8.24571059705 1.60269842706\n",
      "Iteration 900 - loss is 102.697449075 - parameters are 2.23087248408 8.2321936391 1.60640304476\n",
      "Iteration 1000 - loss is 114.674325264 - parameters are 2.25046529805 8.25358738662 1.61531292655\n",
      "Epoch 25\n",
      "Iteration 100 - loss is 127.462447749 - parameters are 2.20616387865 8.21157836316 1.6159833434\n",
      "Iteration 200 - loss is 135.830867855 - parameters are 2.23418109305 8.23452376476 1.62682529294\n",
      "Iteration 300 - loss is 88.642725459 - parameters are 2.21513342572 8.21956357349 1.62948880321\n",
      "Iteration 400 - loss is 89.0841010678 - parameters are 2.22961561861 8.2287048047 1.63621034867\n",
      "Iteration 500 - loss is 88.2723419567 - parameters are 2.21807791002 8.21637448362 1.63931829119\n",
      "Iteration 600 - loss is 107.654641522 - parameters are 2.24164301735 8.23367474203 1.64831858149\n",
      "Iteration 700 - loss is 89.7900464666 - parameters are 2.24121150669 8.23390349222 1.65342433953\n",
      "Iteration 800 - loss is 103.359432774 - parameters are 2.24231168701 8.24171999714 1.66006898641\n",
      "Iteration 900 - loss is 99.375150881 - parameters are 2.22676187646 8.22835151381 1.66369487063\n",
      "Iteration 1000 - loss is 111.228481983 - parameters are 2.24611424405 8.24948271956 1.67246023229\n",
      "Epoch 26\n",
      "Iteration 100 - loss is 123.461920034 - parameters are 2.20238621192 8.20800444646 1.67309168239\n",
      "Iteration 200 - loss is 131.55722157 - parameters are 2.22998994511 8.23062048869 1.6837471885\n",
      "Iteration 300 - loss is 85.7710266349 - parameters are 2.211210168 8.21587862034 1.68635169621\n",
      "Iteration 400 - loss is 86.195434207 - parameters are 2.22553052041 8.22499279064 1.69296057128\n",
      "Iteration 500 - loss is 85.6032673215 - parameters are 2.21403059662 8.21264975268 1.69598684499\n",
      "Iteration 600 - loss is 104.185558402 - parameters are 2.23740909144 8.22985712914 1.70485090938\n",
      "Iteration 700 - loss is 86.9214938063 - parameters are 2.23693061988 8.23001568579 1.70985156368\n",
      "Iteration 800 - loss is 99.9927171564 - parameters are 2.23804142907 8.23780171267 1.71638266126\n",
      "Iteration 900 - loss is 96.1751954314 - parameters are 2.22273448201 8.22457934718 1.7199315225\n",
      "Iteration 1000 - loss is 107.905829584 - parameters are 2.24185060466 8.24545196837 1.72855530499\n",
      "Epoch 27\n",
      "Iteration 100 - loss is 119.604599779 - parameters are 2.19868582948 8.20449598727 1.72914880238\n",
      "Iteration 200 - loss is 127.436991965 - parameters are 2.22588282681 8.22678669573 1.73962151972\n",
      "Iteration 300 - loss is 83.0049395623 - parameters are 2.20736675362 8.21226035701 1.74216843237\n",
      "Iteration 400 - loss is 83.4140126278 - parameters are 2.2215275462 8.22134722223 1.74866687944\n",
      "Iteration 500 - loss is 83.0299222836 - parameters are 2.21006514947 8.20899287201 1.75161331084\n",
      "Iteration 600 - loss is 100.842926126 - parameters are 2.23325969971 8.22610786536 1.76034384662\n",
      "Iteration 700 - loss is 84.1588897777 - parameters are 2.23273602385 8.22619858182 1.76524174271\n",
      "Iteration 800 - loss is 96.7493718145 - parameters are 2.23385700653 8.23395428084 1.7716616359\n",
      "Iteration 900 - loss is 93.0927810421 - parameters are 2.21878829232 8.22087571416 1.77513513966\n",
      "Iteration 1000 - loss is 104.701600364 - parameters are 2.2376722906 8.24149365389 1.78362021239\n",
      "Epoch 28\n",
      "Iteration 100 - loss is 115.884980389 - parameters are 2.19506084111 8.20105164176 1.7841767394\n",
      "Iteration 200 - loss is 123.464273385 - parameters are 2.22185773318 8.22302102075 1.79447023779\n",
      "Iteration 300 - loss is 80.3403438479 - parameters are 2.20360124668 8.20870744345 1.7969609229\n",
      "Iteration 400 - loss is 80.7356409865 - parameters are 2.21760473076 8.21776678204 1.80335113073\n",
      "Iteration 500 - loss is 80.5486056886 - parameters are 2.20617959731 8.2054024595 1.80621949709\n",
      "Iteration 600 - loss is 97.6218307703 - parameters are 2.22919283905 8.22242559526 1.81481913807\n",
      "Iteration 700 - loss is 81.498077159 - parameters are 2.22862565055 8.22245074456 1.81961655821\n",
      "Iteration 800 - loss is 93.6245740869 - parameters are 2.22975636692 8.23017627319 1.82592753337\n",
      "Iteration 900 - loss is 90.1233107144 - parameters are 2.21492135896 8.21723922344 1.82932730167\n",
      "Iteration 1000 - loss is 101.611228533 - parameters are 2.2335772744 8.23760633114 1.83767646458\n",
      "Epoch 29\n",
      "Iteration 100 - loss is 112.297785812 - parameters are 2.19150941374 8.19767009818 1.83819697303\n",
      "Iteration 200 - loss is 119.633407576 - parameters are 2.21791271851 8.21932212938 1.8483147399\n",
      "Iteration 300 - loss is 77.7732932376 - parameters are 2.19991176917 8.20521857052 1.85075052636\n",
      "Iteration 400 - loss is 78.1563010255 - parameters are 2.21376016709 8.21425018273 1.85703463167\n",
      "Iteration 500 - loss is 78.1557726347 - parameters are 2.20237202747 8.20187716578 1.85982666263\n",
      "Iteration 600 - loss is 94.5175656192 - parameters are 2.22520656506 8.21880899439 1.86829798104\n",
      "Iteration 700 - loss is 78.9350756001 - parameters are 2.2245974931 8.21877077211 1.87299714628\n",
      "Iteration 800 - loss is 90.6137060421 - parameters are 2.22573751844 8.22646629469 1.87920143303\n",
      "Iteration 900 - loss is 87.2623825221 - parameters are 2.21113179125 8.21366851656 1.88252904579\n",
      "Iteration 1000 - loss is 98.630340757 - parameters are 2.22956358812 8.23378858845 1.8907450315\n",
      "Epoch 30\n",
      "Iteration 100 - loss is 108.837959898 - parameters are 2.18802976934 8.19435007598 1.89123044381\n",
      "Iteration 200 - loss is 115.938972256 - parameters are 2.21404589423 8.21568871726 1.90117588655\n",
      "Iteration 300 - loss is 75.3000075184 - parameters are 2.1962964988 8.20179245918 1.90355806588\n",
      "Iteration 400 - loss is 75.6721433689 - parameters are 2.20999200426 8.21079616625 1.90973815495\n",
      "Iteration 500 - loss is 75.8480271848 - parameters are 2.19864058377 8.19841567332 1.91245553408\n",
      "Iteration 600 - loss is 91.5256215529 - parameters are 2.22129898985 8.21525676848 1.92080104233\n",
      "Iteration 700 - loss is 76.466073339 - parameters are 2.22064960357 8.21515729543 1.92540411453\n",
      "Iteration 800 - loss is 87.7123449094 - parameters are 2.22179852781 8.22282298285 1.93150388751\n",
      "Iteration 900 - loss is 84.5057805001 - parameters are 2.20741775421 8.21016226703 1.93476088387\n",
      "Iteration 1000 - loss is 95.7547471987 - parameters are 2.2256293212 8.23003904655 1.94284635965\n",
      "Epoch 31\n",
      "Iteration 100 - loss is 105.500656309 - parameters are 2.18462018291 8.19109032493 1.94329756991\n",
      "Iteration 200 - loss is 112.375770274 - parameters are 2.2102554268 8.21211950922 1.95307401817\n",
      "Iteration 300 - loss is 72.9168648366 - parameters are 2.19275366702 8.19842785973 1.95540384579\n",
      "Iteration 400 - loss is 73.2794797393 - parameters are 2.2062984454 8.20740350306 1.96148195592\n",
      "Iteration 500 - loss is 73.6221154567 - parameters are 2.19498346446 8.19501669551 1.9641263222\n",
      "Iteration 600 - loss is 88.6416779254 - parameters are 2.2174682801 8.21176765258 1.97234847459\n",
      "Iteration 700 - loss is 74.0874193473 - parameters are 2.21678009083 8.21160897749 1.97685755834\n",
      "Iteration 800 - loss is 84.9162540054 - parameters are 2.21793751809 8.21924500679 1.98285493893\n",
      "Iteration 900 - loss is 81.8494660043 - parameters are 2.20377746648 8.20671917936 1.98604281858\n",
      "Iteration 1000 - loss is 92.980433022 - parameters are 2.22177261839 8.22635635768 1.99400038826\n",
      "Epoch 32\n",
      "Iteration 100 - loss is 102.281228936 - parameters are 2.18127898051 8.18788962431 1.99441826327\n",
      "Iteration 200 - loss is 108.938819329 - parameters are 2.20653953577 8.20861325853 2.00402897113\n",
      "Iteration 300 - loss is 70.6203944108 - parameters are 2.18928155706 8.19512355094 2.00630766753\n",
      "Iteration 400 - loss is 70.9747755712 - parameters are 2.20267774573 8.20407099141 2.0122857885\n",
      "Iteration 500 - loss is 71.4749190691 - parameters are 2.19139892025 8.19167897587 2.01485873776\n",
      "Iteration 600 - loss is 85.8615939105 - parameters are 2.21371265502 8.20834041034 2.02295993219\n",
      "Iteration 700 - loss is 71.7956158826 - parameters are 2.21298711856 8.20812451237 2.02737707663\n",
      "Iteration 800 - loss is 82.221374128 - parameters are 2.21415266669 8.21573106639 2.03327413455\n",
      "Iteration 900 - loss is 79.2895695158 - parameters are 2.20020919844 8.20333798831 2.03639435894\n",
      "Iteration 1000 - loss is 90.3035503294 - parameters are 2.21799167779 8.22273920478 2.04422656482\n",
      "Epoch 33\n",
      "Iteration 100 - loss is 99.1752228067 - parameters are 2.17800453745 8.18474678205 2.04461194506\n",
      "Iteration 200 - loss is 105.623342194 - parameters are 2.20289649189 8.20516874619 2.05406009316\n",
      "Iteration 300 - loss is 68.4072696164 - parameters are 2.18587850207 8.19187833942 2.05628884506\n",
      "Iteration 400 - loss is 68.7546429994 - parameters are 2.19912821075 8.20079745656 2.06216892053\n",
      "Iteration 500 - loss is 69.4034489238 - parameters are 2.18788525242 8.18840128715 2.06467200684\n",
      "Iteration 600 - loss is 83.1814002881 - parameters are 2.2100303846 8.20497383321 2.07265458634\n",
      "Iteration 700 - loss is 69.5873114225 - parameters are 2.20926890327 8.20470262442 2.07698178698\n",
      "Iteration 800 - loss is 79.6238153909 - parameters are 2.21044220344 8.21227989147 2.08278054187\n",
      "Iteration 900 - loss is 76.8223828658 - parameters are 2.19671127035 8.20001745798 2.08583453542\n",
      "Iteration 1000 - loss is 87.7204105137 - parameters are 2.21428474897 8.21918630065 2.09354386002\n",
      "Epoch 34\n",
      "Iteration 100 - loss is 96.1783654455 - parameters are 2.17479527649 8.181660634 2.09389756058\n",
      "Iteration 200 - loss is 102.424757449 - parameters are 2.19932461523 8.20178478016 2.10318625818\n",
      "Iteration 300 - loss is 66.2743014202 - parameters are 2.18254288336 8.1886910588 2.10536621963\n",
      "Iteration 400 - loss is 66.6158342005 - parameters are 2.19564819439 8.19758175009 2.11115014844\n",
      "Iteration 500 - loss is 67.4048393043 - parameters are 2.18444081107 8.1851824306 2.11358488542\n",
      "Iteration 600 - loss is 80.5972916446 - parameters are 2.20641978775 8.20166673977 2.12145113977\n",
      "Iteration 700 - loss is 67.459293959 - parameters are 2.20562371241 8.20134206743 2.12569034017\n",
      "Iteration 800 - loss is 77.1198494739 - parameters are 2.20680440874 8.20889024099 2.13139276308\n",
      "Iteration 900 - loss is 74.4443518551 - parameters are 2.19328205057 8.19675638106 2.13438191433\n",
      "Iteration 1000 - loss is 85.2274769971 - parameters are 2.21065013114 8.21569638717 2.14197078214\n",
      "Epoch 35\n",
      "Iteration 100 - loss is 93.2865586696 - parameters are 2.17164966612 8.17863004311 2.14229359366\n",
      "Iteration 200 - loss is 99.3386706708 - parameters are 2.19582227353 8.19846019472 2.15142588058\n",
      "Iteration 300 - loss is 64.2184321463 - parameters are 2.17927312869 8.18556056906 2.15355817402\n",
      "Iteration 400 - loss is 64.5552350685 - parameters are 2.19223609738 8.19442274926 2.15924781153\n",
      "Iteration 500 - loss is 65.4763422724 - parameters are 2.18106399338 8.18202123514 2.16161567364\n",
      "Iteration 600 - loss is 78.1056189662 - parameters are 2.20287923063 8.19841797495 2.1693678408\n",
      "Iteration 700 - loss is 65.4084846339 - parameters are 2.20204986267 8.19804162387 2.1735209342\n",
      "Iteration 800 - loss is 74.7059022658 - parameters are 2.20323761176 8.2055609022 2.17912894908\n",
      "Iteration 900 - loss is 72.1520692475 - parameters are 2.1899199539 8.19355357802 2.18205461178\n",
      "Iteration 1000 - loss is 82.8213583376 - parameters are 2.20708617143 8.21226823454 2.18952539094\n",
      "Epoch 36\n",
      "Iteration 100 - loss is 90.4958707912 - parameters are 2.16856621901 8.17565389873 2.18981808043\n",
      "Iteration 200 - loss is 96.360866057 - parameters are 2.19238788047 8.19519384976 2.19879692901\n",
      "Iteration 300 - loss is 62.2367295542 - parameters are 2.17606771065 8.18248575583 2.20088264629\n",
      "Iteration 400 - loss is 62.5698592051 - parameters are 2.18889036555 8.19131935626 2.20647980558\n",
      "Iteration 500 - loss is 63.6153223482 - parameters are 2.17775324194 8.17891655664 2.20878222932\n",
      "Iteration 600 - loss is 75.7028826016 - parameters are 2.19940712502 8.19522640942 2.21642249692\n",
      "Iteration 700 - loss is 63.4319316948 - parameters are 2.19854571818 8.19480010404 2.22049132787\n",
      "Iteration 800 - loss is 72.3785468771 - parameters are 2.19974018876 8.20229068998 2.22600681292\n",
      "Iteration 900 - loss is 69.9422681155 - parameters are 2.18662343993 8.19040789639 2.22887030712\n",
      "Iteration 1000 - loss is 80.4988016812 - parameters are 2.20359126323 8.20890064051 2.23622531098\n",
      "Epoch 37\n",
      "Iteration 100 - loss is 87.8025292053 - parameters are 2.16554349036 8.17273111585 2.23648862272\n",
      "Iteration 200 - loss is 93.4872984739 - parameters are 2.18901989409 8.19198463015 2.2453169396\n",
      "Iteration 300 - loss is 60.3263812117 - parameters are 2.17292514509 8.17946552976 2.24735714295\n",
      "Iteration 400 - loss is 60.6568422088 - parameters are 2.18560948831 8.18827049763 2.25286359607\n",
      "Iteration 500 - loss is 61.8192514546 - parameters are 2.17450704321 8.17586727717 2.25510198119\n",
      "Iteration 600 - loss is 73.3857255748 - parameters are 2.19600192672 8.19209093884 2.26263248789\n",
      "Iteration 700 - loss is 61.5268047541 - parameters are 2.19510968892 8.19161634543 2.26661885371\n",
      "Iteration 800 - loss is 70.1344970027 - parameters are 2.19631056145 8.19907844603 2.27204364276\n",
      "Iteration 900 - loss is 67.8118155184 - parameters are 2.18339101148 8.18731821 2.27484625583\n",
      "Iteration 1000 - loss is 78.256686541 - parameters are 2.2001638446 8.2055924297 2.28208774456\n",
      "Epoch 38\n",
      "Iteration 100 - loss is 85.2029133429 - parameters are 2.16258007649 8.16986063447 2.28232240081\n",
      "Iteration 200 - loss is 90.7140858896 - parameters are 2.1857168153 8.18883144507 2.29100302875\n",
      "Iteration 300 - loss is 58.4846891471 - parameters are 2.16984398962 8.17649882581 2.29299875177\n",
      "Iteration 400 - loss is 58.8134362446 - parameters are 2.18239199713 8.18527512361 2.29841623083\n",
      "Iteration 500 - loss is 60.0857041147 - parameters are 2.17132392599 8.17287230432 2.30059194146\n",
      "Iteration 600 - loss is 71.1509272279 - parameters are 2.19266213409 8.18901048327 2.30801477831\n",
      "Iteration 700 - loss is 59.6903893348 - parameters are 2.1917402291 8.18848921189 2.3119204306\n",
      "Iteration 800 - loss is 67.9706006151 - parameters are 2.19294719544 8.19592303817 2.31725631441\n",
      "Iteration 900 - loss is 65.757706496 - parameters are 2.18022121316 8.18428341831 2.31999930201\n",
      "Iteration 1000 - loss is 76.0920188849 - parameters are 2.19680239674 8.20234245284 2.32712948406\n",
      "Epoch 39\n",
      "Iteration 100 - loss is 82.6935479679 - parameters are 2.15967461335 8.16704141887 2.3273361859\n",
      "Iteration 200 - loss is 88.0375021801 - parameters are 2.18247718636 8.18573322745 2.33587190549\n",
      "Iteration 300 - loss is 56.7090647643 - parameters are 2.16682284217 8.17358460268 2.33782415401\n",
      "Iteration 400 - loss is 57.0370048807 - parameters are 2.17923646411 8.18233220752 2.34315435235\n",
      "Iteration 500 - loss is 58.412352886 - parameters are 2.16820245996 8.1699305705 2.34526871809\n",
      "Iteration 600 - loss is 68.9953971769 - parameters are 2.1893862866 8.18598398654 2.35258592981\n",
      "Iteration 700 - loss is 57.9200816867 - parameters are 2.18843583572 8.185417593 2.35641257586\n",
      "Iteration 800 - loss is 65.8838339693 - parameters are 2.18964859871 8.19282335966 2.36166130333\n",
      "Iteration 900 - loss is 63.777058358 - parameters are 2.17711262988 8.18130244566 2.36434589039\n",
      "Iteration 1000 - loss is 74.0019255157 - parameters are 2.19350544254 8.19914958614 2.37136692397\n",
      "Epoch 40\n",
      "Iteration 100 - loss is 80.2710968009 - parameters are 2.1568257752 8.16427245697 2.37154635199\n",
      "Iteration 200 - loss is 85.453970285 - parameters are 2.1792995895 8.18268893328 2.3799398833\n",
      "Iteration 300 - loss is 54.9970240074 - parameters are 2.16386033964 8.17072184215 2.38184963628\n",
      "Iteration 400 - loss is 55.3250181761 - parameters are 2.17614150057 8.17944074516 2.38709420953\n",
      "Iteration 500 - loss is 56.7969640193 - parameters are 2.1651412543 8.16704103229 2.38914852651\n",
      "Iteration 600 - loss is 66.9161695627 - parameters are 2.18617296342 8.1830104156 2.39636211276\n",
      "Iteration 700 - loss is 56.2133838578 - parameters are 2.18519504706 8.18240040337 2.40011141688\n",
      "Iteration 800 - loss is 63.8712959032 - parameters are 2.18641332022 8.18977832854 2.40527469632\n",
      "Iteration 900 - loss is 61.8671052554 - parameters are 2.17406388552 8.1783742407 2.40790207793\n",
      "Iteration 1000 - loss is 71.9836487265 - parameters are 2.19027154513 8.19601273061 2.41481607236\n",
      "Epoch 41\n",
      "Iteration 100 - loss is 77.9323564507 - parameters are 2.15403227326 8.16155275972 2.41496888739\n",
      "Iteration 200 - loss is 82.9600556947 - parameters are 2.17618264559 8.17969754114 2.4232228916\n",
      "Iteration 300 - loss is 53.3461827608 - parameters are 2.16095515655 8.16790954853 2.42509110199\n",
      "Iteration 400 - loss is 53.6750480075 - parameters are 2.17310575579 8.17659975428 2.43025166909\n",
      "Iteration 500 - loss is 55.2373933298 - parameters are 2.16213895635 8.16420266976 2.43224720098\n",
      "Iteration 600 - loss is 64.9103975807 - parameters are 2.18302078212 8.18008875996 2.43935911759\n",
      "Iteration 700 - loss is 54.5678990082 - parameters are 2.18201644133 8.17943658196 2.44303270244\n",
      "Iteration 800 - loss is 61.9302024168 - parameters are 2.1832399485 8.18678688694 2.44811220269\n",
      "Iteration 900 - loss is 60.0251930165 - parameters are 2.1710736416 8.17549777566 2.450683545\n",
      "Iteration 1000 - loss is 70.0345412171 - parameters are 2.18709930661 8.19293081143 2.4574925621\n",
      "Epoch 42\n",
      "Iteration 100 - loss is 75.6742506386 - parameters are 2.15129285446 8.15888136045 2.45761940587\n",
      "Iteration 200 - loss is 80.5524602513 - parameters are 2.17312501281 8.17675805152 2.46573648681\n",
      "Iteration 300 - loss is 51.7542524724 - parameters are 2.1581060038 8.16514674805 2.46756408233\n",
      "Iteration 400 - loss is 52.084763621 - parameters are 2.17012791567 8.17380827397 2.47264222657\n",
      "Iteration 500 - loss is 53.7315822698 - parameters are 2.15919425034 8.16141448591 2.47458020558\n",
      "Iteration 600 - loss is 62.9753482766 - parameters are 2.17992839738 8.17721803111 2.48159236566\n",
      "Iteration 700 - loss is 52.9813269522 - parameters are 2.17889863529 8.17652509145 2.48519181351\n",
      "Iteration 800 - loss is 60.0578815156 - parameters are 2.18012711032 8.18384800049 2.49018916507\n",
      "Iteration 900 - loss is 58.2487742355 - parameters are 2.16814059602 8.17267204579 2.49270560614\n",
      "Iteration 1000 - loss is 68.1520612581 - parameters are 2.18398736668 8.18990277731 2.49941166153\n",
      "Epoch 43\n",
      "Iteration 100 - loss is 73.4938246984 - parameters are 2.14860630024 8.15625731432 2.49951315733\n",
      "Iteration 200 - loss is 78.228016247 - parameters are 2.17012538542 8.17386948636 2.50749586297\n",
      "Iteration 300 - loss is 50.2190359873 - parameters are 2.15531162742 8.16243248831 2.50928374693\n",
      "Iteration 400 - loss is 50.5519273973 - parameters are 2.16720670153 8.17106536414 2.51428101691\n",
      "Iteration 500 - loss is 52.2775541901 - parameters are 2.15630585615 8.15867550602 2.5161626447\n",
      "Iteration 600 - loss is 61.1083975908 - parameters are 2.17689449981 8.17439726196 2.52307691986\n",
      "Iteration 700 - loss is 51.4514599168 - parameters are 2.17584028305 8.17366491763 2.5266037738\n",
      "Iteration 800 - loss is 58.2517683034 - parameters are 2.17707346944 8.18096065767 2.53152056991\n",
      "Iteration 900 - loss is 56.5354035974 - parameters are 2.16526348187 8.1698960687 2.53398322054\n",
      "Iteration 1000 - loss is 66.3337680872 - parameters are 2.18093440145 8.18692759989 2.54058828488\n",
      "Epoch 44\n",
      "Iteration 100 - loss is 71.388240339 - parameters are 2.14597142537 8.15367969769 2.54066503819\n",
      "Iteration 200 - loss is 75.9836808027 - parameters are 2.16718249259 8.17103088846 2.54851586211\n",
      "Iteration 300 - loss is 48.7384235819 - parameters are 2.15257080743 8.15976583776 2.55026491416\n",
      "Iteration 400 - loss is 49.074390819 - parameters are 2.16434086898 8.16837010501 2.55518282469\n",
      "Iteration 500 - loss is 50.8734107827 - parameters are 2.15347252812 8.15598477706 2.55700927332\n",
      "Iteration 600 - loss is 59.3070256412 - parameters are 2.1739178147 8.17162550628 2.56382749468\n",
      "Iteration 700 - loss is 49.976178505 - parameters are 2.17284007473 8.17085506879 2.5672832598\n",
      "Iteration 800 - loss is 56.5094003117 - parameters are 2.17407772539 8.17812386927 2.57212105751\n",
      "Iteration 900 - loss is 54.8827334289 - parameters are 2.16244106622 8.16716888382 2.57453100201\n",
      "Iteration 1000 - loss is 64.5773175277 - parameters are 2.17793912221 8.18400427319 2.58103700224\n",
      "Epoch 45\n",
      "Iteration 100 - loss is 69.3547706541 - parameters are 2.14338707686 8.15114760761 2.58108960131\n",
      "Iteration 200 - loss is 73.8165305142 - parameters are 2.16429509724 8.16824132099 2.58881098411\n",
      "Iteration 300 - loss is 47.3103891867 - parameters are 2.1498823567 8.15714588515 2.59052206095\n",
      "Iteration 400 - loss is 47.6500906302 - parameters are 2.16152920675 8.16572159657 2.595362094\n",
      "Iteration 500 - loss is 49.5173286925 - parameters are 2.15069305395 8.15334136716 2.59713450678\n",
      "Iteration 600 - loss is 57.5688122295 - parameters are 2.17099710094 8.16890183823 2.6038584661\n",
      "Iteration 700 - loss is 48.5534478529 - parameters are 2.1698967354 8.16809457514 2.60724461061\n",
      "Iteration 800 - loss is 54.8284130534 - parameters are 2.17113861226 8.17533666775 2.61200493177\n",
      "Iteration 900 - loss is 53.2885094621 - parameters are 2.15967214904 8.16448955181 2.61436322876\n",
      "Iteration 1000 - loss is 62.8804578162 - parameters are 2.17500027432 8.181131813 2.62077204926\n",
      "Epoch 46\n",
      "Iteration 100 - loss is 67.3907953683 - parameters are 2.14085213288 8.14866016126 2.62080106569\n",
      "Iteration 200 - loss is 71.7237563505 - parameters are 2.16146199491 8.16549986698 2.62839539636\n",
      "Iteration 300 - loss is 45.9329867887 - parameters are 2.14724511988 8.15457173901 2.63006933246\n",
      "Iteration 400 - loss is 46.2770451764 - parameters are 2.1587705356 8.1631189581 2.63483293802\n",
      "Iteration 500 - loss is 48.2075562916 - parameters are 2.14796625357 8.15074436504 2.63655243037\n",
      "Iteration 600 - loss is 55.8914325611 - parameters are 2.16813114996 8.16622535177 2.64318388105\n",
      "Iteration 700 - loss is 47.1813139703 - parameters are 2.16700902384 8.16538248822 2.64650183737\n",
      "Iteration 800 - loss is 53.2065357877 - parameters are 2.16825489763 8.17259810671 2.65118616959\n",
      "Iteration 900 - loss is 51.7505668 - parameters are 2.15695556215 8.16185715402 2.65349385271\n",
      "Iteration 1000 - loss is 61.241025628 - parameters are 2.17211663608 8.17830925633 2.65980733645\n",
      "Epoch 47\n",
      "Iteration 100 - loss is 65.4937963052 - parameters are 2.13836550173 8.1462164954 2.65981332579\n",
      "Iteration 200 - loss is 69.7026587906 - parameters are 2.15868201275 8.16280562882 2.66728294298\n",
      "Iteration 300 - loss is 44.6043470032 - parameters are 2.14465797236 8.15204252715 2.66892055127\n",
      "Iteration 400 - loss is 44.9533509176 - parameters are 2.15606370733 8.16056132767 2.67360914819\n",
      "Iteration 500 - loss is 46.942410605 - parameters are 2.1452909781 8.14819287946 2.67527680845\n",
      "Iteration 600 - loss is 54.2726531663 - parameters are 2.16531878462 8.16359516021 2.6818174665\n",
      "Iteration 700 - loss is 45.8579002552 - parameters are 2.16417573152 8.16271788037 2.68506863235\n",
      "Iteration 800 - loss is 51.6415874861 - parameters are 2.16542538145 8.16990726037 2.68967842996\n",
      "Iteration 900 - loss is 50.2668260733 - parameters are 2.15429016811 8.15927079194 2.6919365086\n",
      "Iteration 1000 - loss is 59.6569422919 - parameters are 2.16928701767 8.17553566091 2.69815645823\n",
      "Epoch 48\n",
      "Iteration 100 - loss is 63.6613530668 - parameters are 2.13592612085 8.1438157659 2.69813996046\n",
      "Iteration 200 - loss is 67.7506431892 - parameters are 2.1559540085 8.1601577278 2.70548715383\n",
      "Iteration 300 - loss is 43.3226738068 - parameters are 2.14211981929 8.14955739623 2.70708922632\n",
      "Iteration 400 - loss is 43.6771791035 - parameters are 2.15340760375 8.15804786171 2.71170420312\n",
      "Iteration 500 - loss is 45.7202743824 - parameters are 2.14266610887 8.14568603874 2.71332109336\n",
      "Iteration 600 - loss is 52.7103280125 - parameters are 2.16255885826 8.16101039575 2.7197726384\n",
      "Iteration 700 - loss is 44.5814041731 - parameters are 2.1613956815 8.16009984423 2.72295837774\n",
      "Iteration 800 - loss is 50.1314729896 - parameters are 2.162648895 8.16726322302 2.72749506273\n",
      "Iteration 900 - loss is 48.8352897788 - parameters are 2.1516748593 8.15672958668 2.72970452271\n",
      "Iteration 1000 - loss is 58.1262101811 - parameters are 2.16651026015 8.17281010463 2.73583270163\n",
      "Epoch 49\n",
      "Iteration 100 - loss is 61.8911389142 - parameters are 2.13353295588 8.14145714722 2.73579424169\n",
      "Iteration 200 - loss is 65.8652153557 - parameters are 2.15327686947 8.15755530363 2.74302125309\n",
      "Iteration 300 - loss is 42.0862414235 - parameters are 2.13962959461 8.14711551122 2.74458856155\n",
      "Iteration 400 - loss is 42.4467726046 - parameters are 2.15080113571 8.15557773451 2.74913127723\n",
      "Iteration 500 - loss is 44.5395933064 - parameters are 2.14009055644 8.14322299022 2.75069843398\n",
      "Iteration 600 - loss is 51.2023947981 - parameters are 2.15985025371 8.15847020896 2.75706251016\n",
      "Iteration 700 - loss is 43.3500940926 - parameters are 2.15866772747 8.15752749213 2.76018415425\n",
      "Iteration 800 - loss is 48.6741793453 - parameters are 2.15992429993 8.1646651085 2.76464911707\n",
      "Iteration 900 - loss is 47.4540387887 - parameters are 2.14910855695 8.1542326785 2.76681092131\n",
      "Iteration 1000 - loss is 56.6469092753 - parameters are 2.16378523448 8.17013168509 2.77284905473\n",
      "Epoch 50\n",
      "Iteration 100 - loss is 60.180916838 - parameters are 2.13118499974 8.13913983195 2.772789143\n",
      "Iteration 200 - loss is 64.0439773384 - parameters are 2.15064951164 8.15499751401 2.77989816769\n",
      "Iteration 300 - loss is 40.8933913549 - parameters are 2.1371862601 8.14471605498 2.78143146423\n",
      "Iteration 400 - loss is 41.2604428887 - parameters are 2.14824324222 8.15315013782 2.78590324902\n",
      "Iteration 500 - loss is 43.3988733312 - parameters are 2.13756325965 8.14080289978 2.78742168404\n",
      "Iteration 600 - loss is 49.7468714181 - parameters are 2.15719188237 8.15597376835 2.79369990093\n",
      "Iteration 700 - loss is 42.1623062689 - parameters are 2.15599075274 8.15499995569 2.79675874921\n",
      "Iteration 800 - loss is 47.2677723145 - parameters are 2.15725048721 8.16211204974 2.80115334971\n",
      "Iteration 900 - loss is 46.121229024 - parameters are 2.14659021021 8.15177922627 2.80326843886\n",
      "Iteration 1000 - loss is 55.2171938807 - parameters are 2.16111084057 8.16749951902 2.80921821475\n",
      "Epoch 51\n",
      "Iteration 100 - loss is 58.5285358091 - parameters are 2.12888127177 8.13686303031 2.80913734757\n",
      "Iteration 200 - loss is 62.2846234032 - parameters are 2.14807087875 8.15248353417 2.81613053539\n",
      "Iteration 300 - loss is 39.742529548 - parameters are 2.13478880456 8.1423582278 2.81763055303\n",
      "Iteration 400 - loss is 40.1165671385 - parameters are 2.14573288951 8.15076428038 2.82203270915\n",
      "Iteration 500 - loss is 42.2966781452 - parameters are 2.13508318474 8.13842495141 2.82350341012\n",
      "Iteration 600 - loss is 48.3418525934 - parameters are 2.15458268332 8.15352025994 2.82969734358\n",
      "Iteration 700 - loss is 41.0164419679 - parameters are 2.15336366934 8.15251638527 2.83269466462\n",
      "Iteration 800 - loss is 45.9103930437 - parameters are 2.15462637633 8.15960319822 2.83702023282\n",
      "Iteration 900 - loss is 44.8350882815 - parameters are 2.14411879526 8.14936840706 2.8390895259\n",
      "Iteration 1000 - loss is 53.8352895042 - parameters are 2.15848600635 8.16491274191 2.84495259598\n",
      "Epoch 52\n",
      "Iteration 100 - loss is 56.9319272015 - parameters are 2.12662081687 8.13462596974 2.84485125607\n",
      "Iteration 200 - loss is 60.5849361948 - parameters are 2.14553994141 8.15001255647 2.85173071254\n",
      "Iteration 300 - loss is 38.6321236938 - parameters are 2.13243624289 8.140041247 2.85319816582\n",
      "Iteration 400 - loss is 39.0135854997 - parameters are 2.14326907019 8.14841938754 2.85753196819\n",
      "Iteration 500 - loss is 41.2316267498 - parameters are 2.13264932451 8.13608834669 2.85895589937\n",
      "Iteration 600 - loss is 46.9855066545 - parameters are 2.15202162247 8.15110888682 2.86506709244\n",
      "Iteration 700 - loss is 39.9109647237 - parameters are 2.15078541707 8.1500759495 2.86800412483\n",
      "Iteration 800 - loss is 44.6002548887 - parameters are 2.15205091427 8.15713772359 2.8722619617\n",
      "Iteration 900 - loss is 43.5939132083 - parameters are 2.1416933145 8.1469994156 2.8742863567\n",
      "Iteration 1000 - loss is 52.4994898699 - parameters are 2.15590968696 8.16237050747 2.88006433738\n",
      "Epoch 53\n",
      "Iteration 100 - loss is 55.3891013778 - parameters are 2.12440270468 8.13242789444 2.87994299427\n",
      "Iteration 200 - loss is 58.942783074 - parameters are 2.14305569631 8.14758378997 2.88671078171\n",
      "Iteration 300 - loss is 37.5607006492 - parameters are 2.13012761534 8.13776434647 2.88814636723\n",
      "Iteration 400 - loss is 37.9499984558 - parameters are 2.14085080247 8.14611470084 2.89241306414\n",
      "Iteration 500 - loss is 40.2023911505 - parameters are 2.13026069743 8.13379230438 2.8937911671\n",
      "Iteration 600 - loss is 45.6760724723 - parameters are 2.14950769169 8.14873886871 2.89982113076\n",
      "Iteration 700 - loss is 38.8443977221 - parameters are 2.14825496271 8.14767783485 2.90269908392\n",
      "Iteration 800 - loss is 43.3356403857 - parameters are 2.14952307477 8.15471481313 2.90689046219\n",
      "Iteration 900 - loss is 42.3960664149 - parameters are 2.13931279568 8.14467146393 2.90887083663\n",
      "Iteration 1000 - loss is 51.2081540737 - parameters are 2.15338086384 8.1598719872 2.91456530991\n",
      "Epoch 54\n",
      "Iteration 100 - loss is 53.8981444288 - parameters are 2.12222602883 8.13026806493 2.91442442039\n",
      "Iteration 200 - loss is 57.3561126205 - parameters are 2.14061716535 8.14519646006 2.92108255898\n",
      "Iteration 300 - loss is 36.5268439765 - parameters are 2.12786198664 8.1355267763 2.9224869559\n",
      "Iteration 400 - loss is 36.9243643222 - parameters are 2.13847712932 8.14384947759 2.9266877697\n",
      "Iteration 500 - loss is 39.2076941526 - parameters are 2.12791634692 8.13153605998 2.9280209639\n",
      "Iteration 600 - loss is 44.4118565292 - parameters are 2.14703990808 8.14640944161 2.93397117791\n",
      "Iteration 700 - loss is 37.8153213047 - parameters are 2.14577129911 8.14532124516 2.93679123296\n",
      "Iteration 800 - loss is 42.1148983611 - parameters are 2.14704185742 8.15233367137 2.94091739785\n",
      "Iteration 900 - loss is 41.239973721 - parameters are 2.13697629118 8.14238378088 2.94285460935\n",
      "Iteration 1000 - loss is 49.9597038676 - parameters are 2.15089854397 8.15741636999 2.94846712371\n",
      "Epoch 55\n",
      "Iteration 100 - loss is 52.457215061 - parameters are 2.12008990616 8.12814575767 2.94830713223\n",
      "Iteration 200 - loss is 55.8229512934 - parameters are 2.13822339491 8.142849808 2.95485760099\n",
      "Iteration 300 - loss is 35.529191595 - parameters are 2.12563844531 8.13332780235 2.95623147158\n",
      "Iteration 400 - loss is 35.9352968532 - parameters are 2.1361471177 8.14162299055 2.96036759935\n",
      "Iteration 500 - loss is 38.2463072584 - parameters are 2.12561534051 8.12931886532 2.96165678279\n",
      "Iteration 600 - loss is 43.1912301227 - parameters are 2.14461731314 8.14411985737 2.96752869644\n",
      "Iteration 700 - loss is 36.822370587 - parameters are 2.14333344445 8.14300540123 2.97029200696\n",
      "Iteration 800 - loss is 40.9364411726 - parameters are 2.14460628688 8.14999351963 2.97435417688\n",
      "Iteration 900 - loss is 40.1241215262 - parameters are 2.13468287718 8.14013561169 2.97624906371\n",
      "Iteration 1000 - loss is 48.7526210671 - parameters are 2.14846175905 8.15500286165 2.98178113494\n",
      "Epoch 56\n",
      "Iteration 100 - loss is 51.064541623 - parameters are 2.11799347604 8.12606026464 2.981602474\n",
      "Iteration 200 - loss is 54.3414002417 - parameters are 2.1358734551 8.14054309062 2.98804721185\n",
      "Iteration 300 - loss is 34.5664335381 - parameters are 2.12345610289 8.13116670591 2.98939120195\n",
      "Iteration 400 - loss is 34.981462957 - parameters are 2.13385985789 8.1394345275 2.9934638161\n",
      "Iteration 500 - loss is 37.317048658 - parameters are 2.12335676915 8.12713998814 2.9947098659\n",
      "Iteration 600 - loss is 42.0126266945 - parameters are 2.14223897208 8.14186938328 3.00050489878\n",
      "Iteration 700 - loss is 35.8642331841 - parameters are 2.14094044143 8.14072954035 3.00321259159\n",
      "Iteration 800 - loss is 39.7987420761 - parameters are 2.14221541215 8.14769359562 3.00721195886\n",
      "Iteration 900 - loss is 39.0470543007 - parameters are 2.13243165299 8.13792621761 3.00906534046\n",
      "Iteration 1000 - loss is 47.5854450761 - parameters are 2.14606956481 8.15263068452 3.01451845248\n",
      "Epoch 57\n",
      "Iteration 100 - loss is 49.7184192651 - parameters are 2.1159358996 8.12401089296 3.01432154302\n",
      "Iteration 200 - loss is 52.9096322576 - parameters are 2.13356643903 8.13827557993 3.02066244969\n",
      "Iteration 300 - loss is 33.6373098118 - parameters are 2.12131409325 8.12904278326 3.02197718924\n",
      "Iteration 400 - loss is 34.061580513 - parameters are 2.13161446271 8.13728339089 3.02598743812\n",
      "Iteration 500 - loss is 36.4187813123 - parameters are 2.12113974648 8.12499871169 3.02719121112\n",
      "Iteration 600 - loss is 40.8745392804 - parameters are 2.13990397305 8.13965730178 3.03291075382\n",
      "Iteration 700 - loss is 34.9396470402 - parameters are 2.13859135654 8.13849291597 3.03556392973\n",
      "Iteration 800 - loss is 38.7003327112 - parameters are 2.1398683058 8.14543315305 3.03950166125\n",
      "Iteration 900 - loss is 38.0073721886 - parameters are 2.13022174032 8.13575487549 3.04131433873\n",
      "Iteration 1000 - loss is 46.456770524 - parameters are 2.14372104022 8.15029907706 3.04668994443\n",
      "Epoch 58\n",
      "Iteration 100 - loss is 48.4172072251 - parameters are 2.11391635912 8.12199696449 3.04647519615\n",
      "Iteration 200 - loss is 51.5258888648 - parameters are 2.1313014621 8.1360465627 3.05271413318\n",
      "Iteration 300 - loss is 32.7406083484 - parameters are 2.11921157189 8.12695534539 3.05400023659\n",
      "Iteration 400 - loss is 33.1744162867 - parameters are 2.12941006689 8.13516889753 3.05794924513\n",
      "Iteration 500 - loss is 35.5504111209 - parameters are 2.11896340812 8.12289433436 3.05911157843\n",
      "Iteration 600 - loss is 39.7755180735 - parameters are 2.13761142652 8.13748291001 3.06475699325\n",
      "Iteration 700 - loss is 34.0473983554 - parameters are 2.13628527934 8.13629479722 3.06735672778\n",
      "Iteration 800 - loss is 37.6398007005 - parameters are 2.13756406327 8.1432114612 3.07123396568\n",
      "Iteration 900 - loss is 37.0037287195 - parameters are 2.12805228258 8.13362087738 3.07300672231\n",
      "Iteration 1000 - loss is 45.365245007 - parameters are 2.14141528683 8.14800729348 3.07830624428\n",
      "Epoch 59\n",
      "Iteration 100 - loss is 47.1593262345 - parameters are 2.11193405739 8.12001781551 3.07807405606\n",
      "Iteration 200 - loss is 50.1884775361 - parameters are 2.12907766137 8.13385534022 3.08421284764\n",
      "Iteration 300 - loss is 31.8751630518 - parameters are 2.11714771531 8.12490371758 3.08547091434\n",
      "Iteration 400 - loss is 32.318783937 - parameters are 2.12724582636 8.13309037819 3.08935978456\n",
      "Iteration 500 - loss is 34.7108851723 - parameters are 2.11682691106 8.12082616931 3.09048149608\n",
      "Iteration 600 - loss is 38.7141680963 - parameters are 2.13536046457 8.13534551952 3.09605411772\n",
      "Iteration 700 - loss is 33.1863196053 - parameters are 2.13402132176 8.13413446859 3.09860146177\n",
      "Iteration 800 - loss is 36.6157873551 - parameters are 2.13530180216 8.14102780457 3.10241932403\n",
      "Iteration 900 - loss is 36.0348286225 - parameters are 2.1259224443 8.13152353021 3.10415292574\n",
      "Iteration 1000 - loss is 44.309566932 - parameters are 2.13915142809 8.14575460334 3.10937775705\n",
      "Epoch 60\n",
      "Iteration 100 - loss is 45.9432560384 - parameters are 2.10998821703 8.11807279631 3.10912851724\n",
      "Iteration 200 - loss is 48.8957690338 - parameters are 2.12689419488 8.13170122787 3.11516895113\n",
      "Iteration 300 - loss is 31.0398519298 - parameters are 2.11512172038 8.12288723908 3.11639956595\n",
      "Iteration 400 - loss is 31.493542112 - parameters are 2.1251209177 8.13104717731 3.12022937756\n",
      "Iteration 500 - loss is 33.8991900716 - parameters are 2.11472943296 8.11879354411 3.12131126654\n",
      "Iteration 600 - loss is 37.6891469757 - parameters are 2.13315024028 8.1332444559 3.12681240275\n",
      "Iteration 700 - loss is 32.3552876495 - parameters are 2.13179861747 8.1320112295 3.12930838332\n",
      "Iteration 800 - loss is 35.6269854838 - parameters are 2.13308066162 8.13888148253 3.1330679644\n",
      "Iteration 900 - loss is 35.0994257365 - parameters are 2.12383141043 8.12946215535 3.13476316021\n",
      "Iteration 1000 - loss is 43.2884834551 - parameters are 2.13692860872 8.14354029122 3.13991466511\n",
      "Epoch 61\n",
      "Iteration 100 - loss is 44.7675330249 - parameters are 2.10807807994 8.11616127086 3.13964875188\n",
      "Iteration 200 - loss is 47.6461948661 - parameters are 2.12475024107 8.12958355482 3.14559258028\n",
      "Iteration 300 - loss is 30.2335953077 - parameters are 2.11313280371 8.12090526278 3.14679631385\n",
      "Iteration 400 - loss is 30.6975926279 - parameters are 2.12303453743 8.12903865265 3.15056812477\n",
      "Iteration 500 - loss is 33.1143503426 - parameters are 2.11267017158 8.11679580034 3.15161097231\n",
      "Iteration 600 - loss is 36.6991628157 - parameters are 2.13097992709 8.13117905846 3.15704190456\n",
      "Iteration 700 - loss is 31.5532219236 - parameters are 2.12961632117 8.129924394 3.15948752534\n",
      "Iteration 800 - loss is 34.6721372985 - parameters are 2.13089980168 8.13677180889 3.16318989676\n",
      "Iteration 900 - loss is 34.1963210149 - parameters are 2.12177838575 8.12743608833 3.16484741924\n",
      "Iteration 1000 - loss is 42.3007885119 - parameters are 2.13474599403 8.14136365629 3.16992693391\n",
      "Epoch 62\n",
      "Iteration 100 - loss is 43.6307479575 - parameters are 2.10620290672 8.11428261652 3.16964471553\n",
      "Iteration 200 - loss is 46.4382448556 - parameters are 2.12264499813 8.12750166373 3.1754936559\n",
      "Iteration 300 - loss is 29.455354122 - parameters are 2.11118020107 8.1189571549 3.17667106509\n",
      "Iteration 400 - loss is 29.9298787287 - parameters are 2.1209859015 8.12706417501 3.180385912\n",
      "Iteration 500 - loss is 32.3554268997 - parameters are 2.11064834418 8.11483229334 3.18139048149\n",
      "Iteration 600 - loss is 35.7429721646 - parameters are 2.1288487182 8.1291486799 3.18675246558\n",
      "Iteration 700 - loss is 30.7790827114 - parameters are 2.12747360804 8.12787329037 3.18914870763\n",
      "Iteration 800 - loss is 33.7500324127 - parameters are 2.12875840262 8.13469811164 3.19279491856\n",
      "Iteration 900 - loss is 33.3243606168 - parameters are 2.11976259431 8.12544467844 3.19441548425\n",
      "Iteration 1000 - loss is 41.3453209338 - parameters are 2.1326027694 8.13922401205 3.19942431744\n",
      "Epoch 63\n",
      "Iteration 100 - loss is 42.5315438064 - parameters are 2.10436197608 8.11243622365 3.19912615263\n",
      "Iteration 200 - loss is 45.2704648128 - parameters are 2.12057768346 8.1254549104 3.20488188849\n",
      "Iteration 300 - loss is 28.7041282874 - parameters are 2.10926316683 8.11704229462 3.20603351678\n",
      "Iteration 400 - loss is 29.1893834211 - parameters are 2.11897424468 8.12512312788 3.20969241559\n",
      "Iteration 500 - loss is 31.6215155873 - parameters are 2.10866318691 8.11290239178 3.21065945327\n",
      "Iteration 600 - loss is 34.8193780695 - parameters are 2.12675582605 8.127152686 3.21595371992\n",
      "Iteration 700 - loss is 30.0318694934 - parameters are 2.12536967309 8.12585726076 3.21830154224\n",
      "Iteration 800 - loss is 32.8595059277 - parameters are 2.12665566443 8.13265973255 3.22189262005\n",
      "Iteration 900 - loss is 32.4824340831 - parameters are 2.11778327884 8.12348728844 3.22347692989\n",
      "Iteration 1000 - loss is 40.4209626477 - parameters are 2.1304981396 8.13712068594 3.22841636362\n",
      "Epoch 64\n",
      "Iteration 100 - loss is 41.4686136736 - parameters are 2.10255458433 8.11062149532 3.22810260181\n",
      "Iteration 200 - loss is 44.1414543105 - parameters are 2.11854753309 8.12344266352 3.23376678355\n",
      "Iteration 300 - loss is 27.9789551359 - parameters are 2.10738097342 8.11516007384 3.23489316141\n",
      "Iteration 400 - loss is 28.4751278822 - parameters are 2.11699882003 8.12321490719 3.23849710779\n",
      "Iteration 500 - loss is 30.9117457829 - parameters are 2.10671395431 8.11100547741 3.23942734313\n",
      "Iteration 600 - loss is 33.9272282171 - parameters are 2.12470048171 8.12519045531 3.24465509859\n",
      "Iteration 700 - loss is 29.3106193676 - parameters are 2.12330373063 8.12387566094 3.24695543875\n",
      "Iteration 800 - loss is 31.9994366029 - parameters are 2.12459080616 8.13065602686 3.25049238955\n",
      "Iteration 900 - loss is 31.669472592 - parameters are 2.11583970022 8.12156329422 3.25204112928\n",
      "Iteration 1000 - loss is 39.5266369535 - parameters are 2.12843132833 8.13505301901 3.25691241944\n",
      "Epoch 65\n",
      "Iteration 100 - loss is 40.4406988079 - parameters are 2.10078004485 8.10883784701 3.25658340109\n",
      "Iteration 200 - loss is 43.0498645549 - parameters are 2.11655380117 8.1214643043 3.2621576467\n",
      "Iteration 300 - loss is 27.2789079228 - parameters are 2.10553291079 8.11330989683 3.26325929196\n",
      "Iteration 400 - loss is 27.786169936 - parameters are 2.11505889836 8.12133892097 3.26680926178\n",
      "Iteration 500 - loss is 30.2252790606 - parameters are 2.10479991875 8.10914094471 3.26770340798\n",
      "Iteration 600 - loss is 33.0654131538 - parameters are 2.12268193436 8.12326137886 3.27286583461\n",
      "Iteration 700 - loss is 28.6144055388 - parameters are 2.12127501365 8.12192785987 3.27511960927\n",
      "Iteration 800 - loss is 31.1687451056 - parameters are 2.12256306547 8.12868636296 3.27860341843\n",
      "Iteration 900 - loss is 30.8844472906 - parameters are 2.11393113695 8.11967208448 3.28011725899\n",
      "Iteration 1000 - loss is 38.6613068771 - parameters are 2.1264015776 8.13302036564 3.28492163604\n",
      "Epoch 66\n",
      "Iteration 100 - loss is 39.4465867039 - parameters are 2.0990376876 8.10708470629 3.28457769284\n",
      "Iteration 200 - loss is 41.9943963471 - parameters are 2.11459575942 8.11951922625 3.29006358869\n",
      "Iteration 300 - loss is 26.6030943982 - parameters are 2.1037182859 8.11149117999 3.29114100689\n",
      "Iteration 400 - loss is 27.1216025956 - parameters are 2.11315376773 8.11949458913 3.29463795674\n",
      "Iteration 500 - loss is 29.5613079128 - parameters are 2.1029203699 8.1073082006 3.29549671112\n",
      "Iteration 600 - loss is 32.2328645833 - parameters are 2.12069945078 8.12136485986 3.30059496791\n",
      "Iteration 700 - loss is 27.9423358743 - parameters are 2.11928277335 8.12001323946 3.30280307343\n",
      "Iteration 800 - loss is 30.3663923372 - parameters are 2.12057169798 8.12675012209 3.3062347061\n",
      "Iteration 900 - loss is 30.1263676989 - parameters are 2.11205688463 8.11781306043 3.30771430399\n",
      "Iteration 1000 - loss is 37.8239735939 - parameters are 2.12440814724 8.13102209319 3.31245297349\n",
      "Epoch 67\n",
      "Iteration 100 - loss is 38.485109284 - parameters are 2.09732685862 8.10536151256 3.31209442871\n",
      "Iteration 200 - loss is 40.9737981322 - parameters are 2.11267269664 8.11760683486 3.31749353024\n",
      "Iteration 300 - loss is 25.9506554393 - parameters are 2.10193642224 8.10970335151 3.31854721499\n",
      "Iteration 400 - loss is 26.4805526681 - parameters are 2.11128273294 8.11768134313 3.32199208256\n",
      "Iteration 500 - loss is 28.919054527 - parameters are 2.10107461427 8.10550666414 3.32281612702\n",
      "Iteration 600 - loss is 31.4285537373 - parameters are 2.11875231487 8.11950031345 3.32785135016\n",
      "Iteration 700 - loss is 27.2935515219 - parameters are 2.11732627856 8.11813119425 3.33001466309\n",
      "Iteration 800 - loss is 29.5913778313 - parameters are 2.11861597686 8.12484669801 3.33339506469\n",
      "Iteration 900 - loss is 29.3942801828 - parameters are 2.1102162555 8.11598563548 3.33484106234\n",
      "Iteration 1000 - loss is 37.0136749211 - parameters are 2.12245031439 8.12905758171 3.33951520561\n",
      "Epoch 68\n",
      "Iteration 100 - loss is 37.5551411564 - parameters are 2.09564691957 8.10366771675 3.33914237428\n",
      "Iteration 200 - loss is 39.9868641318 - parameters are 2.11078391823 8.11572654737 3.34445620674\n",
      "Iteration 300 - loss is 25.3207637414 - parameters are 2.10018665934 8.10794585112 3.34548664\n",
      "Iteration 400 - loss is 25.8621794187 - parameters are 2.10944511507 8.11589862574 3.34888034459\n",
      "Iteration 500 - loss is 28.2977696146 - parameters are 2.0992619747 8.10373576623 3.34967034597\n",
      "Iteration 600 - loss is 30.6514898157 - parameters are 2.11683982714 8.11766716637 3.35464364938\n",
      "Iteration 700 - loss is 26.6672255869 - parameters are 2.1154048153 8.11628113107 3.356763027\n",
      "Iteration 800 - loss is 28.8427382212 - parameters are 2.11669519228 8.12297549673 3.36009312368\n",
      "Iteration 900 - loss is 28.6872664929 - parameters are 2.10840857794 8.114189235 3.36150614984\n",
      "Iteration 1000 - loss is 36.2294838737 - parameters are 2.12052737301 8.12712622365 3.36611692448\n",
      "Epoch 69\n",
      "Iteration 100 - loss is 36.655597948 - parameters are 2.09399724732 8.10200278101 3.36573011368\n",
      "Iteration 200 - loss is 39.0324325555 - parameters are 2.10892874572 8.11387779243 3.37096017279\n",
      "Iteration 300 - loss is 24.7126225648 - parameters are 2.09846835235 8.10621812985 3.37196782524\n",
      "Iteration 400 - loss is 25.2656732926 - parameters are 2.10764025102 8.11414589078 3.37531126814\n",
      "Iteration 500 - loss is 27.6967312905 - parameters are 2.0974817899 8.10199494936 3.37606787865\n",
      "Iteration 600 - loss is 29.9007184937 - parameters are 2.11496130423 8.11586485675 3.38098035445\n",
      "Iteration 700 - loss is 26.062561867 - parameters are 2.11351768624 8.1144624688 3.38305663528\n",
      "Iteration 800 - loss is 28.1195457729 - parameters are 2.11480865091 8.12113593622 3.38633733439\n",
      "Iteration 900 - loss is 28.0044423657 - parameters are 2.10663319601 8.11242329597 3.38771800445\n",
      "Iteration 1000 - loss is 35.4705072829 - parameters are 2.11863863342 8.12522742359 3.39226654492\n",
      "Epoch 70\n",
      "Iteration 100 - loss is 35.7854347066 - parameters are 2.09237723342 8.10036617852 3.39186605402\n",
      "Iteration 200 - loss is 38.1093838876 - parameters are 2.10710651632 8.11206000992 3.39701380661\n",
      "Iteration 300 - loss is 24.1254645352 - parameters are 2.09678087153 8.10451964973 3.39799913794\n",
      "Iteration 400 - loss is 24.6902546899 - parameters are 2.10586749306 8.11242260289 3.40129320287\n",
      "Iteration 500 - loss is 27.1152439999 - parameters are 2.09573341403 8.10028366731 3.40201706043\n",
      "Iteration 600 - loss is 29.1753204917 - parameters are 2.11311607851 8.11409283382 3.40686977951\n",
      "Iteration 700 - loss is 25.4787936403 - parameters are 2.11166421025 8.11267463808 3.40890378375\n",
      "Iteration 800 - loss is 27.420906981 - parameters are 2.11295567553 8.11932744612 3.41213597434\n",
      "Iteration 900 - loss is 27.3449561844 - parameters are 2.10488946903 8.11068726676 3.41348489065\n",
      "Iteration 1000 - loss is 34.7358844734 - parameters are 2.11678342182 8.12336059793 3.41797230881\n",
      "Epoch 71\n",
      "Iteration 100 - loss is 34.9436443717 - parameters are 2.0907862838 8.09875739315 3.41755842967\n",
      "Iteration 200 - loss is 37.2166392462 - parameters are 2.10531658246 8.11027265066 3.42262531437\n",
      "Iteration 300 - loss is 23.5585504945 - parameters are 2.0951236019 8.10284988354 3.42358877359\n",
      "Iteration 400 - loss is 24.1351727936 - parameters are 2.1041262084 8.11072823722 3.42683432707\n",
      "Iteration 500 - loss is 26.5526374905 - parameters are 2.09401621622 8.09860138488 3.42752605573\n",
      "Iteration 600 - loss is 28.4744102062 - parameters are 2.11130349763 8.11235055766 3.43232006814\n",
      "Iteration 700 - loss is 24.9151825053 - parameters are 2.10984372196 8.11091708099 3.4343125982\n",
      "Iteration 800 - loss is 26.745961224 - parameters are 2.1111356045 8.1175494675 3.43749715139\n",
      "Iteration 900 - loss is 26.7079876975 - parameters are 2.10317677116 8.10898060683 3.43881490361\n",
      "Iteration 1000 - loss is 34.0247859958 - parameters are 2.11496107986 8.12152517463 3.44324228927\n",
      "Epoch 72\n",
      "Iteration 100 - loss is 34.1292563081 - parameters are 2.08922381826 8.09717591929 3.44281530646\n",
      "Iteration 200 - loss is 36.3531588116 - parameters are 2.10355831142 8.10851517617 3.44780273432\n",
      "Iteration 300 - loss is 23.0111684006 - parameters are 2.09349594277 8.1012083146 3.44874476003\n",
      "Iteration 400 - loss is 23.5997044458 - parameters are 2.10241577876 8.10906227927 3.45194265181\n",
      "Iteration 500 - loss is 26.0082658285 - parameters are 2.09232958019 8.09694757767 3.45260286206\n",
      "Iteration 600 - loss is 27.7971343982 - parameters are 2.10952292407 8.11063749897 3.45733919755\n",
      "Iteration 700 - loss is 24.3710172707 - parameters are 2.10805557131 8.10918925086 3.45929103849\n",
      "Iteration 800 - loss is 26.0938794766 - parameters are 2.10934779137 8.11580145253 3.46242880792\n",
      "Iteration 900 - loss is 26.0927467904 - parameters are 2.10149449094 8.10730278651 3.46371597334\n",
      "Iteration 1000 - loss is 33.3364124133 - parameters are 2.11317096422 8.11972059297 3.46808439471\n",
      "Epoch 73\n",
      "Iteration 100 - loss is 33.3413349015 - parameters are 2.08768927015 8.09562126151 3.46764458576\n",
      "Iteration 200 - loss is 35.5179403188 - parameters are 2.10183108487 8.10678705844 3.47255394084\n",
      "Iteration 300 - loss is 22.4826322724 - parameters are 2.09189730737 8.09959443648 3.47347496153\n",
      "Iteration 400 - loss is 23.0831530717 - parameters are 2.10073560001 8.10742422459 3.47662602494\n",
      "Iteration 500 - loss is 25.4815064558 - parameters are 2.09067290384 8.0953217318 3.47725531408\n",
      "Iteration 600 - loss is 27.1426709368 - parameters are 2.10777373476 8.10895313881 3.48193498253\n",
      "Iteration 700 - loss is 23.8456128908 - parameters are 2.10629912314 8.10749061194 3.48384690248\n",
      "Iteration 800 - loss is 25.463863077 - parameters are 2.10759160447 8.11408286432 3.48693872474\n",
      "Iteration 900 - loss is 25.4984723099 - parameters are 2.09984203094 8.1056532867 3.48819586856\n",
      "Iteration 1000 - loss is 32.6699931395 - parameters are 2.11141244621 8.11794630325 3.49250637282\n",
      "Epoch 74\n",
      "Iteration 100 - loss is 32.5789782124 - parameters are 2.08618208594 8.0940929344 3.49205400839\n",
      "Iteration 200 - loss is 34.7100176147 - parameters are 2.10013429848 8.10508777967 3.49688664837\n",
      "Iteration 300 - loss is 21.9722811804 - parameters are 2.09032712243 8.0980077528 3.49778708269\n",
      "Iteration 400 - loss is 22.5848476483 - parameters are 2.09908508174 8.10581357861 3.50089213503\n",
      "Iteration 500 - loss is 24.9717592865 - parameters are 2.08904559884 8.09372334367 3.5014910875\n",
      "Iteration 600 - loss is 26.5102275949 - parameters are 2.10605532068 8.10729696839 3.50611507937\n",
      "Iteration 700 - loss is 23.3383094468 - parameters are 2.10457375675 8.10582063919 3.50798782996\n",
      "Iteration 800 - loss is 24.8551425451 - parameters are 2.10586642648 8.11239317659 3.51103452498\n",
      "Iteration 900 - loss is 24.9244309374 - parameters are 2.09821880735 8.10403159866 3.51226220063\n",
      "Iteration 1000 - loss is 32.024785324 - parameters are 2.10968491133 8.11620176659 3.51651581437\n",
      "Epoch 75\n",
      "Iteration 100 - loss is 31.8413166851 - parameters are 2.0847017249 8.0925904623 3.51605115847\n",
      "Iteration 200 - loss is 33.9284592733 - parameters are 2.09846736159 8.10341683208 3.52080841522\n",
      "Iteration 300 - loss is 21.4794782778 - parameters are 2.08878482786 8.09644777701 3.52168867225\n",
      "Iteration 400 - loss is 22.1041417161 - parameters are 2.09746364692 8.10422985639 3.52474851513\n",
      "Iteration 500 - loss is 24.4784458413 - parameters are 2.08744709027 8.09215191972 3.52531770282\n",
      "Iteration 600 - loss is 25.8990408954 - parameters are 2.10436708648 8.10566848882 3.52988698958\n",
      "Iteration 700 - loss is 22.8484711707 - parameters are 2.10287886555 8.10417881802 3.53172130641\n",
      "Iteration 800 - loss is 24.2669764509 - parameters are 2.10417165404 8.11073187345 3.53472367783\n",
      "Iteration 900 - loss is 24.3699161094 - parameters are 2.09662424963 8.10243722379 3.53592242725\n",
      "Iteration 1000 - loss is 31.4000727858 - parameters are 2.10798775893 8.11448645465 3.54012015695\n",
      "Epoch 76\n",
      "Iteration 100 - loss is 31.1275119114 - parameters are 2.08324765872 8.09111337908 3.5396434671\n",
      "Iteration 200 - loss is 33.1723672689 - parameters are 2.09682969677 8.10177371768 3.54432664727\n",
      "Iteration 300 - loss is 21.0036098732 - parameters are 2.08726987636 8.09491403211 3.54518712675\n",
      "Iteration 400 - loss is 21.6404124318 - parameters are 2.0958707315 8.10267258238 3.54820254647\n",
      "Iteration 500 - loss is 24.0010084179 - parameters are 2.08587681624 8.09060697623 3.54874252907\n",
      "Iteration 600 - loss is 25.3083750053 - parameters are 2.10270845011 8.1040672109 3.55325806361\n",
      "Iteration 700 - loss is 22.3754855095 - parameters are 2.10121385663 8.10256464403 3.5550546666\n",
      "Iteration 800 - loss is 23.6986503297 - parameters are 2.10250669739 8.10909844919 3.55801350216\n",
      "Iteration 900 - loss is 23.8342469837 - parameters are 2.09505780012 8.10086967332 3.55918385609\n",
      "Iteration 1000 - loss is 30.7951649892 - parameters are 2.1063204018 8.11279984941 3.56332668858\n",
      "Epoch 77\n",
      "Iteration 100 - loss is 30.4367554432 - parameters are 2.08181937117 8.08966122793 3.56283821604\n",
      "Iteration 200 - loss is 32.440875704 - parameters are 2.09522073953 8.10015794804 3.56744860158\n",
      "Iteration 300 - loss is 20.5440845406 - parameters are 2.08578173304 8.09340605052 3.56828969419\n",
      "Iteration 400 - loss is 21.1930596598 - parameters are 2.09430578408 8.10114129027 3.57126146204\n",
      "Iteration 500 - loss is 23.5389092955 - parameters are 2.08433422755 8.08908803904 3.57177278732\n",
      "Iteration 600 - loss is 24.7375206752 - parameters are 2.10107884249 8.10249265493 3.57623550438\n",
      "Iteration 700 - loss is 21.9187622286 - parameters are 2.09957815044 8.10097762284 3.57799509818\n",
      "Iteration 800 - loss is 23.1494756428 - parameters are 2.10087097998 8.10749240803 3.58091117011\n",
      "Iteration 900 - loss is 23.3167674473 - parameters are 2.0935189137 8.0993284682 3.58205364834\n",
      "Iteration 1000 - loss is 30.209396064 - parameters are 2.10468226585 8.11114144293 3.58614255123\n",
      "Epoch 78\n",
      "Iteration 100 - loss is 29.7682676556 - parameters are 2.08041635776 8.08823356112 3.58564254116\n",
      "Iteration 200 - loss is 31.7331495887 - parameters are 2.0936399379 8.09856904409 3.59018138987\n",
      "Iteration 300 - loss is 20.1003322669 - parameters are 2.08431987515 8.09192337379 3.59100347745\n",
      "Iteration 400 - loss is 20.7615051018 - parameters are 2.09276826558 8.09963552275 3.59393235008\n",
      "Iteration 500 - loss is 23.0916299725 - parameters are 2.08281878736 8.08759464339 3.59441555418\n",
      "Iteration 600 - loss is 24.1857942229 - parameters are 2.09947770712 8.10094435043 3.59882637074\n",
      "Iteration 700 - loss is 21.4777325523 - parameters are 2.09797118037 8.09941726978 3.6005496451\n",
      "Iteration 800 - loss is 22.6187887808 - parameters are 2.09926393814 8.10591326387 3.60342371046\n",
      "Iteration 900 - loss is 22.8168451662 - parameters are 2.09200705747 8.09781313876 3.60453882211\n",
      "Iteration 1000 - loss is 29.6421238649 - parameters are 2.10307278972 8.10951073714 3.60857474425\n",
      "Epoch 79\n",
      "Iteration 100 - loss is 29.1212966552 - parameters are 2.07903812546 8.08682993984 3.60806343589\n",
      "Iteration 200 - loss is 31.0483836704 - parameters are 2.09208675218 8.09700653592 3.61253198192\n",
      "Iteration 300 - loss is 19.671803634 - parameters are 2.08288379169 8.09046555245 3.61333543771\n",
      "Iteration 400 - loss is 20.3451914613 - parameters are 2.0912576489 8.09815483132 3.61622215743\n",
      "Iteration 500 - loss is 22.6586704352 - parameters are 2.0813299708 8.08612633366 3.61667776518\n",
      "Iteration 600 - loss is 23.6525365582 - parameters are 2.09790449978 8.09942183602 3.62103758084\n",
      "Iteration 700 - loss is 21.0518483402 - parameters are 2.09639239247 8.09788310974 3.62272521101\n",
      "Iteration 800 - loss is 22.1059501083 - parameters are 2.09768502072 8.10436054014 3.62555801202\n",
      "Iteration 900 - loss is 22.3338706745 - parameters are 2.0905217104 8.09632322459 3.62664625579\n",
      "Iteration 1000 - loss is 29.0927290696 - parameters are 2.10149142445 8.10790724359 3.63063012769\n",
      "Epoch 80\n",
      "Iteration 100 - loss is 28.4951172331 - parameters are 2.07768419232 8.08544993393 3.63010775449\n",
      "Iteration 200 - loss is 30.3858013108 - parameters are 2.09056065453 8.09546996257 3.6345072089\n",
      "Iteration 300 - loss is 19.257969034 - parameters are 2.08147298313 8.08903214578 3.63529239776\n",
      "Iteration 400 - loss is 19.9435816429 - parameters are 2.08977341859 8.09669877608 3.63813769285\n",
      "Iteration 500 - loss is 22.2395484564 - parameters are 2.07986726473 8.08468266319 3.63856621803\n",
      "Iteration 600 - loss is 23.1371122481 - parameters are 2.09635868818 8.09792465918 3.64287591539\n",
      "Iteration 700 - loss is 20.6405812969 - parameters are 2.09484124507 8.09637467693 3.64452856244\n",
      "Iteration 800 - loss is 21.6103430477 - parameters are 2.09613368876 8.10283376951 3.64732082685\n",
      "Iteration 900 - loss is 21.8672565005 - parameters are 2.08906236304 8.09485827429 3.64838269129\n",
      "Iteration 1000 - loss is 28.5606143146 - parameters are 2.09993763319 8.10633048329 3.65231542548\n",
      "Epoch 81\n",
      "Iteration 100 - loss is 27.8890298606 - parameters are 2.07635408726 8.08409312175 3.65178221533\n",
      "Iteration 200 - loss is 29.7446534085 - parameters are 2.08906112874 8.09395887186 3.65611376653\n",
      "Iteration 300 - loss is 18.8583179172 - parameters are 2.0800869611 8.08762272164 3.65688104517\n",
      "Iteration 400 - loss is 19.5561579839 - parameters are 2.08831507056 8.09526692557 3.65968563021\n",
      "Iteration 500 - loss is 21.833798923 - parameters are 2.07843016737 8.08326319408 3.66008757581\n",
      "Iteration 600 - loss is 22.6389086198 - parameters are 2.09483975169 8.09645237603 3.66434802086\n",
      "Iteration 700 - loss is 20.2434222144 - parameters are 2.09331720845 8.09489151464 3.66596633205\n",
      "Iteration 800 - loss is 21.1313732008 - parameters are 2.09460941516 8.10133249374 3.66871877345\n",
      "Iteration 900 - loss is 21.4164363287 - parameters are 2.08762851717 8.09341784527 3.66975473717\n",
      "Iteration 1000 - loss is 28.0452033651 - parameters are 2.09841089083 8.10477998645 3.67363722866\n",
      "Epoch 82\n",
      "Iteration 100 - loss is 27.302359725 - parameters are 2.0750473497 8.08275908994 3.67309340399\n",
      "Iteration 200 - loss is 29.1242173654 - parameters are 2.08758766986 8.09247282015 3.67735821825\n",
      "Iteration 300 - loss is 18.4723580705 - parameters are 2.07872524807 8.08623685625 3.67810793543\n",
      "Iteration 400 - loss is 19.182421517 - parameters are 2.08688211177 8.09385885658 3.68087251156\n",
      "Iteration 500 - loss is 21.4409731903 - parameters are 2.07701818803 8.08186749697 3.68124837007\n",
      "Iteration 600 - loss is 22.1573348999 - parameters are 2.09334718098 8.09500455121 3.68546041252\n",
      "Iteration 700 - loss is 19.8598802455 - parameters are 2.09181976458 8.09343317509 3.68704502164\n",
      "Iteration 800 - loss is 20.6684675063 - parameters are 2.09311168439 8.09985626346 3.68975833978\n",
      "Iteration 900 - loss is 20.9808641959 - parameters are 2.08621968557 8.09200150357 3.6907688717\n",
      "Iteration 1000 - loss is 27.5459403195 - parameters are 2.09691068373 8.10325529231 3.69460199835\n",
      "Epoch 83\n",
      "Iteration 100 - loss is 26.7344558049 - parameters are 2.07376352932 8.08144743326 3.6940477763\n",
      "Iteration 200 - loss is 28.5237960941 - parameters are 2.08613978394 8.09101137224 3.69824699821\n",
      "Iteration 300 - loss is 18.0996149239 - parameters are 2.0773873771 8.08487413403 3.69897949496\n",
      "Iteration 400 - loss is 18.821891263 - parameters are 2.08547405996 8.09247415393 3.7017047502\n",
      "Iteration 500 - loss is 21.0606384632 - parameters are 2.07563084678 8.08049515088 3.70205500386\n",
      "Iteration 600 - loss is 21.6918213889 - parameters are 2.0918804778 8.09358075763 3.7062194775\n",
      "Iteration 700 - loss is 19.4894822068 - parameters are 2.09034840673 8.09199921919 3.70777100519\n",
      "Iteration 800 - loss is 20.2210734307 - parameters are 2.09163999218 8.09840463797 3.71044588629\n",
      "Iteration 900 - loss is 20.5600137202 - parameters are 2.08483539167 8.09060882363 3.71143144588\n",
      "Iteration 1000 - loss is 27.0622888459 - parameters are 2.09543650941 8.10175594894 3.71521606875\n",
      "Epoch 84\n",
      "Iteration 100 - loss is 26.1846899813 - parameters are 2.07250218579 8.08015775438 3.71465166134\n",
      "Iteration 200 - loss is 27.9427170655 - parameters are 2.08471698773 8.0895741011 3.71878641426\n",
      "Iteration 300 - loss is 17.7396308867 - parameters are 2.07607289153 8.08353414741 3.71950202408\n",
      "Iteration 400 - loss is 18.4741035523 - parameters are 2.08409044333 8.09111241037 3.7221886336\n",
      "Iteration 500 - loss is 20.6923772019 - parameters are 2.07426767424 8.07914574301 3.72251375463\n",
      "Iteration 600 - loss is 21.2418186686 - parameters are 2.09043915461 8.09218057632 3.72663147767\n",
      "Iteration 700 - loss is 19.1317719098 - parameters are 2.08890263927 8.09058921639 3.72815053174\n",
      "Iteration 800 - loss is 19.7886581936 - parameters are 2.09019384521 8.09697718504 3.73078764881\n",
      "Iteration 900 - loss is 20.1533773613 - parameters are 2.08347516929 8.08923938817 3.73174868628\n",
      "Iteration 1000 - loss is 26.5937314493 - parameters are 2.09398787626 8.10028151302 3.73548565005\n",
      "Epoch 85\n",
      "Iteration 100 - loss is 25.652456186 - parameters are 2.07126288848 8.07888966375 3.73491126428\n",
      "Iteration 200 - loss is 27.3803313942 - parameters are 2.08331880842 8.08816058776 3.73898265081\n",
      "Iteration 300 - loss is 17.3919647092 - parameters are 2.07478134473 8.08221649667 3.73968169984\n",
      "Iteration 400 - loss is 18.1386113728 - parameters are 2.08273080034 8.08977322634 3.74233032625\n",
      "Iteration 500 - loss is 20.3357865513 - parameters are 2.07292821124 8.07781886854 3.7426307771\n",
      "Iteration 600 - loss is 20.8067968417 - parameters are 2.08902273438 8.09080359627 3.74670255252\n",
      "Iteration 700 - loss is 18.7863095193 - parameters are 2.08748197729 8.08920274442 3.74818972824\n",
      "Iteration 800 - loss is 19.3707080226 - parameters are 2.08877276085 8.09557348075 3.75078974137\n",
      "Iteration 900 - loss is 19.7604657101 - parameters are 2.0821385624 8.08789278792 3.75172669792\n",
      "Iteration 1000 - loss is 26.1397687678 - parameters are 2.09256430325 8.09883154968 3.75541683119\n",
      "Epoch 86\n",
      "Iteration 100 - loss is 25.1371695822 - parameters are 2.07004521623 8.07764277938 3.75483266922\n",
      "Iteration 200 - loss is 26.8360129608 - parameters are 2.08194478337 8.0867704211 3.75884177163\n",
      "Iteration 300 - loss is 17.0561908704 - parameters are 2.07351229982 8.08092078974 3.75952457885\n",
      "Iteration 400 - loss is 17.8149837448 - parameters are 2.08139467935 8.08845620986 3.76213587244\n",
      "Iteration 500 - loss is 19.9904777938 - parameters are 2.07161200856 8.07651413047 3.76241210605\n",
      "Iteration 600 - loss is 20.3862448013 - parameters are 2.08763075026 8.08944941421 3.76643872188\n",
      "Iteration 700 - loss is 18.4526709372 - parameters are 2.0860859464 8.08783938921 3.76789460233\n",
      "Iteration 800 - loss is 18.9667274391 - parameters are 2.08737626688 8.0941931093 3.77045815894\n",
      "Iteration 900 - loss is 19.3808068077 - parameters are 2.08082512481 8.08656862153 3.77137146696\n",
      "Iteration 1000 - loss is 25.6999188983 - parameters are 2.0911653197 8.09740563233 3.77501558264\n",
      "Epoch 87\n",
      "Iteration 100 - loss is 24.6382657786 - parameters are 2.06884875709 8.07641672669 3.77442184191\n",
      "Iteration 200 - loss is 26.3091575685 - parameters are 2.08059445981 8.0854031977 3.77836972252\n",
      "Iteration 300 - loss is 16.7318989898 - parameters are 2.07226532944 8.07964664205 3.77903659996\n",
      "Iteration 400 - loss is 17.5028051205 - parameters are 2.08008163846 8.08716097631 3.78161119898\n",
      "Iteration 500 - loss is 19.6560758238 - parameters are 2.07031862673 8.07523113948 3.78186365898\n",
      "Iteration 600 - loss is 19.9796695304 - parameters are 2.08626274539 8.08811763451 3.78584588865\n",
      "Iteration 700 - loss is 18.1304472118 - parameters are 2.08471408243 8.0864987446 3.78727104498\n",
      "Iteration 800 - loss is 18.5762385731 - parameters are 2.0860039012 8.09283566282 3.78979878014\n",
      "Iteration 900 - loss is 19.0139454911 - parameters are 2.07953441997 8.08526649533 3.7906888634\n",
      "Iteration 1000 - loss is 25.2737167475 - parameters are 2.08979046496 8.09600334245 3.79428775904\n",
      "Epoch 88\n",
      "Iteration 100 - loss is 24.1552000745 - parameters are 2.06767310811 8.07521113836 3.79368463237\n",
      "Iteration 200 - loss is 25.7991821332 - parameters are 2.07926739466 8.0840585217 3.79757233405\n",
      "Iteration 300 - loss is 16.4186932633 - parameters are 2.07104001549 8.07839367638 3.79822358691\n",
      "Iteration 400 - loss is 17.2016748073 - parameters are 2.07879124519 8.08588714834 3.80076211782\n",
      "Iteration 500 - loss is 19.3322186425 - parameters are 2.06904763571 8.07396951369 3.80099123876\n",
      "Iteration 600 - loss is 19.5865954281 - parameters are 2.08491827256 8.08680786897 3.8049298414\n",
      "Iteration 700 - loss is 17.81924397 - parameters are 2.08336593114 8.08518041224 3.8063248331\n",
      "Iteration 800 - loss is 18.1987805045 - parameters are 2.08465521162 8.0915007412 3.8088173698\n",
      "Iteration 900 - loss is 18.6594427649 - parameters are 2.07826602069 8.08398602322 3.80968464367\n",
      "Iteration 1000 - loss is 24.8607134098 - parameters are 2.0884392882 8.09462426942 3.81323910178\n",
      "Epoch 89\n",
      "Iteration 100 - loss is 23.6874467345 - parameters are 2.06651787505 8.07402565413 3.81262677753\n",
      "Iteration 200 - loss is 25.3055239056 - parameters are 2.07796315423 8.08273600457 3.81645532402\n",
      "Iteration 300 - loss is 16.1161919207 - parameters are 2.0698359489 8.07716152268 3.81709125092\n",
      "Iteration 400 - loss is 16.9112064142 - parameters are 2.07752307628 8.08463435564 3.81959432863\n",
      "Iteration 500 - loss is 19.0185568739 - parameters are 2.06779861471 8.07272887856 3.81980053619\n",
      "Iteration 600 - loss is 19.2065636638 - parameters are 2.08359689408 8.08551973666 3.82369625694\n",
      "Iteration 700 - loss is 17.5186808729 - parameters are 2.08204104803 8.08388400141 3.82506163214\n",
      "Iteration 800 - loss is 17.833908631 - parameters are 2.08332975556 8.09018795194 3.82751958152\n",
      "Iteration 900 - loss is 18.3168751991 - parameters are 2.07701950889 8.08272682643 3.82836445315\n",
      "Iteration 1000 - loss is 24.4604755697 - parameters are 2.08711134815 8.09326801037 3.83187524154\n",
      "Epoch 90\n",
      "Iteration 100 - loss is 23.2344982915 - parameters are 2.0653826722 8.07285992069 3.83125390372\n",
      "Iteration 200 - loss is 24.8276397242 - parameters are 2.076681314 8.08143526506 3.83502430008\n",
      "Iteration 300 - loss is 15.8240267054 - parameters are 2.06865272938 8.07594981793 3.83564519314\n",
      "Iteration 400 - loss is 16.6310273198 - parameters are 2.07627671747 8.08340223488 3.83811342128\n",
      "Iteration 500 - loss is 18.7147532988 - parameters are 2.0665711519 8.07150886671 3.83829713248\n",
      "Iteration 600 - loss is 18.839131556 - parameters are 2.08229818142 8.0842528638 3.84215070276\n",
      "Iteration 700 - loss is 17.2283910919 - parameters are 2.08073899804 8.08260912883 3.84348699849\n",
      "Iteration 800 - loss is 17.4811940616 - parameters are 2.08202709983 8.08889690998 3.84591096015\n",
      "Iteration 900 - loss is 17.9858343496 - parameters are 2.0757944754 8.08148853345 3.84673382864\n",
      "Iteration 1000 - loss is 24.0725849275 - parameters are 2.08580621286 8.09193417002 3.85020170074\n",
      "Epoch 91\n",
      "Iteration 100 - loss is 22.7958648776 - parameters are 2.06426712217 8.07171359151 3.84957152913\n",
      "Iteration 200 - loss is 24.3650052967 - parameters are 2.07542145841 8.08015592895 3.85328476209\n",
      "Iteration 300 - loss is 15.5418423738 - parameters are 2.06748996525 8.07475820598 3.85389090715\n",
      "Iteration 400 - loss is 16.3607781615 - parameters are 2.07505176324 8.08219042946 3.85632487827\n",
      "Iteration 500 - loss is 18.4204824078 - parameters are 2.06536484423 8.07030911776 3.85648650168\n",
      "Iteration 600 - loss is 18.4838719757 - parameters are 2.08102171507 8.08300688359 3.86029863949\n",
      "Iteration 700 - loss is 16.948020807 - parameters are 2.07945935534 8.08135541852 3.86160638194\n",
      "Iteration 800 - loss is 17.1402230335 - parameters are 2.0807468204 8.08762723751 3.86399694414\n",
      "Iteration 900 - loss is 17.665926202 - parameters are 2.07459051975 8.0802707798 3.86479820077\n",
      "Iteration 1000 - loss is 23.6966376478 - parameters are 2.08452345945 8.0906223605 3.86822389589\n",
      "Epoch 92\n",
      "Iteration 100 - loss is 22.3710735803 - parameters are 2.06317085563 8.07058632668 3.86758506615\n",
      "Iteration 200 - loss is 23.9171145105 - parameters are 2.0741831806 8.07889762896 3.8712421045\n",
      "Iteration 300 - loss is 15.2692962155 - parameters are 2.06634727315 8.07358633741 3.87183378127\n",
      "Iteration 400 - loss is 16.100112345 - parameters are 2.07384781658 8.08099858948 3.87423407708\n",
      "Iteration 500 - loss is 18.1354299718 - parameters are 2.06417929719 8.06912927817 3.87437401305\n",
      "Iteration 600 - loss is 18.140372774 - parameters are 2.0797670843 8.08178143606 3.87814542322\n",
      "Iteration 700 - loss is 16.677228724 - parameters are 2.07820170309 8.08012250163 3.879425128\n",
      "Iteration 800 - loss is 16.8105963519 - parameters are 2.07948850218 8.08637856386 3.88178286793\n",
      "Iteration 900 - loss is 17.3567706379 - parameters are 2.07340724989 8.07907320792 3.8825628963\n",
      "Iteration 1000 - loss is 23.3322438298 - parameters are 2.08326267393 8.08933220117 3.88594713999\n",
      "Epoch 93\n",
      "Iteration 100 - loss is 21.9596678248 - parameters are 2.06209351115 8.0694777928 3.88529982378\n",
      "Iteration 200 - loss is 23.4834787689 - parameters are 2.07296608223 8.07766000459 3.88890161873\n",
      "Iteration 300 - loss is 15.0060575906 - parameters are 2.06522427787 8.07243386938 3.88947910093\n",
      "Iteration 400 - loss is 15.8486955724 - parameters are 2.07266448885 8.07982637149 3.89184629254\n",
      "Iteration 500 - loss is 17.8592926288 - parameters are 2.0630141246 8.06796900112 3.89196493331\n",
      "Iteration 600 - loss is 17.8082362307 - parameters are 2.07853388691 8.08057616793 3.89569630783\n",
      "Iteration 700 - loss is 16.415685611 - parameters are 2.07696563322 8.07891001631 3.8969484802\n",
      "Iteration 800 - loss is 16.4919288529 - parameters are 2.07825173875 8.08515052533 3.89927396422\n",
      "Iteration 900 - loss is 17.0580009214 - parameters are 2.07224428204 8.07789546701 3.90003314043\n",
      "Iteration 1000 - loss is 22.9790269979 - parameters are 2.08202345091 8.08806331853 3.90337664474\n",
      "Epoch 94\n",
      "Iteration 100 - loss is 21.5612067792 - parameters are 2.061034735 8.0683876628 3.9027210098\n",
      "Iteration 200 - loss is 23.0636263546 - parameters are 2.07176977325 8.07644270199 3.90626849535\n",
      "Iteration 300 - loss is 14.751807487 - parameters are 2.06412061216 8.07130046551 3.90683205085\n",
      "Iteration 400 - loss is 15.6062053891 - parameters are 2.07150139949 8.07867343844 3.90916669897\n",
      "Iteration 500 - loss is 17.591777488 - parameters are 2.06186894839 8.06682794635 3.90926442894\n",
      "Iteration 600 - loss is 17.4870785261 - parameters are 2.07732172906 8.07939073247 3.91295644716\n",
      "Iteration 700 - loss is 16.1630738526 - parameters are 2.07575074621 8.07771760751 3.91418158229\n",
      "Iteration 800 - loss is 16.1838488862 - parameters are 2.07703613221 8.08394276503 3.91647536616\n",
      "Iteration 900 - loss is 16.7692632064 - parameters are 2.07110124045 8.07673721288 3.91721405898\n",
      "Iteration 1000 - loss is 22.6366236128 - parameters are 2.08080539348 8.08681534604 3.92051752275\n",
      "Epoch 95\n",
      "Iteration 100 - loss is 21.1752647838 - parameters are 2.05999418091 8.06731561581 3.91985373303\n",
      "Iteration 200 - loss is 22.6571018161 - parameters are 2.07059387171 8.0752453738 3.92334782631\n",
      "Iteration 300 - loss is 14.5062380938 - parameters are 2.0630359165 8.07018579571 3.92389771731\n",
      "Iteration 400 - loss is 15.3723307484 - parameters are 2.07035817588 8.07753945952 3.92620037247\n",
      "Iteration 500 - loss is 17.3326017475 - parameters are 2.06074339841 8.06570578 3.92627756833\n",
      "Iteration 600 - loss is 17.1765292319 - parameters are 2.07613022504 8.07822478937 3.92993089727\n",
      "Iteration 700 - loss is 15.9190870229 - parameters are 2.0745566509 8.0765449269 3.93112948046\n",
      "Iteration 800 - loss is 15.8859978188 - parameters are 2.07584129292 8.08275493277 3.93339210955\n",
      "Iteration 900 - loss is 16.4902160625 - parameters are 2.06997775724 8.07559810781 3.93411068059\n",
      "Iteration 1000 - loss is 22.304682601 - parameters are 2.07960811291 8.08558792393 3.93737478971\n",
      "Epoch 96\n",
      "Iteration 100 - loss is 20.8014308011 - parameters are 2.05897150996 8.06626133706 3.93670300548\n",
      "Iteration 200 - loss is 22.2634653789 - parameters are 2.06943800352 8.07406767904 3.94014460708\n",
      "Iteration 300 - loss is 14.2690523912 - parameters are 2.06196983893 8.06908953608 3.94068109021\n",
      "Iteration 400 - loss is 15.146771593 - parameters are 2.06923445312 8.07642410999 3.94295229296\n",
      "Iteration 500 - loss is 17.081492329 - parameters are 2.05963711227 8.06460217452 3.9430093239\n",
      "Iteration 600 - loss is 16.8762308225 - parameters are 2.07495899709 8.07707800461 3.94662461846\n",
      "Iteration 700 - loss is 15.6834294735 - parameters are 2.07338296425 8.07539163268 3.94779712538\n",
      "Iteration 800 - loss is 15.5980295578 - parameters are 2.07466683934 8.08158668485 3.9500291349\n",
      "Iteration 900 - loss is 16.2205300202 - parameters are 2.06887347215 8.07447782043 3.95072793877\n",
      "Iteration 1000 - loss is 21.9828649029 - parameters are 2.07843122854 8.08438069915 3.95395336648\n",
      "Epoch 97\n",
      "Iteration 100 - loss is 20.4393078886 - parameters are 2.05796639032 8.06522451771 3.95327374439\n",
      "Iteration 200 - loss is 21.882292379 - parameters are 2.06830180235 8.07290928297 3.95666373872\n",
      "Iteration 300 - loss is 14.0399637568 - parameters are 2.06092203485 8.06801136875 3.95718706518\n",
      "Iteration 400 - loss is 14.9292384526 - parameters are 2.06812987385 8.07532707112 3.95942734632\n",
      "Iteration 500 - loss is 16.8381855244 - parameters are 2.05854973506 8.0635168085 3.95946457419\n",
      "Iteration 600 - loss is 16.5858382055 - parameters are 2.0738076752 8.07595005029 3.96304247742\n",
      "Iteration 700 - loss is 15.4558159387 - parameters are 2.07222931114 8.07425738946 3.96418937431\n",
      "Iteration 800 - loss is 15.3196100916 - parameters are 2.07351239778 8.08043768402 3.96639128954\n",
      "Iteration 900 - loss is 15.9598871329 - parameters are 2.0677880324 8.07337602556 3.967070674\n",
      "Iteration 1000 - loss is 21.6708430385 - parameters are 2.07727436749 8.08319332515 3.97025808113\n",
      "Epoch 98\n",
      "Iteration 100 - loss is 20.08851269 - parameters are 2.05697849712 8.06420485476 3.96957077432\n",
      "Iteration 200 - loss is 21.5131727184 - parameters are 2.06718490933 8.07176985696 3.9729100299\n",
      "Iteration 300 - loss is 13.8186955869 - parameters are 2.05989216685 8.06695098179 3.97342044565\n",
      "Iteration 400 - loss is 14.719452057 - parameters are 2.06704408805 8.07424803003 3.97563032639\n",
      "Iteration 500 - loss is 16.6024266581 - parameters are 2.05748091927 8.06244936654 3.97564810585\n",
      "Iteration 600 - loss is 16.3050182698 - parameters are 2.07267589692 8.07484060459 3.97918924919\n",
      "Iteration 700 - loss is 15.2359711556 - parameters are 2.07109532424 8.07314186812 3.98031099309\n",
      "Iteration 800 - loss is 15.0504170496 - parameters are 2.07237760227 8.07930759925 3.98248332957\n",
      "Iteration 900 - loss is 15.7079805564 - parameters are 2.06672109252 8.07229240409 3.98314363568\n",
      "Iteration 1000 - loss is 21.368300689 - parameters are 2.07613716456 8.08202546177 3.98629367093\n",
      "Epoch 99\n",
      "Iteration 100 - loss is 19.7486749475 - parameters are 2.05600751227 8.06320205088 3.98559882914\n",
      "Iteration 200 - loss is 21.1557103406 - parameters are 2.06608697298 8.07064907836 3.98888819894\n",
      "Iteration 300 - loss is 13.6049809323 - parameters are 2.05887990454 8.06590806905 3.98938594474\n",
      "Iteration 400 - loss is 14.517142964 - parameters are 2.0659767529 8.07318667958 3.99156593692\n",
      "Iteration 500 - loss is 16.3739697604 - parameters are 2.05643032454 8.06139953915 3.99156461564\n",
      "Iteration 600 - loss is 16.033449451 - parameters are 2.07156330719 8.07374935153 3.99506961915\n",
      "Iteration 700 - loss is 15.0236294988 - parameters are 2.06998064374 8.07204474569 3.99616665809\n",
      "Iteration 800 - loss is 14.7901392778 - parameters are 2.07126209433 8.07819610568 3.99830992184\n",
      "Iteration 900 - loss is 15.4645141448 - parameters are 2.0656723141 8.07122664287 3.9989514841\n",
      "Iteration 1000 - loss is 21.0749322958 - parameters are 2.07501926199 8.08087677514 4.00206478427\n",
      "Epoch 100\n",
      "Iteration 100 - loss is 19.4194370317 - parameters are 2.0550531243 8.06221581434 4.00136255391\n",
      "Iteration 200 - loss is 20.8095227274 - parameters are 2.06500764894 8.06954663042 4.00460287566\n",
      "Iteration 300 - loss is 13.398562148 - parameters are 2.05788492435 8.06488233006 4.00508818724\n",
      "Iteration 400 - loss is 14.3220512023 - parameters are 2.06492753256 8.07214271823 4.00723879353\n",
      "Iteration 500 - loss is 16.1525772549 - parameters are 2.05539761752 8.0603670226 4.00721871231\n",
      "Iteration 600 - loss is 15.770821314 - parameters are 2.07046955815 8.07267598096 4.01068818488\n",
      "Iteration 700 - loss is 14.8185346295 - parameters are 2.06888491723 8.07096570521 4.01176095813\n",
      "Iteration 800 - loss is 14.5384764317 - parameters are 2.07016552281 8.07710288444 4.01387564583\n",
      "Iteration 900 - loss is 15.2292020613 - parameters are 2.0646413657 8.07017843456 4.01449879234\n",
      "Iteration 1000 - loss is 20.7904426736 - parameters are 2.07392030931 8.07974693751 4.01757598259\n",
      "Epoch 101\n",
      "Iteration 100 - loss is 19.1004534896 - parameters are 2.05411502818 8.06124585884 4.01686650682\n",
      "Iteration 200 - loss is 20.4742404134 - parameters are 2.06394659985 8.0684622021 4.0200586033\n",
      "Iteration 300 - loss is 13.1991905567 - parameters are 2.0569069094 8.06387346992 4.02053171151\n",
      "Iteration 400 - loss is 14.133925927 - parameters are 2.06389609804 8.07111584996 4.02265342554\n",
      "Iteration 500 - loss is 15.938019657 - parameters are 2.0543824717 8.05935151882 4.02261491849\n",
      "Iteration 600 - loss is 15.5168341512 - parameters are 2.069394309 8.07162018837 4.02604945811\n",
      "Iteration 700 - loss is 14.6204391578 - parameters are 2.06780779948 8.06990443558 4.02709839633\n",
      "Iteration 800 - loss is 14.2951385845 - parameters are 2.06908754371 8.07602762254 4.02918499552\n",
      "Iteration 900 - loss is 15.0017684046 - parameters are 2.06362792265 8.06914747752 4.02979004812\n",
      "Iteration 1000 - loss is 20.5145466391 - parameters are 2.07283996315 8.07863562712 4.03283174218\n",
      "Epoch 102\n",
      "Iteration 100 - loss is 18.7913906098 - parameters are 2.05319292518 8.06029190347 4.03211516103\n",
      "Iteration 200 - loss is 20.1495065201 - parameters are 2.06290349519 8.06739548801 4.03525984036\n",
      "Iteration 300 - loss is 13.0066261246 - parameters are 2.0559455493 8.06288119915 4.03572097124\n",
      "Iteration 400 - loss is 13.9525250891 - parameters are 2.06288212704 8.07010578415 4.03781427783\n",
      "Iteration 500 - loss is 15.7300752844 - parameters are 2.05338456721 8.05835273525 4.03775767252\n",
      "Iteration 600 - loss is 15.2711985962 - parameters are 2.06833722578 8.07058167481 4.04115786645\n",
      "Iteration 700 - loss is 14.4291043183 - parameters are 2.06674895232 8.06886063151 4.04218339189\n",
      "Iteration 800 - loss is 14.0598458499 - parameters are 2.06802782002 8.07497001275 4.04424238118\n",
      "Iteration 900 - loss is 14.7819468493 - parameters are 2.06263166688 8.06813347569 4.04482965558\n",
      "Iteration 1000 - loss is 20.2469686535 - parameters are 2.07177788709 8.07754252814 4.04783645603\n",
      "Epoch 103\n",
      "Iteration 100 - loss is 18.4919260041 - parameters are 2.05228652272 8.0593536725 4.04711290642\n",
      "Iteration 200 - loss is 19.8349763068 - parameters are 2.0618780111 8.06634618828 4.05021096238\n",
      "Iteration 300 - loss is 12.8206371501 - parameters are 2.05500054006 8.06190523362 4.05066033729\n",
      "Iteration 400 - loss is 13.7776151172 - parameters are 2.06188530374 8.06911223544 4.0527257126\n",
      "Iteration 500 - loss is 15.5285299777 - parameters are 2.05240359072 8.05737038476 4.05265133021\n",
      "Iteration 600 - loss is 15.0336352519 - parameters are 2.06729798126 8.06956014674 4.05601775522\n",
      "Iteration 700 - loss is 14.2442996578 - parameters are 2.0657080444 8.0678339933 4.05702028192\n",
      "Iteration 800 - loss is 13.8323280203 - parameters are 2.06698602152 8.07392975349 4.05905213115\n",
      "Iteration 900 - loss is 14.5694803 - parameters are 2.06165228677 8.06713613847 4.05962193705\n",
      "Iteration 1000 - loss is 19.9874424784 - parameters are 2.07073375148 8.07646733046 4.06259443551\n",
      "Epoch 104\n",
      "Iteration 100 - loss is 18.2017482052 - parameters are 2.0513955342 8.05843089535 4.06186405138\n",
      "Iteration 200 - loss is 19.530316739 - parameters are 2.06086983021 8.06531400845 4.06491626368\n",
      "Iteration 300 - loss is 12.6409999638 - parameters are 2.05407158384 8.06094529442 4.0653540994\n",
      "Iteration 400 - loss is 13.6089706112 - parameters are 2.06090531872 8.06813492366 4.06739201114\n",
      "Iteration 500 - loss is 15.333176833 - parameters are 2.05143923525 8.05640418553 4.06730016657\n",
      "Iteration 600 - loss is 14.8038743329 - parameters are 2.06627625478 8.06855531599 4.07063338914\n",
      "Iteration 700 - loss is 14.0658027348 - parameters are 2.0646847511 8.06682422683 4.07161332312\n",
      "Iteration 800 - loss is 13.6123242179 - parameters are 2.06596182467 8.0729065487 4.07361849354\n",
      "Iteration 900 - loss is 14.3641205591 - parameters are 2.06068947701 8.06615518061 4.07417113479\n",
      "Iteration 1000 - loss is 19.7357108453 - parameters are 2.06970723327 8.07540972965 4.07710991215\n",
      "Epoch 105\n",
      "Iteration 100 - loss is 17.9205562789 - parameters are 2.05051967889 8.05752330645 4.07637282453\n",
      "Iteration 200 - loss is 19.2352060727 - parameters are 2.05987864153 8.06429865936 4.07937995904\n",
      "Iteration 300 - loss is 12.4674986401 - parameters are 2.05315838891 8.06000110774 4.07980646792\n",
      "Iteration 400 - loss is 13.446374048 - parameters are 2.05994186875 8.06717357372 4.08181737547\n",
      "Iteration 500 - loss is 15.1438159433 - parameters are 2.05049120002 8.05545386091 4.08170837752\n",
      "Iteration 600 - loss is 14.5816553215 - parameters are 2.06527173203 8.06756689957 4.08500895403\n",
      "Iteration 700 - loss is 13.8933988311 - parameters are 2.06367875434 8.06583104335 4.08596669346\n",
      "Iteration 800 - loss is 13.3995825594 - parameters are 2.06495491241 8.07190010775 4.08794563793\n",
      "Iteration 900 - loss is 14.165628006 - parameters are 2.05974293844 8.06519032213 4.08848141261\n",
      "Iteration 1000 - loss is 19.4915251372 - parameters are 2.06869801591 8.0743694268 4.09138703927\n",
      "Epoch 106\n",
      "Iteration 100 - loss is 17.648059451 - parameters are 2.04965868175 8.05663064514 4.09064337633\n",
      "Iteration 200 - loss is 18.949333454 - parameters are 2.05890414025 8.06329985704 4.09360618542\n",
      "Iteration 300 - loss is 12.2999247199 - parameters are 2.05226066943 8.0590724048 4.09402157544\n",
      "Iteration 400 - loss is 13.2896154983 - parameters are 2.05899465669 8.06622791548 4.09600593003\n",
      "Iteration 500 - loss is 14.9602541502 - parameters are 2.04955919032 8.05451913938 4.09588008151\n",
      "Iteration 600 - loss is 14.3667266369 - parameters are 2.06428410501 8.06659461961 4.09914855847\n",
      "Iteration 700 - loss is 13.7268806735 - parameters are 2.06268974242 8.06485415945 4.10008449383\n",
      "Iteration 800 - loss is 13.1938598333 - parameters are 2.06396497405 8.07091014528 4.10203765696\n",
      "Iteration 900 - loss is 13.9737712902 - parameters are 2.05881237791 8.06424128815 4.10255685757\n",
      "Iteration 1000 - loss is 19.2546450817 - parameters are 2.06770578914 8.07334612842 4.10542989361\n",
      "Epoch 107\n",
      "Iteration 100 - loss is 17.383976749 - parameters are 2.04881227335 8.05575265557 4.10467978075\n",
      "Iteration 200 - loss is 18.6723985348 - parameters are 2.05794602766 8.06231732263 4.10759900351\n",
      "Iteration 300 - loss is 12.1380769433 - parameters are 2.05137814532 8.05815892171 4.1080034784\n",
      "Iteration 400 - loss is 13.1384923534 - parameters are 2.05806339131 8.06529768368 4.10996172328\n",
      "Iteration 500 - loss is 14.7823048052 - parameters are 2.04864291734 8.05359975435 4.10981932116\n",
      "Iteration 600 - loss is 14.1588453159 - parameters are 2.0633130718 8.06563820328 4.11305623539\n",
      "Iteration 700 - loss is 13.5660481668 - parameters are 2.06171740988 8.06389329688 4.11397074964\n",
      "Iteration 800 - loss is 12.9949211897 - parameters are 2.06299170507 8.06993638115 4.115898568\n",
      "Iteration 900 - loss is 13.7883270341 - parameters are 2.05789750814 8.06330780883 4.1164014815\n",
      "Iteration 1000 - loss is 19.0248384569 - parameters are 2.06673024887 8.07233954634 4.11924247693\n",
      "Epoch 108\n",
      "Iteration 100 - loss is 17.1280366558 - parameters are 2.04798018968 8.0548890866 4.11848603683\n",
      "Iteration 200 - loss is 18.4041111013 - parameters are 2.05700401093 8.06135078223 4.12136239934\n",
      "Iteration 300 - loss is 11.9817609926 - parameters are 2.05051054218 8.05726039941 4.12175615869\n",
      "Iteration 400 - loss is 12.9928090631 - parameters are 2.05714778718 8.06438261784 4.12368872928\n",
      "Iteration 500 - loss is 14.6097875391 - parameters are 2.04774209806 8.05269544416 4.1235300648\n",
      "Iteration 600 - loss is 13.9577767068 - parameters are 2.06235833645 8.06469738262 4.1267359436\n",
      "Iteration 700 - loss is 13.410708136 - parameters are 2.06076145735 8.06294818249 4.12762941237\n",
      "Iteration 800 - loss is 12.8025398412 - parameters are 2.06203480705 8.06897854031 4.12953231461\n",
      "Iteration 900 - loss is 13.6090795489 - parameters are 2.05699804756 8.06238961926 4.13001922261\n",
      "Iteration 1000 - loss is 18.801880807 - parameters are 2.06577109703 8.07134939759 4.13282871754\n",
      "Epoch 109\n",
      "Iteration 100 - loss is 16.8799767772 - parameters are 2.04716217206 8.05403969171 4.13206607027\n",
      "Iteration 200 - loss is 18.1441907175 - parameters are 2.05607780306 8.06039996687 4.13490028584\n",
      "Iteration 300 - loss is 11.8307892453 - parameters are 2.04965759107 8.05637658353 4.13528352517\n",
      "Iteration 400 - loss is 12.8523768828 - parameters are 2.05624756452 8.06348246215 4.13719084921\n",
      "Iteration 500 - loss is 14.442528041 - parameters are 2.04685645512 8.05180595189 4.13701620802\n",
      "Iteration 600 - loss is 13.763294174 - parameters are 2.06141960884 8.06377189452 4.14019156939\n",
      "Iteration 700 - loss is 13.2606740794 - parameters are 2.05982159144 8.06201854813 4.14106436113\n",
      "Iteration 800 - loss is 12.6164967759 - parameters are 2.06109398743 8.0680363527 4.14294276815\n",
      "Iteration 900 - loss is 13.4358205595 - parameters are 2.05611372022 8.06148645935 4.14341394698\n",
      "Iteration 1000 - loss is 18.5855551692 - parameters are 2.06482804145 8.07037540432 4.14619247183\n",
      "Epoch 110\n",
      "Iteration 100 - loss is 16.6395435219 - parameters are 2.046357967 8.05320422889 4.14542373487\n",
      "Iteration 200 - loss is 17.8923663814 - parameters are 2.05516712267 8.05946461235 4.14821650431\n",
      "Iteration 300 - loss is 11.6849805351 - parameters are 2.04881902848 8.05550722433 4.14858941519\n",
      "Iteration 400 - loss is 12.7170136309 - parameters are 2.05536244909 8.0625969654 4.15047191289\n",
      "Iteration 500 - loss is 14.280357845 - parameters are 2.04598571666 8.05093102534 4.15028157516\n",
      "Iteration 600 - loss is 13.5751788136 - parameters are 2.06049660457 8.06286148057 4.15342692796\n",
      "Iteration 700 - loss is 13.1157659299 - parameters are 2.05889752454 8.0611041305 4.15427940407\n",
      "Iteration 800 - loss is 12.4365804803 - parameters are 2.06016895948 8.06710955312 4.1561337292\n",
      "Iteration 900 - loss is 13.2683489408 - parameters are 2.05524425565 8.06059807375 4.15658945003\n",
      "Iteration 1000 - loss is 18.3756518109 - parameters are 2.06390079571 8.06941729366 4.15933752573\n",
      "Epoch 111\n",
      "Iteration 100 - loss is 16.4064917923 - parameters are 2.04556732608 8.05238246056 4.15856281406\n",
      "Iteration 200 - loss is 17.6483761943 - parameters are 2.05427169394 8.05854445919 4.16131482589\n",
      "Iteration 300 - loss is 11.5441599236 - parameters are 2.04799459611 8.05465207659 4.16167759602\n",
      "Iteration 400 - loss is 12.5865434541 - parameters are 2.05449217205 8.06172588084 4.16353568022\n",
      "Iteration 500 - loss is 14.1231141247 - parameters are 2.04512961621 8.05007041687 4.16332992078\n",
      "Iteration 600 - loss is 13.3932191802 - parameters are 2.05958904478 8.06196588698 4.1664457649\n",
      "Iteration 700 - loss is 12.9758098255 - parameters are 2.05798897477 8.06020467112 4.16727827991\n",
      "Iteration 800 - loss is 12.262586673 - parameters are 2.05925944209 8.06619788119 4.16910892904\n",
      "Iteration 900 - loss is 13.1064704635 - parameters are 2.05438938871 8.05972421174 4.16954945799\n",
      "Iteration 1000 - loss is 18.1719679759 - parameters are 2.06298907901 8.06847479765 4.17226759617\n",
      "Epoch 112\n",
      "Iteration 100 - loss is 16.1805846879 - parameters are 2.04479000585 8.05157415348 4.17148702231\n",
      "Iteration 200 - loss is 17.4119670416 - parameters are 2.05339124644 8.0576392525 4.17419895303\n",
      "Iteration 300 - loss is 11.4081584787 - parameters are 2.04718404083 8.05381089952 4.17455176634\n",
      "Iteration 400 - loss is 12.4607966024 - parameters are 2.05363646983 8.06086896617 4.17638584262\n",
      "Iteration 500 - loss is 13.9706394957 - parameters are 2.04428789258 8.04922388335 4.17616493104\n",
      "Iteration 600 - loss is 13.2172110233 - parameters are 2.05869665607 8.0610848645 4.17925175759\n",
      "Iteration 700 - loss is 12.8406378889 - parameters are 2.05709566576 8.05931991618 4.18006465932\n",
      "Iteration 800 - loss is 12.0943180486 - parameters are 2.05836515969 8.0653010812 4.18187203105\n",
      "Iteration 900 - loss is 12.9499975492 - parameters are 2.05354885948 8.05886462713 4.18229762931\n",
      "Iteration 1000 - loss is 17.974307641 - parameters are 2.06209261604 8.06754765313 4.18498633244\n",
      "Epoch 113\n",
      "Iteration 100 - loss is 15.9615932188 - parameters are 2.04402576768 8.05077907865 4.18420000655\n",
      "Iteration 200 - loss is 17.1828942862 - parameters are 2.052525515 8.05674874194 4.18687252083\n",
      "Iteration 300 - loss is 11.2768130629 - parameters are 2.04638711451 8.05298345669 4.18721555755\n",
      "Iteration 400 - loss is 12.3396092122 - parameters are 2.05279508402 8.06002598339 4.18902602441\n",
      "Iteration 500 - loss is 13.8227818252 - parameters are 2.04346028971 8.04839118607 4.18879022515\n",
      "Iteration 600 - loss is 13.0469570335 - parameters are 2.05781917038 8.06021816833 4.19184851663\n",
      "Iteration 700 - loss is 12.7100880148 - parameters are 2.05621732659 8.05844961646 4.19264214628\n",
      "Iteration 800 - loss is 11.9315840304 - parameters are 2.05748584209 8.06441890207 4.19442663209\n",
      "Iteration 900 - loss is 12.798749035 - parameters are 2.05272241315 8.05801907819 4.19483755599\n",
      "Iteration 1000 - loss is 17.7824812809 - parameters are 2.06121113687 8.06663560167 4.19749731764\n",
      "Epoch 114\n",
      "Iteration 100 - loss is 15.7492960301 - parameters are 2.04327437769 8.04999701125 4.19670534752\n",
      "Iteration 200 - loss is 16.9609214726 - parameters are 2.05167423963 8.05587268158 4.19933909847\n",
      "Iteration 300 - loss is 11.1499661276 - parameters are 2.04560357392 8.05216951592 4.19967253522\n",
      "Iteration 400 - loss is 12.2228230969 - parameters are 2.05196776126 8.05919669872 4.20145978418\n",
      "Iteration 500 - loss is 13.6793940484 - parameters are 2.04264655657 8.0475720906 4.20120935668\n",
      "Iteration 600 - loss is 12.8822665985 - parameters are 2.05695632483 8.05936555803 4.20423958714\n",
      "Iteration 700 - loss is 12.5840036652 - parameters are 2.05535369165 8.05759352724 4.2050142795\n",
      "Iteration 800 - loss is 11.7742005329 - parameters are 2.05662122439 8.0635510972 4.20677626384\n",
      "Iteration 900 - loss is 12.6525499468 - parameters are 2.05190979991 8.05718732754 4.207172765\n",
      "Iteration 1000 - loss is 17.5963056418 - parameters are 2.06034437681 8.06573838941 4.20980406993\n",
      "Epoch 115\n",
      "Iteration 100 - loss is 15.5434791366 - parameters are 2.04253560661 8.04922773051 4.20900656114\n",
      "Iteration 200 - loss is 16.745820042 - parameters are 2.0508371654 8.05501082985 4.21160219049\n",
      "Iteration 300 - loss is 11.0274655171 - parameters are 2.04483318063 8.05136884918 4.21192620037\n",
      "Iteration 400 - loss is 12.1102855462 - parameters are 2.05115425312 8.05838088256 4.21369061613\n",
      "Iteration 500 - loss is 13.5403339925 - parameters are 2.04184644707 8.04676636679 4.21342581493\n",
      "Iteration 600 - loss is 12.7229555675 - parameters are 2.05610786163 8.05852679742 4.21642845011\n",
      "Iteration 700 - loss is 12.4622336722 - parameters are 2.05450450052 8.05675140823 4.21718453365\n",
      "Iteration 800 - loss is 11.621989733 - parameters are 2.05577104683 8.06269742442 4.21892439414\n",
      "Iteration 900 - loss is 12.5112312806 - parameters are 2.0511107748 8.05636914209 4.21930671951\n",
      "Iteration 1000 - loss is 17.4156035238 - parameters are 2.05949207633 8.06485576707 4.22191004391\n",
      "Epoch 116\n",
      "Iteration 100 - loss is 15.3439356666 - parameters are 2.04180922969 8.04847101968 4.22110709978\n",
      "Iteration 200 - loss is 16.5373690582 - parameters are 2.05001404228 8.05416294943 4.22366523812\n",
      "Iteration 300 - loss is 10.9091642777 - parameters are 2.04407570088 8.05058123256 4.22397999079\n",
      "Iteration 400 - loss is 12.0018491322 - parameters are 2.050354316 8.05757830936 4.22572195134\n",
      "Iteration 500 - loss is 13.4054642059 - parameters are 2.0410597199 8.04597378859 4.22544302617\n",
      "Iteration 600 - loss is 12.568846025 - parameters are 2.05527352797 8.05770165452 4.22841852369\n",
      "Iteration 700 - loss is 12.3446320488 - parameters are 2.05366949782 8.05592302344 4.22915632072\n",
      "Iteration 800 - loss is 11.4747798495 - parameters are 2.05493505471 8.06185764589 4.23087442823\n",
      "Iteration 900 - loss is 12.3746297921 - parameters are 2.05032509767 8.05556429292 4.23124282023\n",
      "Iteration 1000 - loss is 17.2402035708 - parameters are 2.05865398088 8.06398748977 4.23381863185\n",
      "Epoch 117\n",
      "Iteration 100 - loss is 15.1504656153 - parameters are 2.04109502659 8.04772666593 4.23301035355\n",
      "Iteration 200 - loss is 16.3353549427 - parameters are 2.04920462509 8.05332880719 4.23553162053\n",
      "Iteration 300 - loss is 10.7949204755 - parameters are 2.0433309055 8.04980644616 4.23583728228\n",
      "Iteration 400 - loss is 11.8973715226 - parameters are 2.04956771098 8.05678875757 4.23755715905\n",
      "Iteration 500 - loss is 13.2746517948 - parameters are 2.04028613844 8.04519413404 4.23726435493\n",
      "Iteration 600 - loss is 12.4197660721 - parameters are 2.05445307591 8.05688990144 4.24021316446\n",
      "Iteration 700 - loss is 12.2310578055 - parameters are 2.05284843316 8.05510814114 4.24093299123\n",
      "Iteration 800 - loss is 11.3324049306 - parameters are 2.05411299823 8.06103152802 4.24262971006\n",
      "Iteration 900 - loss is 12.2425877945 - parameters are 2.04955253299 8.05477255522 4.24298440666\n",
      "Iteration 1000 - loss is 17.0699400684 - parameters are 2.05782984086 8.06313331699 4.24553316499\n",
      "Epoch 118\n",
      "Iteration 100 - loss is 14.9628756079 - parameters are 2.0403927813 8.04699446025 4.24471965157\n",
      "Iteration 200 - loss is 16.1395712199 - parameters are 2.04840867335 8.0525081741 4.2472046561\n",
      "Iteration 300 - loss is 10.6845970201 - parameters are 2.04259856978 8.049044274 4.24750138995\n",
      "Iteration 400 - loss is 11.7967153011 - parameters are 2.04879420377 8.05601200957 4.24919954791\n",
      "Iteration 500 - loss is 13.1477682651 - parameters are 2.0395254707 8.04442718517 4.24889310527\n",
      "Iteration 600 - loss is 12.2755496163 - parameters are 2.05364626226 8.05609131433 4.25181566863\n",
      "Iteration 700 - loss is 12.1213747745 - parameters are 2.05204106098 8.05430653373 4.25251783548\n",
      "Iteration 800 - loss is 11.1947046497 - parameters are 2.05330463244 8.06021884137 4.25419352346\n",
      "Iteration 900 - loss is 12.1149529628 - parameters are 2.0487928498 8.05399370822 4.25453475827\n",
      "Iteration 1000 - loss is 16.9046527485 - parameters are 2.05701941143 8.06229301249 4.25705691468\n",
      "Epoch 119\n",
      "Iteration 100 - loss is 14.7809786697 - parameters are 2.039702282 8.04627419741 4.25623826316\n",
      "Iteration 200 - loss is 15.9498182721 - parameters are 2.04762595121 8.05170082515 4.25868760363\n",
      "Iteration 300 - loss is 10.5780614948 - parameters are 2.0418784734 8.04829450395 4.25897556935\n",
      "Iteration 400 - loss is 11.699747794 - parameters are 2.0480335646 8.05524785154 4.26065236715\n",
      "Iteration 500 - loss is 13.0246893702 - parameters are 2.03877748914 8.04367272788 4.26033252193\n",
      "Iteration 600 - loss is 12.1360361692 - parameters are 2.05285284848 8.0553056733 4.26322927325\n",
      "Iteration 700 - loss is 12.0154514404 - parameters are 2.05124714046 8.05351797771 4.26391408475\n",
      "Iteration 800 - loss is 11.0615241083 - parameters are 2.05250971709 8.0594193606 4.26556909338\n",
      "Iteration 900 - loss is 11.9915781462 - parameters are 2.04804582161 8.05322753506 4.26589709573\n",
      "Iteration 1000 - loss is 16.7441866025 - parameters are 2.05622245248 8.06146634418 4.26839309365\n",
      "Epoch 120\n",
      "Iteration 100 - loss is 14.6045940065 - parameters are 2.03902332101 8.04556567584 4.26756939902\n",
      "Iteration 200 - loss is 15.7659031022 - parameters are 2.04685622733 8.05090653927 4.2699836635\n",
      "Iteration 300 - loss is 10.4751859928 - parameters are 2.0411704003 8.04755692767 4.27026301774\n",
      "Iteration 400 - loss is 11.6063409034 - parameters are 2.04728556809 8.05449607346 4.27191880782\n",
      "Iteration 500 - loss is 12.9052949645 - parameters are 2.03804197064 8.04293055195 4.27158579152\n",
      "Iteration 600 - loss is 12.001070651 - parameters are 2.0520726006 8.05453276232 4.27445715744\n",
      "Iteration 700 - loss is 11.9131607767 - parameters are 2.05046643544 8.05274225355 4.27512491247\n",
      "Iteration 800 - loss is 10.9327136462 - parameters are 2.05172801653 8.05863286436 4.27675958702\n",
      "Iteration 900 - loss is 11.872321187 - parameters are 2.04731122629 8.05247382278 4.27707458208\n",
      "Iteration 1000 - loss is 16.5883916995 - parameters are 2.05543872846 8.0606530841 4.27954485715\n",
      "Epoch 121\n",
      "Iteration 100 - loss is 14.4335467911 - parameters are 2.03835569469 8.04486869762 4.27871621244\n",
      "Iteration 200 - loss is 15.5876391059 - parameters are 2.04609927477 8.05012509927 4.28109597884\n",
      "Iteration 300 - loss is 10.3758469602 - parameters are 2.0404741386 8.04683134051 4.28136687516\n",
      "Iteration 400 - loss is 11.5163709469 - parameters are 2.04654999316 8.053756469 4.28300200388\n",
      "Iteration 500 - loss is 12.7894688621 - parameters are 2.03731869635 8.04220045086 4.28265604371\n",
      "Iteration 600 - loss is 11.8705032023 - parameters are 2.05130528908 8.05377236915 4.28550244345\n",
      "Iteration 700 - loss is 11.8143800883 - parameters are 2.04969871424 8.05197914563 4.28615343536\n",
      "Iteration 800 - loss is 10.8081286586 - parameters are 2.05095929964 8.05785913523 4.28776811502\n",
      "Iteration 900 - loss is 11.7570447458 - parameters are 2.04658884593 8.05173236219 4.28807032384\n",
      "Iteration 1000 - loss is 16.4371230122 - parameters are 2.05466800835 8.05985300831 4.29051530405\n",
      "Epoch 122\n",
      "Iteration 100 - loss is 14.2676679589 - parameters are 2.03769920332 8.04418306834 4.28968180038\n",
      "Iteration 200 - loss is 15.4148458517 - parameters are 2.04535487093 8.04935629175 4.29202763667\n",
      "Iteration 300 - loss is 10.2799250437 - parameters are 2.03978948053 8.04611754148 4.29229022565\n",
      "Iteration 400 - loss is 11.4297185019 - parameters are 2.04582662297 8.05302883543 4.29390503337\n",
      "Iteration 500 - loss is 12.6770987004 - parameters are 2.03660745164 8.04148222181 4.2935463523\n",
      "Iteration 600 - loss is 11.744189003 - parameters are 2.05055068876 8.05302428531 4.29636819786\n",
      "Iteration 700 - loss is 11.7189908602 - parameters are 2.04894374967 8.05122844219 4.29700271455\n",
      "Iteration 800 - loss is 10.68762942 - parameters are 2.05020333968 8.05709795962 4.29859773254\n",
      "Iteration 900 - loss is 11.6456161337 - parameters are 2.04587846685 8.05100294783 4.29888737215\n",
      "Iteration 1000 - loss is 16.2902402489 - parameters are 2.05391006548 8.05906589679 4.301307478\n",
      "Epoch 123\n",
      "Iteration 100 - loss is 14.10679401 - parameters are 2.03705365106 8.04350859708 4.30046920462\n",
      "Iteration 200 - loss is 15.2473488692 - parameters are 2.0446227974 8.04859990702 4.302781669\n",
      "Iteration 300 - loss is 10.1873049447 - parameters are 2.03911622229 8.04541533312 4.30303609826\n",
      "Iteration 400 - loss is 11.3462682569 - parameters are 2.04511524479 8.05231297359 4.30463091951\n",
      "Iteration 500 - loss is 12.5680758092 - parameters are 2.03590802598 8.04077566557 4.30425973638\n",
      "Iteration 600 - loss is 11.6219880977 - parameters are 2.04980857872 8.05228830594 4.3070574326\n",
      "Iteration 700 - loss is 11.6268786113 - parameters are 2.04820131885 8.05048993522 4.30767575667\n",
      "Iteration 800 - loss is 10.5710809147 - parameters are 2.04945991426 8.05634912774 4.30925144035\n",
      "Iteration 900 - loss is 11.5379071503 - parameters are 2.04517987941 8.05028537789 4.30952872387\n",
      "Iteration 1000 - loss is 16.1476076915 - parameters are 2.05316467752 8.05829153342 4.31192436849\n",
      "Epoch 124\n",
      "Iteration 100 - loss is 13.9507668186 - parameters are 2.03641884581 8.04284509633 4.31108141282\n",
      "Iteration 200 - loss is 15.0849794443 - parameters are 2.04390283994 8.04785573908 4.31336105391\n",
      "Iteration 300 - loss is 10.0978752778 - parameters are 2.03845416401 8.04472452148 4.31360746822\n",
      "Iteration 400 - loss is 11.2659088677 - parameters are 2.04441564994 8.0516086878 4.31518263174\n",
      "Iteration 500 - loss is 12.4622950839 - parameters are 2.03522021286 8.04008058649 4.31479916134\n",
      "Iteration 600 - loss is 11.503765227 - parameters are 2.04907874222 8.05156422977 4.31757310612\n",
      "Iteration 700 - loss is 11.5379327535 - parameters are 2.04747120313 8.04976342039 4.31817551494\n",
      "Iteration 800 - loss is 10.4583526725 - parameters are 2.04872880518 8.05561243348 4.31973218591\n",
      "Iteration 900 - loss is 11.4337939271 - parameters are 2.04449287796 8.04957945411 4.31999732259\n",
      "Iteration 1000 - loss is 16.009094039 - parameters are 2.05243162632 8.05752970586 4.32236891191\n",
      "Epoch 125\n",
      "Iteration 100 - loss is 13.7994334497 - parameters are 2.03579459917 8.04219238191 4.32152135959\n",
      "Iteration 200 - loss is 14.9275744227 - parameters are 2.04319478834 8.04712358546 4.32376871662\n",
      "Iteration 300 - loss is 10.0115284351 - parameters are 2.03780310964 8.04404491603 4.32400725791\n",
      "Iteration 400 - loss is 11.1885328182 - parameters are 2.04372763367 8.05091578579 4.32556308683\n",
      "Iteration 500 - loss is 12.3596548636 - parameters are 2.0345438097 8.03939679234 4.32516753996\n",
      "Iteration 600 - loss is 11.3893896653 - parameters are 2.0483609666 8.05085185908 4.32791812435\n",
      "Iteration 700 - loss is 11.4520464563 - parameters are 2.04675318803 8.049048697 4.32850489018\n",
      "Iteration 800 - loss is 10.3493186117 - parameters are 2.04800979838 8.05488767437 4.33004286444\n",
      "Iteration 900 - loss is 11.3331567778 - parameters are 2.04381726078 8.04888498176 4.33029605975\n",
      "Iteration 1000 - loss is 15.8745722572 - parameters are 2.05171069785 8.05678020549 4.33264399261\n",
      "Epoch 126\n",
      "Iteration 100 - loss is 13.6526459817 - parameters are 2.03518072634 8.0415502729 4.33179192754\n",
      "Iteration 200 - loss is 14.7749760195 - parameters are 2.04249843635 8.04640324726 4.33400753049\n",
      "Iteration 300 - loss is 9.92816045533 - parameters are 2.03716286687 8.0433763296 4.33423833796\n",
      "Iteration 400 - loss is 11.1140362875 - parameters are 2.04305099511 8.05023407867 4.33577514985\n",
      "Iteration 500 - loss is 12.2600568135 - parameters are 2.03387861776 8.03872409432 4.33536773344\n",
      "Iteration 600 - loss is 11.2787350645 - parameters are 2.04765504321 8.05015099955 4.33809534174\n",
      "Iteration 700 - loss is 11.369116516 - parameters are 2.04604706314 8.04834556788 4.33866673188\n",
      "Iteration 800 - loss is 10.2438568871 - parameters are 2.04730268386 8.05417465148 4.34018631986\n",
      "Iteration 900 - loss is 11.2358800526 - parameters are 2.04315282993 8.04820176952 4.34042777557\n",
      "Iteration 1000 - loss is 15.7439194336 - parameters are 2.05100168212 8.05604282733 4.34275244389\n",
      "Epoch 127\n",
      "Iteration 100 - loss is 13.5102613358 - parameters are 2.03457704608 8.04091859161 4.34189594827\n",
      "Iteration 200 - loss is 14.6270316362 - parameters are 2.04181358158 8.04569452899 4.34408031805\n",
      "Iteration 300 - loss is 9.84767089727 - parameters are 2.03653324705 8.04271857832 4.34430352823\n",
      "Iteration 400 - loss is 11.0423190206 - parameters are 2.04238553717 8.0495633808 4.34582163521\n",
      "Iteration 500 - loss is 12.1634058113 - parameters are 2.03322444207 8.03806230696 4.34540255239\n",
      "Iteration 600 - loss is 11.171679303 - parameters are 2.04696076729 8.04946146028 4.34810756232\n",
      "Iteration 700 - loss is 11.2890432293 - parameters are 2.045352622 8.04765383935 4.34866383913\n",
      "Iteration 800 - loss is 10.1418497429 - parameters are 2.04660725554 8.0534731694 4.35016534588\n",
      "Iteration 900 - loss is 11.1418519987 - parameters are 2.04249939124 8.04752962947 4.35039526014\n",
      "Iteration 1000 - loss is 15.6170166371 - parameters are 2.05030437307 8.05531737002 4.35269704899\n",
      "Epoch 128\n",
      "Iteration 100 - loss is 13.372141111 - parameters are 2.03398338054 8.04029716348 4.35183620337\n",
      "Iteration 200 - loss is 14.4835936839 - parameters are 2.04114002545 8.04499723857 4.35398985202\n",
      "Iteration 300 - loss is 9.76996271816 - parameters are 2.03591406511 8.04207148155 4.35420559877\n",
      "Iteration 400 - loss is 10.9732842042 - parameters are 2.04173106644 8.04890350981 4.35570530764\n",
      "Iteration 500 - loss is 12.0696098382 - parameters are 2.03258109135 8.03741124806 4.35527475781\n",
      "Iteration 600 - loss is 11.0681043401 - parameters are 2.04627793791 8.04878305369 4.35795754061\n",
      "Iteration 700 - loss is 11.2117302727 - parameters are 2.04466966206 8.04697332116 4.35849896168\n",
      "Iteration 800 - loss is 10.0431833722 - parameters are 2.04592331124 8.05278303611 4.3599826869\n",
      "Iteration 900 - loss is 11.0509646255 - parameters are 2.04185675418 8.04686837697 4.36020125429\n",
      "Iteration 1000 - loss is 15.493748783 - parameters are 2.04961856851 8.05460363566 4.3624805421\n",
      "Epoch 129\n",
      "Iteration 100 - loss is 13.2381514255 - parameters are 2.0333995553 8.03968581705 4.36161542539\n",
      "Iteration 200 - loss is 14.3445194133 - parameters are 2.04047757308 8.04431118722 4.36373885619\n",
      "Iteration 300 - loss is 9.69494215621 - parameters are 2.0353051395 8.0414348618 4.36394727084\n",
      "Iteration 400 - loss is 10.9068383476 - parameters are 2.04108739317 8.04825428646 4.36542888314\n",
      "Iteration 500 - loss is 11.9785798731 - parameters are 2.03194837791 8.03677073863 4.36498706204\n",
      "Iteration 600 - loss is 10.967896076 - parameters are 2.04560635789 8.04811559544 4.36764798259\n",
      "Iteration 700 - loss is 11.1370845845 - parameters are 2.04399798456 8.04630382636 4.36817480081\n",
      "Iteration 800 - loss is 9.94774778041 - parameters are 2.04525065255 8.05210406298 4.369641039\n",
      "Iteration 900 - loss is 10.9631135749 - parameters are 2.04122473181 8.04621783064 4.36984845064\n",
      "Iteration 1000 - loss is 15.3740045033 - parameters are 2.04894407001 8.05390142985 4.37210560924\n",
      "Epoch 130\n",
      "Iteration 100 - loss is 13.1081627634 - parameters are 2.03282539921 8.03908438388 4.37123629878\n",
      "Iteration 200 - loss is 14.2096707498 - parameters are 2.03982603322 8.04363618946 4.37333000646\n",
      "Iteration 300 - loss is 9.62251861745 - parameters are 2.03470629208 8.04080854473 4.3735312178\n",
      "Iteration 400 - loss is 10.8428911666 - parameters are 2.04045433112 8.04761553463 4.37499502994\n",
      "Iteration 500 - loss is 11.8902297913 - parameters are 2.03132611759 8.03614060281 4.37454212974\n",
      "Iteration 600 - loss is 10.8709442166 - parameters are 2.04494583373 8.0474589044 4.37718154669\n",
      "Iteration 700 - loss is 11.0650162525 - parameters are 2.04333739447 8.04564517133 4.37769401034\n",
      "Iteration 800 - loss is 9.85543665409 - parameters are 2.04458908478 8.05143606466 4.37914305087\n",
      "Iteration 900 - loss is 10.8781979956 - parameters are 2.04060314069 8.04557781227 4.37933949443\n",
      "Iteration 1000 - loss is 15.2576760204 - parameters are 2.04828068286 8.05321056153 4.38157488926\n",
      "Epoch 131\n",
      "Iteration 100 - loss is 12.9820498271 - parameters are 2.03226074438 8.03849269849 4.38070146082\n",
      "Iteration 200 - loss is 14.0789141352 - parameters are 2.0391852182 8.04297206295 4.3827659317\n",
      "Iteration 300 - loss is 9.55260456654 - parameters are 2.03411734808 8.040192359 4.38296006607\n",
      "Iteration 400 - loss is 10.7813554726 - parameters are 2.03983169753 8.04698708127 4.3844063694\n",
      "Iteration 500 - loss is 11.804476266 - parameters are 2.03071412969 8.03552066784 4.38394257876\n",
      "Iteration 600 - loss is 10.7771421429 - parameters are 2.0442961755 8.04681280256 4.38656084463\n",
      "Iteration 700 - loss is 10.9954384048 - parameters are 2.04268770042 8.04499717563 4.38705919748\n",
      "Iteration 800 - loss is 9.7661472345 - parameters are 2.04393841686 8.05077885903 4.38849132471\n",
      "Iteration 900 - loss is 10.7961204226 - parameters are 2.0399918008 8.04494814677 4.38867698453\n",
      "Iteration 1000 - loss is 15.1446590265 - parameters are 2.04762821596 8.05253084298 4.39089097469\n",
      "Epoch 132\n",
      "Iteration 100 - loss is 12.8596913942 - parameters are 2.03170542605 8.03791059832 4.39001350255\n",
      "Iteration 200 - loss is 13.9521203751 - parameters are 2.03855494381 8.04231862854 4.39204921467\n",
      "Iteration 300 - loss is 9.48511542152 - parameters are 2.03353813599 8.03958613631 4.39223639598\n",
      "Iteration 400 - loss is 10.7221470652 - parameters are 2.03921931306 8.04636875629 4.39366547692\n",
      "Iteration 500 - loss is 11.7212386737 - parameters are 2.03011223687 8.03491076399 4.39319098105\n",
      "Iteration 600 - loss is 10.6863867852 - parameters are 2.04365719678 8.04617711502 4.39578844235\n",
      "Iteration 700 - loss is 10.9282671053 - parameters are 2.0420487146 8.044359662 4.39627292376\n",
      "Iteration 800 - loss is 9.67978019548 - parameters are 2.04329846128 8.05013226715 4.39768841713\n",
      "Iteration 900 - loss is 10.7167866608 - parameters are 2.0393905355 8.04432866213 4.39786347426\n",
      "Iteration 1000 - loss is 15.0348525667 - parameters are 2.04698648174 8.05186208973 4.40005641265\n",
      "Epoch 133\n",
      "Iteration 100 - loss is 12.7409701806 - parameters are 2.03115928259 8.03733792367 4.39917496961\n",
      "Iteration 200 - loss is 13.8291644909 - parameters are 2.03793502924 8.04167571015 4.4011823929\n",
      "Iteration 300 - loss is 9.41996945228 - parameters are 2.03296848754 8.03898971126 4.40136274273\n",
      "Iteration 400 - loss is 10.6651846288 - parameters are 2.03861700167 8.04576039256 4.40277488279\n",
      "Iteration 500 - loss is 11.6404390033 - parameters are 2.02952026513 8.03431072448 4.40228986358\n",
      "Iteration 600 - loss is 10.5985785023 - parameters are 2.04302871463 8.04555166988 4.40486686092\n",
      "Iteration 700 - loss is 10.8634212521 - parameters are 2.04142025269 8.04373245627 4.4053377059\n",
      "Iteration 800 - loss is 9.59623952573 - parameters are 2.042669034 8.04949611318 4.40673683999\n",
      "Iteration 900 - loss is 10.6401056726 - parameters are 2.0387991714 8.0437191893 4.40690147227\n",
      "Iteration 1000 - loss is 14.9281589258 - parameters are 2.04635529612 8.05120412051 4.40907370574\n",
      "Epoch 134\n",
      "Iteration 100 - loss is 12.6257727074 - parameters are 2.03062215537 8.03677451762 4.40818836313\n",
      "Iteration 200 - loss is 13.7099255777 - parameters are 2.03732529704 8.0410431347 4.41016795957\n",
      "Iteration 300 - loss is 9.35708768268 - parameters are 2.03240823761 8.03840292135 4.41034159717\n",
      "Iteration 400 - loss is 10.6103896328 - parameters are 2.03802459058 8.04516182581 4.41173707312\n",
      "Iteration 500 - loss is 11.5620017677 - parameters are 2.02893804368 8.03372038547 4.41124170912\n",
      "Iteration 600 - loss is 10.5136209638 - parameters are 2.04241054945 8.04493629819 4.41379857731\n",
      "Iteration 700 - loss is 10.8008224801 - parameters are 2.04080213379 8.04311538732 4.41425601665\n",
      "Iteration 800 - loss is 9.51543241537 - parameters are 2.0420499544 8.04887022433 4.41563906133\n",
      "Iteration 900 - loss is 10.5659894696 - parameters are 2.03821753836 8.04311956222 4.41579344343\n",
      "Iteration 1000 - loss is 14.8244835204 - parameters are 2.04573447842 8.05055675716 4.41794531283\n",
      "Epoch 135\n",
      "Iteration 100 - loss is 12.5139891729 - parameters are 2.03009388875 8.03622022601 4.4170561406\n",
      "Iteration 200 - loss is 13.5942866669 - parameters are 2.03672557303 8.0404207321 4.41900836432\n",
      "Iteration 300 - loss is 9.29639379609 - parameters are 2.03185722414 8.03782560689 4.41917540672\n",
      "Iteration 400 - loss is 10.5576862355 - parameters are 2.03744191022 8.04457289462 4.42055449062\n",
      "Iteration 500 - loss is 11.4858539189 - parameters are 2.0283654049 8.03313958595 4.42004895717\n",
      "Iteration 600 - loss is 10.4314210378 - parameters are 2.04180252494 8.04433083394 4.42258602533\n",
      "Iteration 700 - loss is 10.7403950668 - parameters are 2.04019418037 8.04250828699 4.42303028565\n",
      "Iteration 800 - loss is 9.43726914643 - parameters are 2.04144104519 8.04825443083 4.4243975061\n",
      "Iteration 900 - loss is 10.494353008 - parameters are 2.03764546937 8.04252961769 4.42454180961\n",
      "Iteration 1000 - loss is 14.7237347933 - parameters are 2.04512385126 8.04991982464 4.42667364995\n",
      "Epoch 136\n",
      "Iteration 100 - loss is 12.4055133291 - parameters are 2.02957432997 8.03567489738 4.42578071666\n",
      "Iteration 200 - loss is 13.4821345938 - parameters are 2.03613568621 8.03980833519 4.42770601414\n",
      "Iteration 300 - loss is 9.23781404427 - parameters are 2.0313152881 8.03725761097 4.42786657612\n",
      "Iteration 400 - loss is 10.5070011911 - parameters are 2.03686879412 8.04399344033 4.42922953542\n",
      "Iteration 500 - loss is 11.4119247664 - parameters are 2.0278021843 8.03256816773 4.42871400469\n",
      "Iteration 600 - loss is 10.3518886817 - parameters are 2.04120446805 8.04373511396 4.43123159637\n",
      "Iteration 700 - loss is 10.6820658418 - parameters are 2.03959621815 8.04191099006 4.43166290021\n",
      "Iteration 800 - loss is 9.36166298727 - parameters are 2.04084213234 8.04764856582 4.43301455707\n",
      "Iteration 900 - loss is 10.4251140884 - parameters are 2.03708280053 8.04194919535 4.43314895053\n",
      "Iteration 1000 - loss is 14.6258241123 - parameters are 2.04452324055 8.04929315089 4.43526109108\n",
      "Epoch 137\n",
      "Iteration 100 - loss is 12.3002423626 - parameters are 2.02906332914 8.03513838291 4.43436446392\n",
      "Iteration 200 - loss is 13.3733598695 - parameters are 2.03555546872 8.03920577963 4.43626327409\n",
      "Iteration 300 - loss is 9.18127715957 - parameters are 2.0307822734 8.03669877941 4.43641746829\n",
      "Iteration 400 - loss is 10.4582637602 - parameters are 2.03630507889 8.04342330701 4.43776456593\n",
      "Iteration 500 - loss is 11.3401458973 - parameters are 2.02724822041 8.03200597537 4.43723920698\n",
      "Iteration 600 - loss is 10.2749368373 - parameters are 2.04061620889 8.04314897788 4.43973764023\n",
      "Iteration 700 - loss is 10.6257640989 - parameters are 2.0390080761 8.04132333417 4.44015620615\n",
      "Iteration 800 - loss is 9.28853009075 - parameters are 2.04025304502 8.04705246534 4.44149255556\n",
      "Iteration 900 - loss is 10.3581932577 - parameters are 2.03652937093 8.04137813764 4.44161720455\n",
      "Iteration 1000 - loss is 14.530665673 - parameters are 2.04393247538 8.04867656683 4.44370996892\n",
      "Epoch 138\n",
      "Iteration 100 - loss is 12.1980767792 - parameters are 2.02856073914 8.03461053636 4.44280971379\n",
      "Iteration 200 - loss is 13.2678565579 - parameters are 2.03498475581 8.03861290391 4.44468246817\n",
      "Iteration 300 - loss is 9.12671427009 - parameters are 2.03025802685 8.03614896068 4.4448304051\n",
      "Iteration 400 - loss is 10.4114056236 - parameters are 2.03575060411 8.0428623414 4.44616189957\n",
      "Iteration 500 - loss is 11.2704511009 - parameters are 2.02670335474 8.03145285611 4.44562687844\n",
      "Iteration 600 - loss is 10.2004813295 - parameters are 2.04003758067 8.04257226809 4.44810646594\n",
      "Iteration 700 - loss is 10.5714215121 - parameters are 2.0384295863 8.04074515979 4.44851250856\n",
      "Iteration 800 - loss is 9.21778939594 - parameters are 2.03967361556 8.04646596825 4.44983380227\n",
      "Iteration 900 - loss is 10.2935137164 - parameters are 2.03598502264 8.0408162897 4.44994886944\n",
      "Iteration 1000 - loss is 14.4381764039 - parameters are 2.04335138796 8.04806990629 4.45202257572\n",
      "Epoch 139\n",
      "Iteration 100 - loss is 12.0989202933 - parameters are 2.02806641555 8.03409121405 4.45111875721\n",
      "Iteration 200 - loss is 13.1655221562 - parameters are 2.03442338568 8.03802954929 4.45296588006\n",
      "Iteration 300 - loss is 9.07405881792 - parameters are 2.02974239811 8.0356080059 4.45310766817\n",
      "Iteration 400 - loss is 10.366360799 - parameters are 2.03520521233 8.04231039288 4.4544238136\n",
      "Iteration 500 - loss is 11.2027762944 - parameters are 2.02616743171 8.03090865986 4.45387929332\n",
      "Iteration 600 - loss is 10.1284407685 - parameters are 2.03946841964 8.04200482967 4.45634034245\n",
      "Iteration 700 - loss is 10.5189720535 - parameters are 2.03786058394 8.04017631015 4.45673407258\n",
      "Iteration 800 - loss is 9.14936253337 - parameters are 2.03910367932 8.04588891621 4.45804055802\n",
      "Iteration 900 - loss is 10.2310012271 - parameters are 2.03544960062 8.04026349938 4.45814620316\n",
      "Iteration 1000 - loss is 14.3482758759 - parameters are 2.04277981359 8.04747300594 4.460201164\n",
      "Epoch 140\n",
      "Iteration 100 - loss is 12.0026797203 - parameters are 2.02758021667 8.03358027478 4.45929384545\n",
      "Iteration 200 - loss is 13.0662574799 - parameters are 2.03387119952 8.0374555597 4.46111575386\n",
      "Iteration 300 - loss is 9.02324648023 - parameters are 2.02923523957 8.03507576871 4.46125149957\n",
      "Iteration 400 - loss is 10.3230655606 - parameters are 2.03466874894 8.04176731338 4.46255254582\n",
      "Iteration 500 - loss is 11.1370594522 - parameters are 2.02564029861 8.03037323912 4.46199868652\n",
      "Iteration 600 - loss is 10.0587364554 - parameters are 2.03890856504 8.04144651035 4.46444149947\n",
      "Iteration 700 - loss is 10.4683519156 - parameters are 2.0373009072 8.03961663118 4.46482312413\n",
      "Iteration 800 - loss is 9.08317373356 - parameters are 2.03854307468 8.04532115357 4.4661150445\n",
      "Iteration 900 - loss is 10.1705840282 - parameters are 2.03492295267 8.03971961712 4.46621142459\n",
      "Iteration 1000 - loss is 14.2608862143 - parameters are 2.04221759052 8.04688570528 4.46824794729\n",
      "Epoch 141\n",
      "Iteration 100 - loss is 11.9092648733 - parameters are 2.02710200337 8.03307757983 4.46733719081\n",
      "Iteration 200 - loss is 12.9699665523 - parameters are 2.03332804139 8.03689078177 4.46913429489\n",
      "Iteration 300 - loss is 8.97421509314 - parameters are 2.02873640637 8.03455210533 4.46926410263\n",
      "Iteration 400 - loss is 10.2814583615 - parameters are 2.03414106216 8.04123295738 4.47055029533\n",
      "Iteration 500 - loss is 11.0732405368 - parameters are 2.02512180551 8.02984644894 4.46998725427\n",
      "Iteration 600 - loss is 9.99129229135 - parameters are 2.03835785901 8.04089716048 4.47241212814\n",
      "Iteration 700 - loss is 10.4194994346 - parameters are 2.03675039725 8.03906597147 4.47278185068\n",
      "Iteration 800 - loss is 9.01914973877 - parameters are 2.03799164298 8.04476252739 4.47405944501\n",
      "Iteration 900 - loss is 10.1121927492 - parameters are 2.03440492938 8.03918449599 4.47414671427\n",
      "Iteration 1000 - loss is 14.1759320137 - parameters are 2.04166455999 8.04630784651 4.47616510092\n",
      "Epoch 142\n",
      "Iteration 100 - loss is 11.8185884633 - parameters are 2.02663163909 8.03258299284 4.4752509674\n",
      "Iteration 200 - loss is 12.876556497 - parameters are 2.03279375818 8.0363350647 4.47702367035\n",
      "Iteration 300 - loss is 8.92690457821 - parameters are 2.02824575629 8.03403687441 4.4771476426\n",
      "Iteration 400 - loss is 10.241479759 - parameters are 2.03362200299 8.04070718184 4.47841922327\n",
      "Iteration 500 - loss is 11.0112614332 - parameters are 2.02461180523 8.02932814687 4.4778471549\n",
      "Iteration 600 - loss is 9.92603468932 - parameters are 2.03781614656 8.04035663295 4.48025438178\n",
      "Iteration 700 - loss is 10.372355018 - parameters are 2.03620889813 8.03852418224 4.48061240193\n",
      "Iteration 800 - loss is 8.95721971788 - parameters are 2.03744922844 8.04421288734 4.48187590516\n",
      "Iteration 900 - loss is 10.0557603293 - parameters are 2.03389538403 8.03865799154 4.48195421513\n",
      "Iteration 1000 - loss is 14.0933402568 - parameters are 2.0411205661 8.04573927459 4.48395476265\n",
      "Epoch 143\n",
      "Iteration 100 - loss is 11.7305660027 - parameters are 2.0261689898 8.03209637985 4.48303731181\n",
      "Iteration 200 - loss is 12.7859374348 - parameters are 2.03226819955 8.03578826028 4.48478601008\n",
      "Iteration 300 - loss is 8.88125687161 - parameters are 2.02776314974 8.03352993707 4.48490424742\n",
      "Iteration 400 - loss is 10.2030723424 - parameters are 2.03311142509 8.04018984615 4.48616145351\n",
      "Iteration 500 - loss is 10.9510658845 - parameters are 2.02411015329 8.02881819291 4.48558050953\n",
      "Iteration 600 - loss is 9.86289248974 - parameters are 2.03728327549 8.03982478315 4.48797037659\n",
      "Iteration 700 - loss is 10.3268610734 - parameters are 2.03567625674 8.03799111726 4.48831689053\n",
      "Iteration 800 - loss is 8.89731518424 - parameters are 2.03691567808 8.04367208566 4.4895665336\n",
      "Iteration 900 - loss is 10.0012219397 - parameters are 2.03339417262 8.03813996184 4.48963603316\n",
      "Iteration 1000 - loss is 14.013040235 - parameters are 2.04058545577 8.04517983708 4.49161903344\n",
      "Epoch 144\n",
      "Iteration 100 - loss is 11.6451157121 - parameters are 2.02571392389 8.0316176092 4.49069832383\n",
      "Iteration 200 - loss is 12.6980223835 - parameters are 2.03175121789 8.03525022279 4.49242340721\n",
      "Iteration 300 - loss is 8.83721585564 - parameters are 2.02728844964 8.03303115678 4.49253600837\n",
      "Iteration 400 - loss is 10.1661806636 - parameters are 2.03260918481 8.03968081209 4.49377907336\n",
      "Iteration 500 - loss is 10.8925994304 - parameters are 2.0236167078 8.0283164495 4.49318940277\n",
      "Iteration 600 - loss is 9.80179687844 - parameters are 2.03675909636 8.03930146894 4.49556219234\n",
      "Iteration 700 - loss is 10.2829619409 - parameters are 2.03515232272 8.03746663281 4.49589739277\n",
      "Iteration 800 - loss is 8.83936991635 - parameters are 2.03639084172 8.04313997714 4.49713340269\n",
      "Iteration 900 - loss is 9.94851490719 - parameters are 2.03290115372 8.03763026738 4.49719423812\n",
      "Iteration 1000 - loss is 13.934963472 - parameters are 2.04005907869 8.04462938417 4.49915997808\n",
      "Epoch 145\n",
      "Iteration 100 - loss is 11.562158431 - parameters are 2.02526631217 8.03114655148 4.49823606715\n",
      "Iteration 200 - loss is 12.6127271618 - parameters are 2.03124266825 8.034720809 4.49993791891\n",
      "Iteration 300 - loss is 8.79472729272 - parameters are 2.02682152146 8.03254039936 4.50004498077\n",
      "Iteration 400 - loss is 10.1307511695 - parameters are 2.03211514107 8.03917994381 4.50127413421\n",
      "Iteration 500 - loss is 10.8358093476 - parameters are 2.02313132947 8.0278227814 4.50067588336\n",
      "Iteration 600 - loss is 9.74268130769 - parameters are 2.0362434624 8.03878655061 4.50303187305\n",
      "Iteration 700 - loss is 10.2406038272 - parameters are 2.03463694849 8.03695058764 4.50335594927\n",
      "Iteration 800 - loss is 8.78331988137 - parameters are 2.0358745719 8.04261641903 4.50457854917\n",
      "Iteration 900 - loss is 9.89757864169 - parameters are 2.03241618848 8.03712877106 4.5046308642\n",
      "Iteration 1000 - loss is 13.8590436505 - parameters are 2.03954128725 8.0440877686 4.5065796259\n",
      "Epoch 146\n",
      "Iteration 100 - loss is 11.48161753 - parameters are 2.02482602781 8.03068307953 4.50565256999\n",
      "Iteration 200 - loss is 12.5299702963 - parameters are 2.03074240826 8.0341998781 4.50733156698\n",
      "Iteration 300 - loss is 8.75373876168 - parameters are 2.02636223308 8.03205753296 4.50743318465\n",
      "Iteration 400 - loss is 10.0967321373 - parameters are 2.03162915535 8.03868710774 4.50864865225\n",
      "Iteration 500 - loss is 10.7806445921 - parameters are 2.02265388155 8.02733705573 4.5080419649\n",
      "Iteration 600 - loss is 9.68548142 - parameters are 2.0357362295 8.03827989081 4.51038142765\n",
      "Iteration 700 - loss is 10.1997347421 - parameters are 2.0341299891 8.03644284295 4.51069456561\n",
      "Iteration 800 - loss is 8.72910316128 - parameters are 2.03536672379 8.04210127104 4.51190397484\n",
      "Iteration 900 - loss is 9.84835456555 - parameters are 2.03193914057 8.03663533811 4.5119479107\n",
      "Iteration 1000 - loss is 13.7852165411 - parameters are 2.03903193651 8.0435548456 4.51387997142\n",
      "Epoch 147\n",
      "Iteration 100 - loss is 11.4034188279 - parameters are 2.02439294629 8.03022706838 4.51294982578\n",
      "Iteration 200 - loss is 12.4496729316 - parameters are 2.03025029814 8.03368729164 4.51460633855\n",
      "Iteration 300 - loss is 8.71419959621 - parameters are 2.02591045479 8.03158242794 4.51470260537\n",
      "Iteration 400 - loss is 10.0640736123 - parameters are 2.0311510916 8.0382021726 4.51590460908\n",
      "Iteration 500 - loss is 10.7270557438 - parameters are 2.02218422972 8.02685914186 4.51528962645\n",
      "Iteration 600 - loss is 9.63013497451 - parameters are 2.03523725611 8.03778135451 4.51761283062\n",
      "Iteration 700 - loss is 10.1603044375 - parameters are 2.03363130222 8.03594326227 4.51791521299\n",
      "Iteration 800 - loss is 8.67665988156 - parameters are 2.03486715518 8.04159439526 4.51911164717\n",
      "Iteration 900 - loss is 9.80078604562 - parameters are 2.0314698761 8.03614983608 4.51914734265\n",
      "Iteration 1000 - loss is 13.7134199332 - parameters are 2.03853088412 8.04303047288 4.52106297496\n",
      "Epoch 148\n",
      "Iteration 100 - loss is 11.3274905106 - parameters are 2.02396694534 8.02977839521 4.52012979378\n",
      "Iteration 200 - loss is 12.3717587432 - parameters are 2.02976620061 8.03318291354 4.52176418671\n",
      "Iteration 300 - loss is 8.6760608255 - parameters are 2.02546605924 8.0311149569 4.52185519433\n",
      "Iteration 400 - loss is 10.0327273468 - parameters are 2.03068081624 8.03772500932 4.52304395236\n",
      "Iteration 500 - loss is 10.6749949531 - parameters are 2.02172224213 8.02638891142 4.52242081317\n",
      "Iteration 600 - loss is 9.57658177591 - parameters are 2.03474640324 8.03729080899 4.52472802264\n",
      "Iteration 700 - loss is 10.1222643481 - parameters are 2.0331407481 8.03545171151 4.52501982888\n",
      "Iteration 800 - loss is 8.62593214242 - parameters are 2.03437572642 8.04109565614 4.52620349998\n",
      "Iteration 900 - loss is 9.75481832764 - parameters are 2.0310082636 8.03567213477 4.52623109142\n",
      "Iteration 1000 - loss is 13.6435935692 - parameters are 2.0380379903 8.04251451056 4.52813056332\n",
      "Epoch 149\n",
      "Iteration 100 - loss is 11.2537630527 - parameters are 2.02354790491 8.02933693928 4.52719439977\n",
      "Iteration 200 - loss is 12.2961538544 - parameters are 2.02928998083 8.03268661 4.52880703114\n",
      "Iteration 300 - loss is 8.63927511693 - parameters are 2.02502892138 8.03065499461 4.5288928695\n",
      "Iteration 400 - loss is 10.0026467427 - parameters are 2.03021819807 8.03725549101 4.53006859646\n",
      "Iteration 500 - loss is 10.6244158885 - parameters are 2.02126778928 8.02592623822 4.52943743697\n",
      "Iteration 600 - loss is 9.52476360592 - parameters are 2.03426353435 8.03680812376 4.5317289112\n",
      "Iteration 700 - loss is 10.0855675344 - parameters are 2.03265818948 8.03496805885 4.5320103176\n",
      "Iteration 800 - loss is 8.57686395238 - parameters are 2.03389230037 8.04060492042 4.533181434\n",
      "Iteration 900 - loss is 9.71039847281 - parameters are 2.03055417397 8.03520210623 4.53320105542\n",
      "Iteration 1000 - loss is 13.5756790802 - parameters are 2.03755311775 8.04200682114 4.53508463035\n",
      "Epoch 150\n",
      "Iteration 100 - loss is 11.1821691422 - parameters are 2.02313570712 8.02890258196 4.53414553658\n",
      "Iteration 200 - loss is 12.2227867548 - parameters are 2.02882150637 8.03219824947 4.53573675872\n",
      "Iteration 300 - loss is 8.60379672074 - parameters are 2.02459891842 8.03020241798 4.53581751612\n",
      "Iteration 400 - loss is 9.97378679425 - parameters are 2.02976310825 8.03679349293 4.53698042301\n",
      "Iteration 500 - loss is 10.5752736871 - parameters are 2.020820744 8.02547099824 4.5363413771\n",
      "Iteration 600 - loss is 9.474624157 - parameters are 2.03378851536 8.03633317055 4.5386173712\n",
      "Iteration 700 - loss is 10.0501686282 - parameters are 2.03218349159 8.03449217472 4.53888855097\n",
      "Iteration 800 - loss is 8.52940116416 - parameters are 2.03341674232 8.04012205712 4.54004731752\n",
      "Iteration 900 - loss is 9.66747529674 - parameters are 2.03010748041 8.03473962466 4.54005910061\n",
      "Iteration 1000 - loss is 13.5096199243 - parameters are 2.03707613163 8.04150726943 4.54192703759\n",
      "Epoch 151\n",
      "Iteration 100 - loss is 11.1126436076 - parameters are 2.02273023624 8.02847520662 4.54098506476\n",
      "Iteration 200 - loss is 12.1515882224 - parameters are 2.02836064719 8.03171770263 4.54255522411\n",
      "Iteration 300 - loss is 8.56958141659 - parameters are 2.02417592976 8.02975710601 4.54263098726\n",
      "Iteration 400 - loss is 9.94610403462 - parameters are 2.02931542021 8.03633889247 4.54378128156\n",
      "Iteration 500 - loss is 10.5275249063 - parameters are 2.0203809814 8.02502306956 4.54313448076\n",
      "Iteration 600 - loss is 9.42610896847 - parameters are 2.03332121458 8.03586582324 4.54539524558\n",
      "Iteration 700 - loss is 10.0160237786 - parameters are 2.03171652205 8.03402393176 4.5456563689\n",
      "Iteration 800 - loss is 8.48349141276 - parameters are 2.03294892 8.03964693748 4.54680298699\n",
      "Iteration 900 - loss is 9.62599931031 - parameters are 2.0296680584 8.03428456642 4.54680706115\n",
      "Iteration 1000 - loss is 13.4453613266 - parameters are 2.03660689951 8.04101572256 4.54865961483\n",
      "Epoch 152\n",
      "Iteration 100 - loss is 11.0451233475 - parameters are 2.02233137858 8.02805469862 4.54771481313\n",
      "Iteration 200 - loss is 12.0824912481 - parameters are 2.02790727552 8.03124484231 4.54926425039\n",
      "Iteration 300 - loss is 8.53658646203 - parameters are 2.023759837 8.02931893975 4.54933510438\n",
      "Iteration 400 - loss is 9.91955648297 - parameters are 2.02887500966 8.03589156904 4.55047299014\n",
      "Iteration 500 - loss is 10.4811274767 - parameters are 2.01994837884 8.02458233235 4.54981856365\n",
      "Iteration 600 - loss is 9.37916536472 - parameters are 2.03286150263 8.03540595785 4.55206434588\n",
      "Iteration 700 - loss is 9.98309060145 - parameters are 2.03125715086 8.03356320479 4.55231557994\n",
      "Iteration 800 - loss is 8.43908405573 - parameters are 2.03248870346 8.03917943493 4.55345024755\n",
      "Iteration 900 - loss is 9.58592266274 - parameters are 2.02923578565 8.03383680997 4.55344673997\n",
      "Iteration 1000 - loss is 13.3828502218 - parameters are 2.0361452913 8.04053204988 4.5552841607\n",
      "Epoch 153\n",
      "Iteration 100 - loss is 10.9795472626 - parameters are 2.02193902254 8.02764094531 4.55433657939\n",
      "Iteration 200 - loss is 12.0154309629 - parameters are 2.0274612659 8.03077954351 4.55586562958\n",
      "Iteration 300 - loss is 8.50477054266 - parameters are 2.02335052385 8.02888780228 4.55593165798\n",
      "Iteration 400 - loss is 9.89410359403 - parameters are 2.02844175453 8.03545140412 4.55705733584\n",
      "Iteration 500 - loss is 10.4360406575 - parameters are 2.01952281587 8.02414866881 4.5563954106\n",
      "Iteration 600 - loss is 9.33374239565 - parameters are 2.03240925244 8.0349534525 4.55862645281\n",
      "Iteration 700 - loss is 9.95132812945 - parameters are 2.03080525033 8.03310987075 4.55886796188\n",
      "Iteration 800 - loss is 8.39613011545 - parameters are 2.0320359651 8.03871942503 4.55999087368\n",
      "Iteration 900 - loss is 9.54719908653 - parameters are 2.02881054203 8.03339623583 4.55997990933\n",
      "Iteration 1000 - loss is 13.3220351984 - parameters are 2.03569117925 8.04005612295 4.56180244327\n",
      "Epoch 154\n",
      "Iteration 100 - loss is 10.9158561902 - parameters are 2.02155305849 8.02723383593 4.56085213065\n",
      "Iteration 200 - loss is 11.9503445671 - parameters are 2.02702249506 8.0303216833 4.56236112323\n",
      "Iteration 300 - loss is 8.47409372412 - parameters are 2.0229478761 8.02846357866 4.5624224081\n",
      "Iteration 400 - loss is 9.86970620919 - parameters are 2.0280155349 8.03501828117 4.56353607536\n",
      "Iteration 500 - loss is 10.3922249927 - parameters are 2.01910417416 8.02372196315 4.5628667761\n",
      "Iteration 600 - loss is 9.28979077908 - parameters are 2.03196433921 8.03450818733 4.56508331681\n",
      "Iteration 700 - loss is 9.92069676457 - parameters are 2.03036069504 8.03266380867 4.56531526231\n",
      "Iteration 800 - loss is 8.35458222344 - parameters are 2.03159057955 8.03826678546 4.56642660966\n",
      "Iteration 900 - loss is 9.50978384434 - parameters are 2.02839220958 8.03296272656 4.56640831138\n",
      "Iteration 1000 - loss is 13.2628664449 - parameters are 2.03524443783 8.03958781551 4.56821620055\n",
      "Epoch 155\n",
      "Iteration 100 - loss is 10.8539928404 - parameters are 2.02117337879 8.02683326162 4.56726320404\n",
      "Iteration 200 - loss is 11.8871712629 - parameters are 2.02659084194 8.02987114083 4.56875246301\n",
      "Iteration 300 - loss is 8.44451740559 - parameters are 2.02255178159 8.02804615591 4.56880908489\n",
      "Iteration 400 - loss is 9.8463265094 - parameters are 2.02759623297 8.03459208562 4.56991093559\n",
      "Iteration 500 - loss is 10.3496422691 - parameters are 2.01869233753 8.02330210155 4.56923438486\n",
      "Iteration 600 - loss is 9.24726284515 - parameters are 2.03152664031 8.03407004452 4.57143665861\n",
      "Iteration 700 - loss is 9.89115823178 - parameters are 2.02992336182 8.03222489962 4.57165919914\n",
      "Iteration 800 - loss is 8.31439456656 - parameters are 2.0311524237 8.03782139596 4.5727591702\n",
      "Iteration 900 - loss is 9.47363367768 - parameters are 2.02798067241 8.0325361667 4.57273365873\n",
      "Iteration 1000 - loss is 13.2052956975 - parameters are 2.03480494377 8.03912700342 4.57452714107\n",
      "Epoch 156\n",
      "Iteration 100 - loss is 10.793901735 - parameters are 2.02079987769 8.02643911537 4.57357150719\n",
      "Iteration 200 - loss is 11.8258521881 - parameters are 2.02616618759 8.02942779726 4.57504135117\n",
      "Iteration 300 - loss is 8.41600427503 - parameters are 2.02216213016 8.02763542294 4.57509338917\n",
      "Iteration 400 - loss is 9.82392796961 - parameters are 2.02718373305 8.0341727048 4.57618361412\n",
      "Iteration 500 - loss is 10.308255476 - parameters are 2.01828719184 8.02288897212 4.57549993232\n",
      "Iteration 600 - loss is 9.20611248264 - parameters are 2.03109603528 8.03363890823 4.57768816979\n",
      "Iteration 700 - loss is 9.86267553455 - parameters are 2.02949312967 8.03179302672 4.57790146119\n",
      "Iteration 800 - loss is 8.27552283506 - parameters are 2.03072137659 8.03738313829 4.57899024094\n",
      "Iteration 900 - loss is 9.43870675738 - parameters are 2.02757581669 8.03211644274 4.57895763492\n",
      "Iteration 1000 - loss is 13.1492761901 - parameters are 2.03437257597 8.03867356463 4.58073694442\n",
      "Epoch 157\n",
      "Iteration 100 - loss is 10.7355291482 - parameters are 2.02043245135 8.02605129199 4.57977871881\n",
      "Iteration 200 - loss is 11.7663303531 - parameters are 2.02574841519 8.02899153575 4.58122946115\n",
      "Iteration 300 - loss is 8.38851826588 - parameters are 2.0217788136 8.02723127057 4.58127699294\n",
      "Iteration 400 - loss is 9.8024753148 - parameters are 2.02677792148 8.03376002797 4.5823557798\n",
      "Iteration 500 - loss is 10.2680287652 - parameters are 2.01788862498 8.02248246484 4.58166508524\n",
      "Iteration 600 - loss is 9.16629508712 - parameters are 2.03067240582 8.03321466456 4.58383951325\n",
      "Iteration 700 - loss is 9.83521291184 - parameters are 2.02906987974 8.03136807504 4.58404370865\n",
      "Iteration 800 - loss is 8.23792417241 - parameters are 2.03029731941 8.03695189623 4.58512147899\n",
      "Iteration 900 - loss is 9.40496263572 - parameters are 2.02717753062 8.03170344311 4.58508189504\n",
      "Iteration 1000 - loss is 13.0947626059 - parameters are 2.03394721544 8.03822737915 4.58684726174\n",
      "Epoch 158\n",
      "Iteration 100 - loss is 10.6788230495 - parameters are 2.02007099779 8.02566968807 4.58588648921\n",
      "Iteration 200 - loss is 11.708550579 - parameters are 2.02533740995 8.0285622414 4.58731843806\n",
      "Iteration 300 - loss is 8.36202451522 - parameters are 2.02140172566 8.02683359142 4.58736153991\n",
      "Iteration 400 - loss is 9.78193447755 - parameters are 2.02637868659 8.0333539462 4.58842907322\n",
      "Iteration 500 - loss is 10.2289274141 - parameters are 2.01749652683 8.0220824716 4.58773148215\n",
      "Iteration 600 - loss is 9.12776751086 - parameters are 2.03025563565 8.03279720151 4.58989232376\n",
      "Iteration 700 - loss is 9.80873579654 - parameters are 2.02865349526 8.0309499316 4.59008757365\n",
      "Iteration 800 - loss is 8.20155712687 - parameters are 2.02988013545 8.03652755549 4.59115451341\n",
      "Iteration 900 - loss is 9.37236220029 - parameters are 2.02678570437 8.0312970581 4.59110806616\n",
      "Iteration 1000 - loss is 13.04171103 - parameters are 2.03352874532 8.037788329 4.59285971626\n",
      "Epoch 159\n",
      "Iteration 100 - loss is 10.6237330484 - parameters are 2.01971541683 8.02529420196 4.59189644077\n",
      "Iteration 200 - loss is 11.6524594391 - parameters are 2.0249330591 8.02813980125 4.5933098992\n",
      "Iteration 300 - loss is 8.33648932345 - parameters are 2.02103076193 8.02644227996 4.59334864601\n",
      "Iteration 400 - loss is 9.76227255706 - parameters are 2.02598591871 8.03295435242 4.59440510727\n",
      "Iteration 500 - loss is 10.190917788 - parameters are 2.01711078921 8.02168888606 4.59370073392\n",
      "Iteration 600 - loss is 9.09048801449 - parameters are 2.02984561058 8.03238640897 4.59584820849\n",
      "Iteration 700 - loss is 9.78321077536 - parameters are 2.02824386156 8.03053848533 4.59603466075\n",
      "Iteration 800 - loss is 8.16638160469 - parameters are 2.02946971005 8.03611000373 4.59709094577\n",
      "Iteration 900 - loss is 9.34086762932 - parameters are 2.02640023004 8.03089717987 4.59703774788\n",
      "Iteration 1000 - loss is 12.9900789046 - parameters are 2.03311705079 8.03735629817 4.5987759038\n",
      "Epoch 160\n",
      "Iteration 100 - loss is 10.5702103407 - parameters are 2.01936561005 8.02492473372 4.59781016849\n",
      "Iteration 200 - loss is 11.5980052008 - parameters are 2.02453525188 8.02772410421 4.59920543456\n",
      "Iteration 300 - loss is 8.31188011527 - parameters are 2.02066581988 8.02605723243 4.59923989988\n",
      "Iteration 400 - loss is 9.74345777958 - parameters are 2.02559951006 8.03256114135 4.60028546757\n",
      "Iteration 500 - loss is 10.1539673057 - parameters are 2.01673130586 8.02130160374 4.5995744242\n",
      "Iteration 600 - loss is 9.0544162202 - parameters are 2.02944221839 8.03198217867 4.60170874748\n",
      "Iteration 700 - loss is 9.7586055501 - parameters are 2.02784086597 8.03013362704 4.60188654742\n",
      "Iteration 800 - loss is 8.13235882493 - parameters are 2.02906593057 8.03569913048 4.60293235058\n",
      "Iteration 900 - loss is 9.31044234863 - parameters are 2.02602100164 8.03050370239 4.6028725128\n",
      "Iteration 1000 - loss is 12.9398249849 - parameters are 2.03271201903 8.03693117261 4.60459739325\n",
      "Epoch 161\n",
      "Iteration 100 - loss is 10.5182076573 - parameters are 2.0190214808 8.02456118512 4.60362924047\n",
      "Iteration 200 - loss is 11.5451377708 - parameters are 2.02414387943 8.02731504104 4.60500660731\n",
      "Iteration 300 - loss is 8.28816540203 - parameters are 2.02030679878 8.0256783468 4.60503686338\n",
      "Iteration 400 - loss is 9.7254594602 - parameters are 2.02521935477 8.03217420944 4.60607171305\n",
      "Iteration 500 - loss is 10.1180444045 - parameters are 2.01635797238 8.02092052186 4.60535410995\n",
      "Iteration 600 - loss is 9.0195130667 - parameters are 2.02904534884 8.03158440414 4.60747549409\n",
      "Iteration 700 - loss is 9.73488890026 - parameters are 2.02744439778 8.02973524938 4.60764478453\n",
      "Iteration 800 - loss is 8.09945127581 - parameters are 2.02866868633 8.03529482714 4.60868027585\n",
      "Iteration 900 - loss is 9.28105098997 - parameters are 2.02564791503 8.03011652141 4.60861390703\n",
      "Iteration 1000 - loss is 12.8909092967 - parameters are 2.03231353922 8.03651284018 4.61032572707\n",
      "Epoch 162\n",
      "Iteration 100 - loss is 10.467679214 - parameters are 2.01868293414 8.02420345957 4.60935519838\n",
      "Iteration 200 - loss is 11.4938086418 - parameters are 2.02375883481 8.02691250434 4.61071495429\n",
      "Iteration 300 - loss is 8.26531474537 - parameters are 2.01995359969 8.02530552278 4.61074107205\n",
      "Iteration 400 - loss is 9.7082479659 - parameters are 2.02484534883 8.03179345489 4.61176537634\n",
      "Iteration 500 - loss is 10.0831185076 - parameters are 2.01599068623 8.02054553941 4.61104132192\n",
      "Iteration 600 - loss is 8.98574076553 - parameters are 2.02865489361 8.03119298071 4.61314997557\n",
      "Iteration 700 - loss is 9.71203064687 - parameters are 2.02705434827 8.0293432468 4.61331089686\n",
      "Iteration 800 - loss is 8.06762267253 - parameters are 2.02827786861 8.03489698691 4.6143362435\n",
      "Iteration 900 - loss is 9.25265935089 - parameters are 2.02528086793 8.02973553446 4.61426345063\n",
      "Iteration 1000 - loss is 12.8432930956 - parameters are 2.03192150246 8.03610119062 4.61596242174\n",
      "Epoch 163\n",
      "Iteration 100 - loss is 10.4185806635 - parameters are 2.01834987678 8.02385146211 4.61498955793\n",
      "Iteration 200 - loss is 11.4439708401 - parameters are 2.02338001296 8.02651638846 4.61633198645\n",
      "Iteration 300 - loss is 8.24329872207 - parameters are 2.01960612541 8.02493866175 4.61635403559\n",
      "Iteration 400 - loss is 9.69179468 - parameters are 2.02447739005 8.03141877762 4.61736796429\n",
      "Iteration 500 - loss is 10.0491599921 - parameters are 2.01562934664 8.02017655708 4.61663756507\n",
      "Iteration 600 - loss is 8.95306275899 - parameters are 2.02827074627 8.03080780543 4.61873369345\n",
      "Iteration 700 - loss is 9.69000161763 - parameters are 2.02667061059 8.02895751553 4.61888638351\n",
      "Iteration 800 - loss is 8.03683791658 - parameters are 2.0278933706 8.0345055048 4.61990174985\n",
      "Iteration 900 - loss is 9.22523435582 - parameters are 2.02491975982 8.02936064076 4.61982263811\n",
      "Iteration 1000 - loss is 12.7969388276 - parameters are 2.03153580177 8.03569611549 4.62150896823\n",
      "Epoch 164\n",
      "Iteration 100 - loss is 10.3708690485 - parameters are 2.0180222171 8.02350509941 4.62053380935\n",
      "Iteration 200 - loss is 11.3955788764 - parameters are 2.02300731063 8.02612658956 4.62185918936\n",
      "Iteration 300 - loss is 8.22208889011 - parameters are 2.01926428045 8.02457766676 4.6218772383\n",
      "Iteration 400 - loss is 9.67607196768 - parameters are 2.024115378 8.03105007917 4.62288095842\n",
      "Iteration 500 - loss is 10.0161401579 - parameters are 2.01527385463 8.01981347722 4.6221443191\n",
      "Iteration 600 - loss is 8.92144367943 - parameters are 2.02789280224 8.03042877709 4.62422812401\n",
      "Iteration 700 - loss is 9.6687736132 - parameters are 2.02629307979 8.02857795354 4.62437271841\n",
      "Iteration 800 - loss is 8.00706305635 - parameters are 2.02751508731 8.03412027757 4.62537826607\n",
      "Iteration 900 - loss is 9.19874401867 - parameters are 2.02456449195 8.02899174124 4.62529293886\n",
      "Iteration 1000 - loss is 12.7518100907 - parameters are 2.03115633202 8.03529750819 4.6269668325\n",
      "Epoch 165\n",
      "Iteration 100 - loss is 10.324502757 - parameters are 2.01769986508 8.02316427968 4.62598941785\n",
      "Iteration 200 - loss is 11.3485886973 - parameters are 2.02264062639 8.02574300547 4.62729802363\n",
      "Iteration 300 - loss is 8.20165775591 - parameters are 2.01892797098 8.02422244246 4.62731213958\n",
      "Iteration 400 - loss is 9.66105314274 - parameters are 2.02375921404 8.03068726275 4.62830581536\n",
      "Iteration 500 - loss is 9.98403119819 - parameters are 2.01492411294 8.01945620381 4.62756303882\n",
      "Iteration 600 - loss is 8.89084930992 - parameters are 2.02752095877 8.03005579616 4.62963471876\n",
      "Iteration 700 - loss is 9.64831937463 - parameters are 2.02592165272 8.02820446052 4.62977135073\n",
      "Iteration 800 - loss is 7.97826524919 - parameters are 2.02714291564 8.03374120372 4.63076723866\n",
      "Iteration 900 - loss is 9.17315740651 - parameters are 2.0242149673 8.02862873849 4.63067579761\n",
      "Iteration 1000 - loss is 12.7078715977 - parameters are 2.03078298991 8.03490526389 4.63233745586\n",
      "Epoch 166\n",
      "Iteration 100 - loss is 10.2794414785 - parameters are 2.01738273229 8.02282891268 4.63135782403\n",
      "Iteration 200 - loss is 11.3029576385 - parameters are 2.02227986055 8.02536553576 4.63264992535\n",
      "Iteration 300 - loss is 8.18197874265 - parameters are 2.01859710486 8.02387289513 4.63266017434\n",
      "Iteration 400 - loss is 9.64671243555 - parameters are 2.0234088012 8.03033023319 4.63364396733\n",
      "Iteration 500 - loss is 9.95280617037 - parameters are 2.01458002602 8.01910464247 4.63289515469\n",
      "Iteration 600 - loss is 8.86124654628 - parameters are 2.02715511488 8.02968876475 4.63495490486\n",
      "Iteration 700 - loss is 9.62861255193 - parameters are 2.02555622806 8.02783693784 4.63508370536\n",
      "Iteration 800 - loss is 7.95041272464 - parameters are 2.02677675425 8.03336818343 4.63607008985\n",
      "Iteration 900 - loss is 9.14844460462 - parameters are 2.02387109054 8.02827153672 4.63597263487\n",
      "Iteration 1000 - loss is 12.6650891412 - parameters are 2.03041567395 8.0345192795 4.63762225548\n",
      "Epoch 167\n",
      "Iteration 100 - loss is 10.2356461623 - parameters are 2.01707073185 8.02249890971 4.63664044435\n",
      "Iteration 200 - loss is 11.2586443797 - parameters are 2.02192491517 8.02499408163 4.63791630654\n",
      "Iteration 300 - loss is 8.16302615968 - parameters are 2.01827159152 8.02352893259 4.63792275343\n",
      "Iteration 400 - loss is 9.63302496199 - parameters are 2.02306404425 8.02997889687 4.63889682251\n",
      "Iteration 500 - loss is 9.92243896827 - parameters are 2.0142415 8.01875870037 4.63814207314\n",
      "Iteration 600 - loss is 8.83260336037 - parameters are 2.02679517134 8.02932758662 4.64019008555\n",
      "Iteration 700 - loss is 9.60962767372 - parameters are 2.02519670624 8.02747528852 4.64031118328\n",
      "Iteration 800 - loss is 7.92347474896 - parameters are 2.02641650357 8.03300111855 4.64128821803\n",
      "Iteration 900 - loss is 9.12457668266 - parameters are 2.02353276801 8.02792004177 4.64118484734\n",
      "Iteration 1000 - loss is 12.6234295583 - parameters are 2.0300542844 8.03413945366 4.6428226248\n",
      "Epoch 168\n",
      "Iteration 100 - loss is 10.1930789763 - parameters are 2.01676377838 8.02217418352 4.64183867155\n",
      "Iteration 200 - loss is 11.2156089015 - parameters are 2.021575694 8.02462854595 4.64309855559\n",
      "Iteration 300 - loss is 8.14477517296 - parameters are 2.017951342 8.02319046422 4.64310126406\n",
      "Iteration 400 - loss is 9.61996669354 - parameters are 2.02272484956 8.02963316176 4.64406576553\n",
      "Iteration 500 - loss is 9.89290429521 - parameters are 2.0139084426 8.01841828627 4.6433051771\n",
      "Iteration 600 - loss is 8.80488876462 - parameters are 2.02644103066 8.02897216711 4.64534164059\n",
      "Iteration 700 - loss is 9.59134011781 - parameters are 2.02484298943 8.02711941721 4.64545516205\n",
      "Iteration 800 - loss is 7.89742159091 - parameters are 2.02606206575 8.03263991258 4.64642299819\n",
      "Iteration 900 - loss is 9.10152566201 - parameters are 2.02319990766 8.02757416102 4.64631380836\n",
      "Iteration 1000 - loss is 12.5828606977 - parameters are 2.02969872326 8.03376568668 4.64793993391\n",
      "Epoch 169\n",
      "Iteration 100 - loss is 10.1517032681 - parameters are 2.01646178802 8.02185464837 4.64695387506\n",
      "Iteration 200 - loss is 11.1738124428 - parameters are 2.02123210245 8.02426883318 4.64819803764\n",
      "Iteration 300 - loss is 8.12720177649 - parameters are 2.01763626887 8.02285740091 4.64819707028\n",
      "Iteration 400 - loss is 9.60751442833 - parameters are 2.02239112517 8.02929293733 4.64915215783\n",
      "Iteration 500 - loss is 9.86417763793 - parameters are 2.0135807632 8.01808331042 4.64838582636\n",
      "Iteration 600 - loss is 8.77807277775 - parameters are 2.026092597 8.02862241316 4.65041092665\n",
      "Iteration 700 - loss is 9.57372608296 - parameters are 2.0244949815 8.02676923015 4.65051699618\n",
      "Iteration 800 - loss is 7.87222448854 - parameters are 2.02571334466 8.03228447062 4.65147578236\n",
      "Iteration 900 - loss is 9.0792644842 - parameters are 2.02287241906 8.02723380342 4.65136086831\n",
      "Iteration 1000 - loss is 12.5433513874 - parameters are 2.02934889421 8.03339788055 4.65297553003\n",
      "Epoch 170\n",
      "Iteration 100 - loss is 10.1114835269 - parameters are 2.01616467836 8.02154021992 4.65198740141\n",
      "Iteration 200 - loss is 11.1332174602 - parameters are 2.02089404757 8.02391484937 4.65321609502\n",
      "Iteration 300 - loss is 8.11028276475 - parameters are 2.01732628626 8.02252965504 4.65321151329\n",
      "Iteration 400 - loss is 9.5956457632 - parameters are 2.02206278067 8.02895813457 4.65415733812\n",
      "Iteration 500 - loss is 9.83623524143 - parameters are 2.01325837273 8.0177536846 4.65338535795\n",
      "Iteration 600 - loss is 8.75212639165 - parameters are 2.02574977621 8.02827823323 4.65539927773\n",
      "Iteration 700 - loss is 9.55676256141 - parameters are 2.02415258798 8.02642463515 4.65549801756\n",
      "Iteration 800 - loss is 7.84785561731 - parameters are 2.02537024581 8.03193469933 4.65644789994\n",
      "Iteration 900 - loss is 9.05776698043 - parameters are 2.02255021333 8.02689887944 4.656327355\n",
      "Iteration 1000 - loss is 12.5048714031 - parameters are 2.0290047026 8.03303593887 4.65793073786\n",
      "Epoch 171\n",
      "Iteration 100 - loss is 10.0723853467 - parameters are 2.01587236844 8.02123081525 4.65694057467\n",
      "Iteration 200 - loss is 11.0937875886 - parameters are 2.02056143802 8.02356650211 4.65815404764\n",
      "Iteration 300 - loss is 8.09399570604 - parameters are 2.01702130975 8.02220714043 4.65814591194\n",
      "Iteration 400 - loss is 9.58433906672 - parameters are 2.02173972724 8.02862866594 4.65908262276\n",
      "Iteration 500 - loss is 9.80905408462 - parameters are 2.01294118365 8.01742932205 4.65830508664\n",
      "Iteration 600 - loss is 8.72702153942 - parameters are 2.02541247573 8.02793953729 4.66030800558\n",
      "Iteration 700 - loss is 9.54042731245 - parameters are 2.02381571604 8.02608554155 4.66039953585\n",
      "Iteration 800 - loss is 7.82428805907 - parameters are 2.02503267636 8.03159050697 4.66134065817\n",
      "Iteration 900 - loss is 9.03700784208 - parameters are 2.02223320315 8.02656930105 4.66121457409\n",
      "Iteration 1000 - loss is 12.4673914386 - parameters are 2.02866605542 8.03267976686 4.66280686\n",
      "Epoch 172\n",
      "Iteration 100 - loss is 10.0343753908 - parameters are 2.01558477869 8.02092635285 4.6618146968\n",
      "Iteration 200 - loss is 11.0554876034 - parameters are 2.02023418402 8.02322370053 4.66301319341\n",
      "Iteration 300 - loss is 8.07831891671 - parameters are 2.01672125644 8.02188977238 4.66300156306\n",
      "Iteration 400 - loss is 9.57357345313 - parameters are 2.02142187759 8.02830444533 4.66392930613\n",
      "Iteration 500 - loss is 9.7826118568 - parameters are 2.01262910997 8.01711013746 4.66314630523\n",
      "Iteration 600 - loss is 8.70273106437 - parameters are 2.02508060463 8.02760623683 4.66513840005\n",
      "Iteration 700 - loss is 9.52469883689 - parameters are 2.02348427447 8.0257518602 4.66522283886\n",
      "Iteration 800 - loss is 7.80149577225 - parameters are 2.02470054506 8.03125180329 4.66615534248\n",
      "Iteration 900 - loss is 9.01696259227 - parameters are 2.02192130268 8.02624498166 4.66602380948\n",
      "Iteration 1000 - loss is 12.4308830763 - parameters are 2.02833286126 8.03232927128 4.66760517734\n",
      "Epoch 173\n",
      "Iteration 100 - loss is 9.99742135734 - parameters are 2.01530183094 8.02062675254 4.66661104805\n",
      "Iteration 200 - loss is 11.0182833835 - parameters are 2.01991219736 8.02288635526 4.66779480858\n",
      "Iteration 300 - loss is 8.06323143626 - parameters are 2.01642604481 8.02157746755 4.66777974185\n",
      "Iteration 400 - loss is 9.5633287571 - parameters are 2.02110914592 8.02798538809 4.66869866107\n",
      "Iteration 500 - loss is 9.7568869349 - parameters are 2.01232206716 8.01679604694 4.66791028498\n",
      "Iteration 600 - loss is 8.67922869018 - parameters are 2.0247540735 8.02727824479 4.66989172952\n",
      "Iteration 700 - loss is 9.50955635231 - parameters are 2.0231581736 8.02542350346 4.66996919294\n",
      "Iteration 800 - loss is 7.77945356294 - parameters are 2.02437376225 8.03091849954 4.6708932169\n",
      "Iteration 900 - loss is 8.99760755832 - parameters are 2.02161442759 8.02592583614 4.67075632366\n",
      "Iteration 1000 - loss is 12.395318759 - parameters are 2.02800503028 8.03198436047 4.67232694942\n",
      "Epoch 174\n",
      "Iteration 100 - loss is 9.96149194637 - parameters are 2.01502344835 8.02033193549 4.67133088736\n",
      "Iteration 200 - loss is 10.9821418758 - parameters are 2.01959539131 8.02255437839 4.67250014815\n",
      "Iteration 300 - loss is 8.04871300334 - parameters are 2.0161355948 8.02127014402 4.67248170232\n",
      "Iteration 400 - loss is 9.55358550949 - parameters are 2.02080144793 8.02767141093 4.67339193919\n",
      "Iteration 500 - loss is 9.73185836148 - parameters are 2.01201997216 8.01648696801 4.672598276\n",
      "Iteration 600 - loss is 8.65648899198 - parameters are 2.0244327945 8.02695547553 4.67456924124\n",
      "Iteration 700 - loss is 9.49497976924 - parameters are 2.02283732536 8.02510038513 4.67463984339\n",
      "Iteration 800 - loss is 7.75813705703 - parameters are 2.02405223979 8.03059050846 4.67555552441\n",
      "Iteration 900 - loss is 8.97891984521 - parameters are 2.02131249499 8.02561178078 4.67541335813\n",
      "Iteration 1000 - loss is 12.3606717626 - parameters are 2.0276824742 8.03164494427 4.67697341484\n",
      "Epoch 175\n",
      "Iteration 100 - loss is 9.92655682749 - parameters are 2.01474955545 8.0200418242 4.67597545272\n",
      "Iteration 200 - loss is 10.9470310606 - parameters are 2.01928368067 8.02222768347 4.67713044625\n",
      "Iteration 300 - loss is 8.03474403247 - parameters are 2.01584982772 8.02096772122 4.67710867756\n",
      "Iteration 400 - loss is 9.54432491373 - parameters are 2.02049870073 8.02736243198 4.67801037131\n",
      "Iteration 500 - loss is 9.70750582344 - parameters are 2.01172274336 8.01618281954 4.67721150759\n",
      "Iteration 600 - loss is 8.63448736845 - parameters are 2.02411668129 8.02663784486 4.67917216171\n",
      "Iteration 700 - loss is 9.48094966808 - parameters are 2.02252164314 8.02478242045 4.67923601477\n",
      "Iteration 800 - loss is 7.73752267323 - parameters are 2.02373589107 8.03026774423 4.68014348732\n",
      "Iteration 900 - loss is 8.96087730983 - parameters are 2.02101542343 8.02530273325 4.67999613374\n",
      "Iteration 1000 - loss is 12.3269161701 - parameters are 2.02736510623 8.03131093402 4.68154579159\n",
      "Epoch 176\n",
      "Iteration 100 - loss is 9.89258660891 - parameters are 2.01448007805 8.01975634245 4.68054596154\n",
      "Iteration 200 - loss is 10.9129199189 - parameters are 2.01897698167 8.02190618549 4.68168691649\n",
      "Iteration 300 - loss is 8.02130559157 - parameters are 2.01556866622 8.02067011993 4.68166188022\n",
      "Iteration 400 - loss is 9.53552882321 - parameters are 2.0202008229 8.02705837069 4.68255516777\n",
      "Iteration 500 - loss is 9.6838096315 - parameters are 2.01143030052 8.01588352177 4.68175118864\n",
      "Iteration 600 - loss is 8.61320001482 - parameters are 2.02380564899 8.02632526996 4.68370169707\n",
      "Iteration 700 - loss is 9.46744727683 - parameters are 2.02221104186 8.02446952605 4.68375891131\n",
      "Iteration 800 - loss is 7.717587597 - parameters are 2.02342463097 8.02995012244 4.68465830763\n",
      "Iteration 900 - loss is 8.9434585362 - parameters are 2.02072313285 8.02499861259 4.68450585105\n",
      "Iteration 1000 - loss is 12.2940268455 - parameters are 2.02705284108 8.03098224252 4.68604527743\n",
      "Epoch 177\n",
      "Iteration 100 - loss is 9.85955280741 - parameters are 2.01421494324 8.01947541529 4.685043611\n",
      "Iteration 200 - loss is 10.8797783994 - parameters are 2.01867521197 8.02158980081 4.68617075231\n",
      "Iteration 300 - loss is 8.00837938034 - parameters are 2.01529203432 8.02037726222 4.68614250277\n",
      "Iteration 400 - loss is 9.52717971929 - parameters are 2.01990773439 8.02675914785 4.68702751882\n",
      "Iteration 500 - loss is 9.66075070026 - parameters are 2.01114256481 8.01558899626 4.68621850795\n",
      "Iteration 600 - loss is 8.59260389677 - parameters are 2.02349961419 8.02601766938 4.68815903339\n",
      "Iteration 700 - loss is 9.45445444957 - parameters are 2.02190543788 8.02416161998 4.68820971724\n",
      "Iteration 800 - loss is 7.69830975537 - parameters are 2.02311837583 8.0296375601 4.6891011674\n",
      "Iteration 900 - loss is 8.92664281144 - parameters are 2.02043554457 8.0246993392 4.68894369069\n",
      "Iteration 1000 - loss is 12.2619794095 - parameters are 2.02674559492 8.03065878401 4.69047305023\n",
      "Epoch 178\n",
      "Iteration 100 - loss is 9.82742781929 - parameters are 2.01395407937 8.01919896901 4.68946957841\n",
      "Iteration 200 - loss is 10.8475773885 - parameters are 2.01837829067 8.02127844718 4.69058312736\n",
      "Iteration 300 - loss is 7.99594770919 - parameters are 2.01501985733 8.02008907147 4.69055171791\n",
      "Iteration 400 - loss is 9.5192606901 - parameters are 2.01961935652 8.02646468554 4.69142859495\n",
      "Iteration 500 - loss is 9.63831052901 - parameters are 2.01085945875 8.01529916587 4.69061463459\n",
      "Iteration 600 - loss is 8.57267672523 - parameters are 2.0231984949 8.02571496301 4.69254533711\n",
      "Iteration 700 - loss is 9.44195364564 - parameters are 2.02160474902 8.02385862161 4.69258959713\n",
      "Iteration 800 - loss is 7.6796677926 - parameters are 2.0228170434 8.02932997557 4.69347322906\n",
      "Iteration 900 - loss is 8.91041010262 - parameters are 2.02015258125 8.02440483477 4.69331081373\n",
      "Iteration 1000 - loss is 12.2307502157 - parameters are 2.02644328536 8.03034047416 4.69483026836\n",
      "Epoch 179\n",
      "Iteration 100 - loss is 9.79618489234 - parameters are 2.01369741605 8.01892693113 4.69382502157\n",
      "Iteration 200 - loss is 10.8162886791 - parameters are 2.01808613823 8.02097204369 4.69492519582\n",
      "Iteration 300 - loss is 7.98399347903 - parameters are 2.01475206185 8.01980547233 4.69489067888\n",
      "Iteration 400 - loss is 9.51175541009 - parameters are 2.01933561195 8.02617490714 4.69575954726\n",
      "Iteration 500 - loss is 9.61647118308 - parameters are 2.01058090618 8.01501395473 4.69494071826\n",
      "Iteration 600 - loss is 8.55339693202 - parameters are 2.02290221053 8.02541707206 4.6968617553\n",
      "Iteration 700 - loss is 9.42992790952 - parameters are 2.02130889448 8.02356045169 4.69689969628\n",
      "Iteration 800 - loss is 7.66164104666 - parameters are 2.02252055288 8.02902728858 4.69777563579\n",
      "Iteration 900 - loss is 8.89474103432 - parameters are 2.01987416689 8.02411502232 4.69760836197\n",
      "Iteration 1000 - loss is 12.2003163272 - parameters are 2.02614583141 8.03002723001 4.69911807094\n",
      "Epoch 180\n",
      "Iteration 100 - loss is 9.7657980986 - parameters are 2.01344488407 8.01865923038 4.69811107908\n",
      "Iteration 200 - loss is 10.7858849424 - parameters are 2.01779867646 8.0206705108 4.69919809274\n",
      "Iteration 300 - loss is 7.97250016165 - parameters are 2.01448857573 8.01952639069 4.69916051985\n",
      "Iteration 400 - loss is 9.5046481202 - parameters are 2.01905642469 8.0258897373 4.70002150777\n",
      "Iteration 500 - loss is 9.5952152759 - parameters are 2.01030683225 8.01473328825 4.69919788962\n",
      "Iteration 600 - loss is 8.53474364624 - parameters are 2.02261068185 8.02512391905 4.70110941604\n",
      "Iteration 700 - loss is 9.41836085145 - parameters are 2.02101779485 8.02326703224 4.70114114099\n",
      "Iteration 800 - loss is 7.64420952645 - parameters are 2.0222288248 8.02872942018 4.70200951183\n",
      "Iteration 900 - loss is 8.87961686696 - parameters are 2.01960022678 8.02382982611 4.70183745832\n",
      "Iteration 1000 - loss is 12.1706554945 - parameters are 2.02585315347 8.02971896997 4.70333757828\n",
      "Epoch 181\n",
      "Iteration 100 - loss is 9.73624230818 - parameters are 2.01319641542 8.01839579667 4.70232887069\n",
      "Iteration 200 - loss is 10.7563396994 - parameters are 2.01751582853 8.02037377022 4.7034029344\n",
      "Iteration 300 - loss is 7.96145178084 - parameters are 2.01422932808 8.01925175367 4.70336235617\n",
      "Iteration 400 - loss is 9.49792360879 - parameters are 2.01878172001 8.02560910188 4.70421558976\n",
      "Iteration 500 - loss is 9.57452595155 - parameters are 2.01003716339 8.01445709306 4.7033872606\n",
      "Iteration 600 - loss is 8.51669667154 - parameters are 2.02232383099 8.02483542776 4.70528942876\n",
      "Iteration 700 - loss is 9.40723662861 - parameters are 2.0207313721 8.02297828661 4.70531503894\n",
      "Iteration 800 - loss is 7.62735388987 - parameters are 2.02194178108 8.02843629271 4.70617596283\n",
      "Iteration 900 - loss is 8.86501947591 - parameters are 2.01933068749 8.02354917168 4.70599920709\n",
      "Iteration 1000 - loss is 12.141746134 - parameters are 2.02556517327 8.02941561383 4.70748989213\n",
      "Epoch 182\n",
      "Iteration 100 - loss is 9.70749316384 - parameters are 2.01295194326 8.01813656106 4.70647949764\n",
      "Iteration 200 - loss is 10.7276272937 - parameters are 2.01723751888 8.02008174497 4.70754081859\n",
      "Iteration 300 - loss is 7.95083289402 - parameters are 2.0139742492 8.01898148959 4.70749728477\n",
      "Iteration 400 - loss is 9.49156719313 - parameters are 2.01851142447 8.02533292798 4.70834288809\n",
      "Iteration 500 - loss is 9.55438686797 - parameters are 2.00977182729 8.01418529701 4.70750992475\n",
      "Iteration 600 - loss is 8.49923646406 - parameters are 2.02204158141 8.02455152323 4.7094028845\n",
      "Iteration 700 - loss is 9.396539927 - parameters are 2.0204495495 8.02269413938 4.7094224795\n",
      "Iteration 800 - loss is 7.61105542251 - parameters are 2.02165934497 8.02814782981 4.71027607613\n",
      "Iteration 900 - loss is 8.8509313312 - parameters are 2.01906547684 8.02327298579 4.71009469437\n",
      "Iteration 1000 - loss is 12.1135673067 - parameters are 2.0252818139 8.02911708264 4.71157609601\n",
      "Epoch 183\n",
      "Iteration 100 - loss is 9.67952705639 - parameters are 2.01271140189 8.01788145578 4.71056404295\n",
      "Iteration 200 - loss is 10.6997228654 - parameters are 2.01696367325 8.01979435935 4.71161282497\n",
      "Iteration 300 - loss is 7.9406285746 - parameters are 2.0137232706 8.01871552796 4.71156638445\n",
      "Iteration 400 - loss is 9.48556470154 - parameters are 2.01824546589 8.0250611439 4.71240447955\n",
      "Iteration 500 - loss is 9.53478218069 - parameters are 2.00951075288 8.01391782912 4.71156695756\n",
      "Iteration 600 - loss is 8.48234411116 - parameters are 2.02176385785 8.02427213172 4.71345085631\n",
      "Iteration 700 - loss is 9.38625594389 - parameters are 2.02017225164 8.02241451641 4.71346453401\n",
      "Iteration 800 - loss is 7.59529601714 - parameters are 2.021381441 8.02786395636 4.71431092115\n",
      "Iteration 900 - loss is 8.83733547797 - parameters are 2.01880452389 8.02300119641 4.71412498827\n",
      "Iteration 1000 - loss is 12.0860986986 - parameters are 2.02500299975 8.02882329881 4.71559725559\n",
      "Epoch 184\n",
      "Iteration 100 - loss is 9.65232110096 - parameters are 2.01247472674 8.01763041416 4.71458357176\n",
      "Iteration 200 - loss is 10.6726023254 - parameters are 2.01669421866 8.01951153888 4.71562001536\n",
      "Iteration 300 - loss is 7.93082439488 - parameters are 2.01347632497 8.01845379945 4.71557071618\n",
      "Iteration 400 - loss is 9.47990245618 - parameters are 2.0179837733 8.02479367909 4.71640142312\n",
      "Iteration 500 - loss is 9.51569652703 - parameters are 2.00925387028 8.01365461963 4.71555941673\n",
      "Iteration 600 - loss is 8.46600131084 - parameters are 2.02149058635 8.02399718072 4.71743439951\n",
      "Iteration 700 - loss is 9.37637037085 - parameters are 2.01989940441 8.02213934477 4.71744225617\n",
      "Iteration 800 - loss is 7.58005815387 - parameters are 2.02110799502 8.0275845985 4.71828154961\n",
      "Iteration 900 - loss is 8.82421551759 - parameters are 2.0185477589 8.0227337327 4.7180911393\n",
      "Iteration 1000 - loss is 12.0593206005 - parameters are 2.02472865649 8.02853418598 4.7195544189\n",
      "Epoch 185\n",
      "Iteration 100 - loss is 9.62585311401 - parameters are 2.01224185433 8.01738337063 4.71853913164\n",
      "Iteration 200 - loss is 10.646242331 - parameters are 2.01642908335 8.01923321029 4.71956343406\n",
      "Iteration 300 - loss is 7.92140640952 - parameters are 2.01323334612 8.01819623588 4.71951132343\n",
      "Iteration 400 - loss is 9.47456725635 - parameters are 2.01772627693 8.0245304642 4.72033476032\n",
      "Iteration 500 - loss is 9.49711501092 - parameters are 2.00900111083 8.01339559989 4.71948834255\n",
      "Iteration 600 - loss is 8.45019035182 - parameters are 2.02122169419 8.02372659889 4.721354552\n",
      "Iteration 700 - loss is 9.36686937741 - parameters are 2.01963093493 8.02186855272 4.72135668225\n",
      "Iteration 800 - loss is 7.56532488088 - parameters are 2.0208389341 8.02730968356 4.72218899591\n",
      "Iteration 900 - loss is 8.81155558934 - parameters are 2.01829511332 8.02247052498 4.7219941806\n",
      "Iteration 1000 - loss is 12.0332138895 - parameters are 2.02445871105 8.02824966908 4.72344861671\n",
      "Epoch 186\n",
      "Iteration 100 - loss is 9.60010159106 - parameters are 2.01201272229 8.01714026071 4.72243175285\n",
      "Iteration 200 - loss is 10.6206202622 - parameters are 2.01616819676 8.01895930152 4.72344410815\n",
      "Iteration 300 - loss is 7.91236113955 - parameters are 2.01299426902 8.01794277017 4.72338923246\n",
      "Iteration 400 - loss is 9.46954636241 - parameters are 2.01747290822 8.02427143097 4.7242055155\n",
      "Iteration 500 - loss is 9.47902318817 - parameters are 2.00875240701 8.0131407024 4.72335475812\n",
      "Iteration 600 - loss is 8.43489409434 - parameters are 2.02095710987 8.02346031607 4.72521233457\n",
      "Iteration 700 - loss is 9.35773959517 - parameters are 2.01936677159 8.02160206973 4.72520883146\n",
      "Iteration 800 - loss is 7.55107979595 - parameters are 2.02057418657 8.02703914008 4.7260342774\n",
      "Iteration 900 - loss is 8.79934035277 - parameters are 2.01804651975 8.02221150473 4.72583512833\n",
      "Iteration 1000 - loss is 12.0077600106 - parameters are 2.02419309159 8.02796967423 4.7272808628\n",
      "Epoch 187\n",
      "Iteration 100 - loss is 9.57504568525 - parameters are 2.0117872693 8.016901021 4.72626244871\n",
      "Iteration 200 - loss is 10.5957141983 - parameters are 2.01591148956 8.01868974171 4.72726304777\n",
      "Iteration 300 - loss is 7.90367555696 - parameters are 2.01275902972 8.01769333638 4.72720545263\n",
      "Iteration 400 - loss is 9.46482748018 - parameters are 2.01722359974 8.0240165123 4.72801469612\n",
      "Iteration 500 - loss is 9.46140705218 - parameters are 2.00850769247 8.01288986077 4.72715966971\n",
      "Iteration 600 - loss is 8.42009595149 - parameters are 2.02069676312 8.02319826326 4.72900875121\n",
      "Iteration 700 - loss is 9.34896810257 - parameters are 2.01910684398 8.02133982641 4.72899970623\n",
      "Iteration 800 - loss is 7.53730702844 - parameters are 2.02031368198 8.02677289778 4.72981839464\n",
      "Iteration 900 - loss is 8.7875549706 - parameters are 2.01780191195 8.02195660457 4.72961498187\n",
      "Iteration 1000 - loss is 11.9829409591 - parameters are 2.02393172752 8.02769412881 4.73105215425\n",
      "Epoch 188\n",
      "Iteration 100 - loss is 9.55066518646 - parameters are 2.01156543507 8.01666558913 4.73003221582\n",
      "Iteration 200 - loss is 10.5715028961 - parameters are 2.01565889355 8.01842446111 4.73102124644\n",
      "Iteration 300 - loss is 7.89533706978 - parameters are 2.01252756539 8.01744786963 4.73096097667\n",
      "Iteration 400 - loss is 9.46039874594 - parameters are 2.01697828523 8.02376564216 4.73176329305\n",
      "Iteration 500 - loss is 9.44425302017 - parameters are 2.00826690198 8.01264300971 4.73090406701\n",
      "Iteration 600 - loss is 8.40577987127 - parameters are 2.02044058484 8.02294037256 4.73274478935\n",
      "Iteration 700 - loss is 9.34054240999 - parameters are 2.01885108287 8.02108175453 4.73273029246\n",
      "Iteration 800 - loss is 7.52399122198 - parameters are 2.02005735105 8.02651088752 4.73354233176\n",
      "Iteration 900 - loss is 8.77618509222 - parameters are 2.0175612248 8.02170575818 4.73333472419\n",
      "Iteration 1000 - loss is 11.9587392631 - parameters are 2.02367454939 8.02742296135 4.73476347172\n",
      "Epoch 189\n",
      "Iteration 100 - loss is 9.52694050124 - parameters are 2.01134716036 8.01643390375 4.73374203441\n",
      "Iteration 200 - loss is 10.547965768 - parameters are 2.01541034172 8.01816339117 4.73471968134\n",
      "Iteration 300 - loss is 7.88733350761 - parameters are 2.01229981424 8.01720630612 4.73465678097\n",
      "Iteration 400 - loss is 9.45624871185 - parameters are 2.01673689951 8.02351875561 4.73545228087\n",
      "Iteration 500 - loss is 9.42754791985 - parameters are 2.0080299714 8.01240008499 4.73458892342\n",
      "Iteration 600 - loss is 8.39193031921 - parameters are 2.0201885071 8.02268657722 4.73642142021\n",
      "Iteration 700 - loss is 9.33245044556 - parameters are 2.01859942023 8.02082778696 4.73640155986\n",
      "Iteration 800 - loss is 7.51111751767 - parameters are 2.01980512569 8.02625304131 4.73720705668\n",
      "Iteration 900 - loss is 8.76521683771 - parameters are 2.01732439429 8.02145890039 4.73699532205\n",
      "Iteration 1000 - loss is 11.9351379672 - parameters are 2.02342148896 8.02715610158 4.73841577976\n",
      "Epoch 190\n",
      "Iteration 100 - loss is 9.50385263328 - parameters are 2.01113238692 8.01620590455 4.73739286857\n",
      "Iteration 200 - loss is 10.5250828613 - parameters are 2.01516576816 8.01790646439 4.73835931355\n",
      "Iteration 300 - loss is 7.87965310771 - parameters are 2.01207571554 8.01696858308 4.73829382588\n",
      "Iteration 400 - loss is 9.45236633196 - parameters are 2.01649937855 8.02327578878 4.73908261812\n",
      "Iteration 500 - loss is 9.4112789765 - parameters are 2.0077968377 8.01216102345 4.73821519635\n",
      "Iteration 600 - loss is 8.3785322615 - parameters are 2.01994046312 8.02243681154 4.74003959902\n",
      "Iteration 700 - loss is 9.32468054123 - parameters are 2.01835178916 8.02057785771 4.74001446219\n",
      "Iteration 800 - loss is 7.49867153788 - parameters are 2.01955693896 8.02599929226 4.74081352141\n",
      "Iteration 900 - loss is 8.75463678239 - parameters are 2.01709135746 8.02121596707 4.74059772637\n",
      "Iteration 1000 - loss is 11.9121206166 - parameters are 2.02317247913 8.02689348036 4.74201002706\n",
      "Epoch 191\n",
      "Iteration 100 - loss is 9.48138316461 - parameters are 2.0109210575 8.01598153218 4.74098566654\n",
      "Iteration 200 - loss is 10.5028348382 - parameters are 2.0149251081 8.01765361444 4.74194108839\n",
      "Iteration 300 - loss is 7.8722845015 - parameters are 2.01185520959 8.01673463879 4.74187305596\n",
      "Iteration 400 - loss is 9.44874094856 - parameters are 2.01626565937 8.02303667882 4.74265524761\n",
      "Iteration 500 - loss is 9.39543380048 - parameters are 2.0075674389 8.01192576296 4.74178382748\n",
      "Iteration 600 - loss is 8.36557114875 - parameters are 2.01969638724 8.02219101093 4.74360026533\n",
      "Iteration 700 - loss is 9.3172214195 - parameters are 2.0181081239 8.02033190183 4.74356993754\n",
      "Iteration 800 - loss is 7.48663937057 - parameters are 2.01931272502 8.02574957459 4.74436266234\n",
      "Iteration 900 - loss is 8.74443194196 - parameters are 2.01686205245 8.02097689514 4.74414287241\n",
      "Iteration 1000 - loss is 11.8896712413 - parameters are 2.02292745393 8.0266350297 4.74554714673\n",
      "Epoch 192\n",
      "Iteration 100 - loss is 9.45951423737 - parameters are 2.0107131158 8.0157607283 4.74452136101\n",
      "Iteration 200 - loss is 10.481202956 - parameters are 2.01468829782 8.01740477602 4.74546593563\n",
      "Iteration 300 - loss is 7.86521670152 - parameters are 2.0116382377 8.01650441254 4.74539540026\n",
      "Iteration 400 - loss is 9.44536227915 - parameters are 2.01603568004 8.02280136393 4.74617109666\n",
      "Iteration 500 - loss is 9.38000037519 - parameters are 2.00734171407 8.01169424243 4.74529574303\n",
      "Iteration 600 - loss is 8.35303290027 - parameters are 2.01945621489 8.02194911184 4.74710434324\n",
      "Iteration 700 - loss is 9.31006218042 - parameters are 2.0178683598 8.02008985548 4.7470689086\n",
      "Iteration 800 - loss is 7.47500755409 - parameters are 2.01907241919 8.02550382358 4.74785540047\n",
      "Iteration 900 - loss is 8.73458975797 - parameters are 2.01663641842 8.02074162256 4.74763168009\n",
      "Iteration 1000 - loss is 11.867774341 - parameters are 2.0226863485 8.02638068271 4.74902805655\n",
      "Epoch 193\n",
      "Iteration 100 - loss is 9.43822853614 - parameters are 2.01050850651 8.0155434355 4.74800086934\n",
      "Iteration 200 - loss is 10.4601690485 - parameters are 2.0144552747 8.01715988492 4.7489347698\n",
      "Iteration 300 - loss is 7.85843908887 - parameters are 2.01142474218 8.0162778446 4.7488617726\n",
      "Iteration 400 - loss is 9.44222040369 - parameters are 2.0158093797 8.02256978331 4.74963107737\n",
      "Iteration 500 - loss is 9.3649670453 - parameters are 2.00711960331 8.01146640174 4.74875185402\n",
      "Iteration 600 - loss is 8.34090388884 - parameters are 2.01921988262 8.02171105175 4.75055274173\n",
      "Iteration 700 - loss is 9.30319228917 - parameters are 2.01763243329 8.01985165583 4.75051228292\n",
      "Iteration 800 - loss is 7.46376306257 - parameters are 2.01883595782 8.02526197558 4.75129264171\n",
      "Iteration 900 - loss is 8.72509808397 - parameters are 2.01641439558 8.02051008832 4.75106505425\n",
      "Iteration 1000 - loss is 11.846414871 - parameters are 2.02244909908 8.02613037359 4.75245365928\n",
      "Epoch 194\n",
      "Iteration 100 - loss is 9.41750927088 - parameters are 2.01030717521 8.01532959733 4.75142509387\n",
      "Iteration 200 - loss is 10.4397155076 - parameters are 2.01422597718 8.01691887796 4.75234849042\n",
      "Iteration 300 - loss is 7.85194140096 - parameters are 2.0112146663 8.01605487625 4.75227307179\n",
      "Iteration 400 - loss is 9.43930575237 - parameters are 2.01558669849 8.02234187715 4.75303608687\n",
      "Iteration 500 - loss is 9.3503225055 - parameters are 2.00690104774 8.01124218178 4.75215305652\n",
      "Iteration 600 - loss is 8.32917092603 - parameters are 2.018987328 8.02147676917 4.75394635484\n",
      "Iteration 700 - loss is 9.29660156392 - parameters are 2.01740028188 8.0196172411 4.75390095319\n",
      "Iteration 800 - loss is 7.4528932917 - parameters are 2.01860327838 8.025023968 4.7546752771\n",
      "Iteration 900 - loss is 8.71594517195 - parameters are 2.01619592511 8.02028223239 4.7544438849\n",
      "Iteration 1000 - loss is 11.8255782276 - parameters are 2.02221564296 8.02588403763 4.75582484285\n",
      "Epoch 195\n",
      "Iteration 100 - loss is 9.39734016045 - parameters are 2.01010906845 8.01511915826 4.75479492213\n",
      "Iteration 200 - loss is 10.4198252657 - parameters are 2.0140003447 8.01668169301 4.75570798229\n",
      "Iteration 300 - loss is 7.84571371977 - parameters are 2.01100795429 8.01583544969 4.75563018194\n",
      "Iteration 400 - loss is 9.43660909379 - parameters are 2.01536757758 8.02211758663 4.75638700763\n",
      "Iteration 500 - loss is 9.33605578955 - parameters are 2.00668598944 8.0110215244 4.75550023194\n",
      "Iteration 600 - loss is 8.31782124795 - parameters are 2.01875848968 8.02124620361 4.75728606198\n",
      "Iteration 700 - loss is 9.29028016421 - parameters are 2.01717184412 8.01938655053 4.75723579746\n",
      "Iteration 800 - loss is 7.44238604501 - parameters are 2.01837431936 8.02478973924 4.75800418309\n",
      "Iteration 900 - loss is 8.70711965932 - parameters are 2.01598094922 8.02005799574 4.75776904746\n",
      "Iteration 1000 - loss is 11.8052502348 - parameters are 2.02198591849 8.02564161117 4.75914248067\n",
      "Epoch 196\n",
      "Iteration 100 - loss is 9.37770541659 - parameters are 2.00991413363 8.01491206368 4.75811122712\n",
      "Iteration 200 - loss is 10.4004817787 - parameters are 2.01377831774 8.01644826894 4.75901411568\n",
      "Iteration 300 - loss is 7.83974646048 - parameters are 2.01080455134 8.01561950811 4.75893397265\n",
      "Iteration 400 - loss is 9.43412152347 - parameters are 2.01515195911 8.02189685385 4.75968470764\n",
      "Iteration 500 - loss is 9.32215625965 - parameters are 2.00647437151 8.01080437242 4.75879424725\n",
      "Iteration 600 - loss is 8.30684250149 - parameters are 2.01853330732 8.02101929556 4.76057272815\n",
      "Iteration 700 - loss is 9.28421857966 - parameters are 2.01694705962 8.01915952434 4.76051767941\n",
      "Iteration 800 - loss is 7.43222952066 - parameters are 2.0181490203 8.02455922873 4.7612802218\n",
      "Iteration 900 - loss is 8.69861055632 - parameters are 2.01576941106 8.0198373203 4.76104140302\n",
      "Iteration 1000 - loss is 11.7854171311 - parameters are 2.02175986507 8.02540303157 4.76240743183\n",
      "Epoch 197\n",
      "Iteration 100 - loss is 9.35858972849 - parameters are 2.00972231907 8.01470825987 4.76137486756\n",
      "Iteration 200 - loss is 10.3816690092 - parameters are 2.01355983776 8.0162185456 4.76226774665\n",
      "Iteration 300 - loss is 7.8340303604 - parameters are 2.01060440355 8.01540699559 4.76218529931\n",
      "Iteration 400 - loss is 9.43183445284 - parameters are 2.01493978618 8.02167962191 4.76293004067\n",
      "Iteration 500 - loss is 9.30861359621 - parameters are 2.00626613797 8.01059066957 4.76203595523\n",
      "Iteration 600 - loss is 8.29622273103 - parameters are 2.0183117216 8.0207959865 4.76380720421\n",
      "Iteration 700 - loss is 9.278407619 - parameters are 2.01672586896 8.01893610374 4.76374744857\n",
      "Iteration 800 - loss is 7.42241229857 - parameters are 2.01792732174 8.02433237687 4.7645042412\n",
      "Iteration 900 - loss is 8.69040723379 - parameters are 2.01556125475 8.01962014895 4.76426179858\n",
      "Iteration 1000 - loss is 11.7660655566 - parameters are 2.0215374231 8.02516823724 4.76562054138\n",
      "Epoch 198\n",
      "Iteration 100 - loss is 9.33997824777 - parameters are 2.00953357397 8.01450769398 4.76458668811\n",
      "Iteration 200 - loss is 10.3633714107 - parameters are 2.01334484722 8.01599246383 4.76546971724\n",
      "Iteration 300 - loss is 7.82855646839 - parameters are 2.01040745791 8.01519785716 4.76538500332\n",
      "Iteration 400 - loss is 9.4297395985 - parameters are 2.01473100287 8.02146583478 4.76612384656\n",
      "Iteration 500 - loss is 9.29541778795 - parameters are 2.00606123379 8.01038036052 4.7652261947\n",
      "Iteration 600 - loss is 8.28595036557 - parameters are 2.01809367419 8.02057621884 4.7669903271\n",
      "Iteration 700 - loss is 9.27283839961 - parameters are 2.01650821376 8.01871623088 4.76692594061\n",
      "Iteration 800 - loss is 7.41292332804 - parameters are 2.01770916522 8.02410912505 4.76767707545\n",
      "Iteration 900 - loss is 8.68249941137 - parameters are 2.01535642535 8.01940642549 4.7674310673\n",
      "Iteration 1000 - loss is 11.7471825407 - parameters are 2.02131853397 8.02493716758 4.76878264056\n",
      "Epoch 199\n",
      "Iteration 100 - loss is 9.32185657409 - parameters are 2.00934784834 8.01431031406 4.76774751962\n",
      "Iteration 200 - loss is 10.3455739124 - parameters are 2.01313328953 8.01576996544 4.76862085573\n",
      "Iteration 300 - loss is 7.82331613451 - parameters are 2.01021366234 8.01499203872 4.7685339123\n",
      "Iteration 400 - loss is 9.42782897191 - parameters are 2.01452555417 8.02125543738 4.7692669514\n",
      "Iteration 500 - loss is 9.28255912225 - parameters are 2.00585960487 8.01017339083 4.76836579079\n",
      "Iteration 600 - loss is 8.27601420626 - parameters are 2.01787910772 8.02035993593 4.77012292006\n",
      "Iteration 700 - loss is 9.26750233725 - parameters are 2.01629403659 8.01849984888 4.77005397753\n",
      "Iteration 800 - loss is 7.40375191573 - parameters are 2.01749449327 8.02388941562 4.77079954503\n",
      "Iteration 900 - loss is 8.67487714616 - parameters are 2.01515486881 8.01919609467 4.77055002873\n",
      "Iteration 1000 - loss is 11.7287554901 - parameters are 2.02110314007 8.02470976298 4.77189454702\n",
      "Epoch 200\n",
      "Iteration 100 - loss is 9.30421074102 - parameters are 2.00916509308 8.01411606896 4.77085817937\n",
      "Iteration 200 - loss is 10.3282619035 - parameters are 2.01292510904 8.01555099318 4.77172197687\n",
      "Iteration 300 - loss is 7.81830100012 - parameters are 2.0100229656 8.01478948706 4.77163284039\n",
      "Iteration 400 - loss is 9.42609486943 - parameters are 2.014323386 8.0210483755 4.7723601678\n",
      "Iteration 500 - loss is 9.27002817589 - parameters are 2.00566119802 8.00996970696 4.77145555514\n",
      "Iteration 600 - loss is 8.26640341438 - parameters are 2.01766796579 8.02014708205 4.77320579291\n",
      "Iteration 700 - loss is 9.26239113624 - parameters are 2.016083281 8.01828690178 4.77313236788\n",
      "Iteration 800 - loss is 7.39488771411 - parameters are 2.01728324935 8.02367319185 4.77387245706\n",
      "Iteration 900 - loss is 8.6675308216 - parameters are 2.01495653203 8.0189891021 4.77361948901\n",
      "Iteration 1000 - loss is 11.7107721774 - parameters are 2.02089118473 8.0244859648 4.77495706504\n",
      "Epoch 201\n",
      "Iteration 100 - loss is 9.28702720258 - parameters are 2.00898525988 8.01392490841 4.77391947129\n",
      "Iteration 200 - loss is 10.3114212193 - parameters are 2.01272025103 8.01533549071 4.77477388209\n",
      "Iteration 300 - loss is 7.81350298819 - parameters are 2.00983531732 8.01459014986 4.7746825884\n",
      "Iteration 400 - loss is 9.4245298626 - parameters are 2.01412444518 8.02084459583 4.77540429508\n",
      "Iteration 500 - loss is 9.25781580607 - parameters are 2.00546596092 8.00976925626 4.77449628615\n",
      "Iteration 600 - loss is 8.25710749972 - parameters are 2.01746019295 8.01993760239 4.77623974225\n",
      "Iteration 700 - loss is 9.25749677992 - parameters are 2.01587589147 8.01807733454 4.77616190704\n",
      "Iteration 800 - loss is 7.38632071021 - parameters are 2.01707537791 8.02346039795 4.77689660545\n",
      "Iteration 900 - loss is 8.66045113688 - parameters are 2.01476136277 8.01878539433 4.77664024115\n",
      "Iteration 1000 - loss is 11.6932207298 - parameters are 2.02068261223 8.02426571534 4.77797098581\n",
      "Epoch 202\n",
      "Iteration 100 - loss is 9.27029282005 - parameters are 2.00880830125 8.01373678295 4.77693218621\n",
      "Iteration 200 - loss is 10.2950381272 - parameters are 2.01251866169 8.01512340263 4.77777735978\n",
      "Iteration 300 - loss is 7.80891429407 - parameters are 2.00965066799 8.01439397561 4.77768394409\n",
      "Iteration 400 - loss is 9.42312678887 - parameters are 2.01392867943 8.02064404592 4.77840011954\n",
      "Iteration 500 - loss is 9.24591314166 - parameters are 2.00527384213 8.0095719869 4.77748876918\n",
      "Iteration 600 - loss is 8.24811630925 - parameters are 2.01725573464 8.01973144301 4.77922555165\n",
      "Iteration 700 - loss is 9.25281152139 - parameters are 2.01567181341 8.017871093 4.77914337742\n",
      "Iteration 800 - loss is 7.37804121474 - parameters are 2.01687082428 8.02325097902 4.77987277118\n",
      "Iteration 900 - loss is 8.65362909661 - parameters are 2.01456930966 8.01858491873 4.77961306522\n",
      "Iteration 1000 - loss is 11.6760896181 - parameters are 2.0204773678 8.02404895787 4.78093708758\n",
      "Epoch 203\n",
      "Iteration 100 - loss is 9.25399484927 - parameters are 2.00863417051 8.01355164391 4.77989710204\n",
      "Iteration 200 - loss is 10.2790993126 - parameters are 2.01232028813 8.01491467442 4.78073318542\n",
      "Iteration 300 - loss is 7.80452737643 - parameters are 2.00946896891 8.01420091369 4.78063768238\n",
      "Iteration 400 - loss is 9.42187874255 - parameters are 2.01373603732 8.02044667417 4.78134841464\n",
      "Iteration 500 - loss is 9.23431157479 - parameters are 2.0050847911 8.00937784793 4.78043377679\n",
      "Iteration 600 - loss is 8.23942001629 - parameters are 2.01705453725 8.01952855087 4.78216399194\n",
      "Iteration 700 - loss is 9.24832787468 - parameters are 2.01547099314 8.01766812391 4.78207754865\n",
      "Iteration 800 - loss is 7.37003985166 - parameters are 2.01666953474 8.02304488108 4.78280172249\n",
      "Iteration 900 - loss is 8.6470560008 - parameters are 2.0143803222 8.01838762356 4.78253872855\n",
      "Iteration 1000 - loss is 11.6593676462 - parameters are 2.02027539755 8.02383563655 4.78385613595\n",
      "Epoch 204\n",
      "Iteration 100 - loss is 9.23812092838 - parameters are 2.00846282175 8.01336944344 4.78281498401\n",
      "Iteration 200 - loss is 10.2635918663 - parameters are 2.0121250783 8.01470925245 4.78364212189\n",
      "Iteration 300 - loss is 7.8003349486 - parameters are 2.00929017219 8.01401091427 4.78354456554\n",
      "Iteration 400 - loss is 9.42077906612 - parameters are 2.0135464683 8.02025242981 4.78424994126\n",
      "Iteration 500 - loss is 9.22300275272 - parameters are 2.00489875809 8.00918678922 4.78333206896\n",
      "Iteration 600 - loss is 8.23100910993 - parameters are 2.01685654802 8.01932887377 4.78505582138\n",
      "Iteration 700 - loss is 9.24403860604 - parameters are 2.01527337789 8.01746837486 4.78496517783\n",
      "Iteration 800 - loss is 7.36230754799 - parameters are 2.01647145643 8.02284205101 4.78568421512\n",
      "Iteration 900 - loss is 8.64072343526 - parameters are 2.01419435074 8.01819345791 4.785417986\n",
      "Iteration 1000 - loss is 11.6430439412 - parameters are 2.02007664852 8.02362569647 4.786728884\n",
      "Epoch 205\n",
      "Iteration 100 - loss is 9.22265906586 - parameters are 2.00829420981 8.01319013446 4.7856865849\n",
      "Iteration 200 - loss is 10.2485032715 - parameters are 2.01193298105 8.01450708397 4.78650491963\n",
      "Iteration 300 - loss is 7.79632997014 - parameters are 2.00911423077 8.01382392834 4.78640534345\n",
      "Iteration 400 - loss is 9.41982134177 - parameters are 2.01335992263 8.02006126291 4.78710544785\n",
      "Iteration 500 - loss is 9.21197856991 - parameters are 2.0047156942 8.00899876145 4.78618439328\n",
      "Iteration 600 - loss is 8.22287438487 - parameters are 2.0166617151 8.01913236037 4.78790178587\n",
      "Iteration 700 - loss is 9.23993672567 - parameters are 2.01507891576 8.01727179432 4.78780700974\n",
      "Iteration 800 - loss is 7.35483552399 - parameters are 2.01627653739 8.02264243657 4.78852099247\n",
      "Iteration 900 - loss is 8.63462326229 - parameters are 2.01401134642 8.0180023717 4.78825158012\n",
      "Iteration 1000 - loss is 11.6271079435 - parameters are 2.0198810686 8.02341908359 4.78955607259\n",
      "Epoch 206\n",
      "Iteration 100 - loss is 9.20759762905 - parameters are 2.00812829032 8.01301367065 4.78851264521\n",
      "Iteration 200 - loss is 10.2338213917 - parameters are 2.01174394605 8.01430811706 4.78932231685\n",
      "Iteration 300 - loss is 7.79250563868 - parameters are 2.00894109835 8.0136399077 4.78922075375\n",
      "Iteration 400 - loss is 9.41899938328 - parameters are 2.01317635143 8.01987312433 4.78991567071\n",
      "Iteration 500 - loss is 9.20123116039 - parameters are 2.00453555134 8.00881371612 4.78899148516\n",
      "Iteration 600 - loss is 8.21500693151 - parameters are 2.01646998748 8.01893896015 4.79070261917\n",
      "Iteration 700 - loss is 9.23601547962 - parameters are 2.01488755569 8.01707833159 4.79060377701\n",
      "Iteration 800 - loss is 7.34761528368 - parameters are 2.01608472653 8.02244598633 4.79131278587\n",
      "Iteration 900 - loss is 8.62874761158 - parameters are 2.01383126124 8.01781431568 4.79104024137\n",
      "Iteration 1000 - loss is 11.6115493969 - parameters are 2.01968860656 8.02321574478 4.79233843051\n",
      "Epoch 207\n",
      "Iteration 100 - loss is 9.19292533299 - parameters are 2.00796501963 8.01284000646 4.79129389341\n",
      "Iteration 200 - loss is 10.2195344584 - parameters are 2.01155792384 8.01411230067 4.79209503977\n",
      "Iteration 300 - loss is 7.78885538212 - parameters are 2.0087707294 8.01345880491 4.79199152211\n",
      "Iteration 400 - loss is 9.41830722816 - parameters are 2.01299570661 8.01968796575 4.79268133413\n",
      "Iteration 500 - loss is 9.19075289036 - parameters are 2.00435828224 8.0086316055 4.79175406808\n",
      "Iteration 600 - loss is 8.20739812647 - parameters are 2.01628131501 8.01874862343 4.79345904311\n",
      "Iteration 700 - loss is 9.23226834205 - parameters are 2.01469924752 8.01688793678 4.79335620038\n",
      "Iteration 800 - loss is 7.34063860565 - parameters are 2.0158959736 8.02225264975 4.79406031474\n",
      "Iteration 900 - loss is 8.62308887155 - parameters are 2.01365404797 8.01762924138 4.79378468835\n",
      "Iteration 1000 - loss is 11.5963583397 - parameters are 2.01949921202 8.02301562773 4.79507667468\n",
      "Epoch 208\n",
      "Iteration 100 - loss is 9.17863122959 - parameters are 2.00780435482 8.01266909707 4.79403104612\n",
      "Iteration 200 - loss is 10.2056310602 - parameters are 2.01137486574 8.01391958454 4.79482380278\n",
      "Iteration 300 - loss is 7.78537285093 - parameters are 2.00860307917 8.01328057332 4.79471836237\n",
      "Iteration 400 - loss is 9.41773913 - parameters are 2.01281794088 8.0195057396 4.79540315064\n",
      "Iteration 500 - loss is 9.18053635103 - parameters are 2.00418384039 8.00845238264 4.7944728537\n",
      "Iteration 600 - loss is 8.20003962331 - parameters are 2.01609564835 8.01856130131 4.79617176778\n",
      "Iteration 700 - loss is 9.22868900763 - parameters are 2.01451394188 8.01670056083 4.79606498887\n",
      "Iteration 800 - loss is 7.33389753415 - parameters are 2.01571022917 8.02206237707 4.79676428681\n",
      "Iteration 900 - loss is 8.6176396809 - parameters are 2.01347966016 8.01744710113 4.79648562795\n",
      "Iteration 1000 - loss is 11.5815250957 - parameters are 2.01931283544 8.02281868101 4.79777151038\n",
      "Epoch 209\n",
      "Iteration 100 - loss is 9.16470469723 - parameters are 2.00764625368 8.0125008984 4.7967248083\n",
      "Iteration 200 - loss is 10.1921001309 - parameters are 2.01119472391 8.01372991924 4.79750930867\n",
      "Iteration 300 - loss is 7.78205191089 - parameters are 2.00843810364 8.01310516703 4.79740197678\n",
      "Iteration 400 - loss is 9.41728955116 - parameters are 2.01264300775 8.01932639912 4.79808182118\n",
      "Iteration 500 - loss is 9.17057435167 - parameters are 2.00401218007 8.00827600137 4.79714854217\n",
      "Iteration 600 - loss is 8.19292334362 - parameters are 2.01591293901 8.0183769457 4.79884149172\n",
      "Iteration 700 - loss is 9.22527138431 - parameters are 2.01433159024 8.01651615547 4.79873083994\n",
      "Iteration 800 - loss is 7.32738437054 - parameters are 2.01552744465 8.02187511936 4.79942539829\n",
      "Iteration 900 - loss is 8.61239292042 - parameters are 2.01330805216 8.01726784802 4.79914375559\n",
      "Iteration 1000 - loss is 11.5670402655 - parameters are 2.01912942808 8.02262485402 4.80042363143\n",
      "Epoch 210\n",
      "Iteration 100 - loss is 9.15113543059 - parameters are 2.00749067472 8.01233536708 4.79937587345\n",
      "Iteration 200 - loss is 10.1789309393 - parameters are 2.01101745128 8.01354325616 4.8001522488\n",
      "Iteration 300 - loss is 7.7788866359 - parameters are 2.00827575953 8.0129325409 4.80004305619\n",
      "Iteration 400 - loss is 9.41695315563 - parameters are 2.01247086148 8.01914989827 4.80071803532\n",
      "Iteration 500 - loss is 9.16085991293 - parameters are 2.00384325631 8.00810241627 4.79978182224\n",
      "Iteration 600 - loss is 8.18604146839 - parameters are 2.01573313926 8.01819550928 4.80146890213\n",
      "Iteration 700 - loss is 9.22200958622 - parameters are 2.01415214486 8.01633467322 4.80135443977\n",
      "Iteration 800 - loss is 7.32109166494 - parameters are 2.01534757225 8.02169082846 4.8020443341\n",
      "Iteration 900 - loss is 8.60734170512 - parameters are 2.01313917904 8.01709143593 4.80175975539\n",
      "Iteration 1000 - loss is 11.5528947181 - parameters are 2.01894894204 8.02243409696 4.80303372038\n",
      "Epoch 211\n",
      "Iteration 100 - loss is 9.13791343091 - parameters are 2.00733757712 8.01217246045 4.80198492383\n",
      "Iteration 200 - loss is 10.1661130785 - parameters are 2.01084300158 8.01335954745 4.8027533033\n",
      "Iteration 300 - loss is 7.77587130113 - parameters are 2.00811600427 8.0127626505 4.80264228021\n",
      "Iteration 400 - loss is 9.4167248022 - parameters are 2.0123014571 8.01897619177 4.8033124714\n",
      "Iteration 500 - loss is 9.15138626028 - parameters are 2.0036770249 8.00793158262 4.80237337147\n",
      "Iteration 600 - loss is 8.17938642966 - parameters are 2.0155562022 8.01801694549 4.80405467505\n",
      "Iteration 700 - loss is 9.21889792692 - parameters are 2.01397555881 8.01615606736 4.80393646338\n",
      "Iteration 800 - loss is 7.31501220819 - parameters are 2.01517056497 8.02150945702 4.80462176805\n",
      "Iteration 900 - loss is 8.60247937657 - parameters are 2.01297299665 8.01691781947 4.80433430037\n",
      "Iteration 1000 - loss is 11.5390795829 - parameters are 2.01877133018 8.02224636085 4.80560244869\n",
      "Epoch 212\n",
      "Iteration 100 - loss is 9.12502899644 - parameters are 2.00718692076 8.01201213654 4.80455263061\n",
      "Iteration 200 - loss is 10.1536364559 - parameters are 2.01067132927 8.01317874603 4.80531314128\n",
      "Iteration 300 - loss is 7.77300037637 - parameters are 2.007958796 8.01259545213 4.80520031744\n",
      "Iteration 400 - loss is 9.41659953774 - parameters are 2.01213475038 8.01880523508 4.80586579678\n",
      "Iteration 500 - loss is 9.14214681779 - parameters are 2.00351344235 8.00776345648 4.80492385643\n",
      "Iteration 600 - loss is 8.1729509024 - parameters are 2.01538208167 8.01784120854 4.80659947556\n",
      "Iteration 700 - loss is 9.21593091275 - parameters are 2.01380178594 8.01598029194 4.80647757482\n",
      "Iteration 800 - loss is 7.3091390241 - parameters are 2.01499637658 8.02133095843 4.80715836299\n",
      "Iteration 900 - loss is 8.59779949554 - parameters are 2.01280946155 8.01674695397 4.80686805262\n",
      "Iteration 1000 - loss is 11.5255862416 - parameters are 2.01859654615 8.02206159751 4.80813047695\n",
      "Epoch 213\n",
      "Iteration 100 - loss is 9.11247271332 - parameters are 2.00703866616 8.01185435407 4.80707965408\n",
      "Iteration 200 - loss is 10.141491283 - parameters are 2.01050238961 8.01300080559 4.80783242098\n",
      "Iteration 300 - loss is 7.77026851958 - parameters are 2.00780409357 8.01243090282 4.80771782563\n",
      "Iteration 400 - loss is 9.41657259089 - parameters are 2.01197069782 8.01863698437 4.80837866799\n",
      "Iteration 500 - loss is 9.13313520197 - parameters are 2.00335246589 8.00759799458 4.8074339329\n",
      "Iteration 600 - loss is 8.16672779673 - parameters are 2.0152107323 8.01766825337 4.80910395794\n",
      "Iteration 700 - loss is 9.21310323651 - parameters are 2.01363078083 8.01580730175 4.8089784274\n",
      "Iteration 800 - loss is 7.30346536186 - parameters are 2.01482496163 8.02115528685 4.80965477104\n",
      "Iteration 900 - loss is 8.59329583483 - parameters are 2.01264853103 8.01657879552 4.80936166351\n",
      "Iteration 1000 - loss is 11.5124063208 - parameters are 2.01842454438 8.02187975953 4.81061845501\n",
      "Epoch 214\n",
      "Iteration 100 - loss is 9.10023544666 - parameters are 2.00689277452 8.01169907242 4.80956664381\n",
      "Iteration 200 - loss is 10.1296680666 - parameters are 2.01033613856 8.01282568056 4.81031178998\n",
      "Iteration 300 - loss is 7.76767057069 - parameters are 2.00765185649 8.01226896026 4.81019545185\n",
      "Iteration 400 - loss is 9.41663936574 - parameters are 2.01180925664 8.01847139651 4.8108517309\n",
      "Iteration 500 - loss is 9.12434521592 - parameters are 2.00319405347 8.00743515438 4.80990424599\n",
      "Iteration 600 - loss is 8.16071025033 - parameters are 2.01504210946 8.01749803563 4.81156876587\n",
      "Iteration 700 - loss is 9.21040977123 - parameters are 2.01346249885 8.01563705231 4.81143966382\n",
      "Iteration 800 - loss is 7.29798468883 - parameters are 2.0146562754 8.02098239719 4.81211163374\n",
      "Iteration 900 - loss is 8.58896237237 - parameters are 2.01249016307 8.0164133009 4.81181577383\n",
      "Iteration 1000 - loss is 11.4995316845 - parameters are 2.01825528004 8.02170080026 4.81306702221\n",
      "Epoch 215\n",
      "Iteration 100 - loss is 9.08830833194 - parameters are 2.00674920767 8.01154625163 4.81201423886\n",
      "Iteration 200 - loss is 10.1181575989 - parameters are 2.01017253281 8.01265332613 4.81275188534\n",
      "Iteration 300 - loss is 7.76520154556 - parameters are 2.00750204496 8.01210958284 4.81263383271\n",
      "Iteration 400 - loss is 9.41679543594 - parameters are 2.01165038477 8.01830842909 4.81328562092\n",
      "Iteration 500 - loss is 9.11577084357 - parameters are 2.00303816373 8.00727489402 4.81233543039\n",
      "Iteration 600 - loss is 8.15489162112 - parameters are 2.01487616924 8.01733051173 4.8139945326\n",
      "Iteration 700 - loss is 9.20784556431 - parameters are 2.01329689609 8.01546949988 4.81386191638\n",
      "Iteration 800 - loss is 7.29269068344 - parameters are 2.01449027393 8.02081224507 4.81452958224\n",
      "Iteration 900 - loss is 8.58479328455 - parameters are 2.01233431635 8.0162504276 4.81423101401\n",
      "Iteration 1000 - loss is 11.4869544271 - parameters are 2.01808870903 8.02152467381 4.81547680752\n",
      "Epoch 216\n",
      "Iteration 100 - loss is 9.07668276668 - parameters are 2.00660792808 8.0113958524 4.81442306792\n",
      "Iteration 200 - loss is 10.1069509493 - parameters are 2.01001152978 8.01248369818 4.81515333383\n",
      "Iteration 300 - loss is 7.76285663016 - parameters are 2.00735461982 8.01195272964 4.81503359449\n",
      "Iteration 400 - loss is 9.4170365388 - parameters are 2.01149404081 8.01814804036 4.81568096319\n",
      "Iteration 500 - loss is 9.10740624418 - parameters are 2.00288475598 8.0071171723 4.81472811048\n",
      "Iteration 600 - loss is 8.14926548019 - parameters are 2.01471286846 8.01716563874 4.81638188111\n",
      "Iteration 700 - loss is 9.20540583164 - parameters are 2.01313392936 8.01530460139 4.81624580711\n",
      "Iteration 800 - loss is 7.28757722843 - parameters are 2.01432691398 8.02064478683 4.81690923747\n",
      "Iteration 900 - loss is 8.58078293972 - parameters are 2.01218095026 8.01609013378 4.81660800425\n",
      "Iteration 1000 - loss is 11.4746668663 - parameters are 2.017924788 8.02135133504 4.81784842973\n",
      "Epoch 217\n",
      "Iteration 100 - loss is 9.06535040234 - parameters are 2.00646889882 8.01124783605 4.81679374951\n",
      "Iteration 200 - loss is 10.0960394552 - parameters are 2.00985308759 8.0123167533 4.81751675205\n",
      "Iteration 300 - loss is 7.76063117496 - parameters are 2.00720954258 8.01179836038 4.81739535332\n",
      "Iteration 400 - loss is 9.41735856977 - parameters are 2.01134018408 8.01799018925 4.81803837269\n",
      "Iteration 500 - loss is 9.09924574699 - parameters are 2.00273379022 8.00696194873 4.81708290057\n",
      "Iteration 600 - loss is 8.14382560493 - parameters are 2.01455216467 8.01700337444 4.81873142431\n",
      "Iteration 700 - loss is 9.20308595214 - parameters are 2.0129735562 8.01514231451 4.81859194802\n",
      "Iteration 800 - loss is 7.28263840417 - parameters are 2.014166153 8.02047997953 4.81925121031\n",
      "Iteration 900 - loss is 8.57692589195 - parameters are 2.01203002481 8.0159323783 4.81894735473\n",
      "Iteration 1000 - loss is 11.4626615363 - parameters are 2.01776347428 8.02118073954 4.8201824976\n",
      "Epoch 218\n",
      "Iteration 100 - loss is 9.05430313657 - parameters are 2.00633208361 8.01110216455 4.81912689215\n",
      "Iteration 200 - loss is 10.085414714 - parameters are 2.00969716503 8.01215244882 4.81984274663\n",
      "Iteration 300 - loss is 7.75852068946 - parameters are 2.00706677536 8.01164643545 4.81971971539\n",
      "Iteration 400 - loss is 9.41775757698 - parameters are 2.01118877455 8.01783483537 4.82035845448\n",
      "Iteration 500 - loss is 9.09128384598 - parameters are 2.00258522711 8.00680918343 4.81940040499\n",
      "Iteration 600 - loss is 8.13856597239 - parameters are 2.0143940161 8.0168436773 4.82104376519\n",
      "Iteration 700 - loss is 9.20088146227 - parameters are 2.01281573483 8.01498259757 4.82090094117\n",
      "Iteration 800 - loss is 7.27786848239 - parameters are 2.01400794918 8.02031778092 4.82155610174\n",
      "Iteration 900 - loss is 8.57321687499 - parameters are 2.01188150072 8.01577712067 4.82124966575\n",
      "Iteration 1000 - loss is 11.4509311819 - parameters are 2.01760472595 8.02101284359 4.82247961008\n",
      "Epoch 219\n",
      "Iteration 100 - loss is 9.04353310558 - parameters are 2.00619744674 8.01095880046 4.82142309449\n",
      "Iteration 200 - loss is 10.0750685751 - parameters are 2.00954372159 8.01199074271 4.82213191438\n",
      "Iteration 300 - loss is 7.75652083696 - parameters are 2.00692628093 8.01149691586 4.82200727707\n",
      "Iteration 400 - loss is 9.41822975599 - parameters are 2.01103977284 8.01768193896 4.82264180381\n",
      "Iteration 500 - loss is 9.0835151949 - parameters are 2.00243902794 8.0066588372 4.82168121832\n",
      "Iteration 600 - loss is 8.1334807529 - parameters are 2.01423838166 8.01668650644 4.82331949699\n",
      "Iteration 700 - loss is 9.19878805089 - parameters are 2.01266042417 8.01482540959 4.82317337891\n",
      "Iteration 800 - loss is 7.27326191989 - parameters are 2.01385226135 8.02015814942 4.82382450305\n",
      "Iteration 900 - loss is 8.5696507964 - parameters are 2.01173533932 8.01562432106 4.82351552789\n",
      "Iteration 1000 - loss is 11.4394687512 - parameters are 2.01744850173 8.02084760421 4.82474035638\n",
      "Epoch 220\n",
      "Iteration 100 - loss is 9.03303267688 - parameters are 2.00606495308 8.01081770697 4.82368294551\n",
      "Iteration 200 - loss is 10.0649931316 - parameters are 2.00939271741 8.01183159365 4.82438484247\n",
      "Iteration 300 - loss is 7.75462742944 - parameters are 2.00678802267 8.01134976327 4.82425862507\n",
      "Iteration 400 - loss is 9.41877144478 - parameters are 2.01089314024 8.01753146091 4.82488900633\n",
      "Iteration 500 - loss is 9.07593460237 - parameters are 2.00229515465 8.00651087144 4.82392592551\n",
      "Iteration 600 - loss is 8.12856430383 - parameters are 2.01408522095 8.01653182166 4.82555920334\n",
      "Iteration 700 - loss is 9.19680155419 - parameters are 2.01250758382 8.01467071022 4.82540984401\n",
      "Iteration 800 - loss is 7.26881335269 - parameters are 2.01369904907 8.02000104414 4.82605699595\n",
      "Iteration 900 - loss is 8.56622273189 - parameters are 2.01159150259 8.01547394029 4.8257455222\n",
      "Iteration 1000 - loss is 11.4282673906 - parameters are 2.01729476105 8.02068497909 4.82696531623\n",
      "Epoch 221\n",
      "Iteration 100 - loss is 9.0227944421 - parameters are 2.00593456812 8.01067884784 4.82590702469\n",
      "Iteration 200 - loss is 10.0551807135 - parameters are 2.00924411329 8.01167496096 4.82660210858\n",
      "Iteration 300 - loss is 7.75283642262 - parameters are 2.00665196454 8.01120493995 4.82647433664\n",
      "Iteration 400 - loss is 9.41937911882 - parameters are 2.01074883865 8.01738336274 4.8271006382\n",
      "Iteration 500 - loss is 9.06853702721 - parameters are 2.00215356982 8.00636524822 4.82613510208\n",
      "Iteration 600 - loss is 8.12381116358 - parameters are 2.01393449424 8.01637958339 4.82776345846\n",
      "Iteration 700 - loss is 9.19491795079 - parameters are 2.01235717403 8.01451845981 4.82761090982\n",
      "Iteration 800 - loss is 7.26451759015 - parameters are 2.01354827253 8.01984642483 4.82825415274\n",
      "Iteration 900 - loss is 8.56292791985 - parameters are 2.01144995313 8.01532593981 4.82794022035\n",
      "Iteration 1000 - loss is 11.4173204382 - parameters are 2.01714346399 8.0205249266 4.82915505997\n",
      "Epoch 222\n",
      "Iteration 100 - loss is 9.0128112102 - parameters are 2.00580625789 8.01054218745 4.82809590211\n",
      "Iteration 200 - loss is 10.0456238798 - parameters are 2.00909787067 8.01152080463 4.82878428104\n",
      "Iteration 300 - loss is 7.75114391124 - parameters are 2.00651807113 8.01106240878 4.8286549797\n",
      "Iteration 400 - loss is 9.42004938632 - parameters are 2.01060683061 8.01723760657 4.82927726628\n",
      "Iteration 500 - loss is 9.0613175738 - parameters are 2.00201423663 8.00622193018 4.82830931423\n",
      "Iteration 600 - loss is 8.1192160458 - parameters are 2.01378616242 8.0162297527 4.82993282729\n",
      "Iteration 700 - loss is 9.19313335709 - parameters are 2.01220915572 8.01436861931 4.82977714042\n",
      "Iteration 800 - loss is 7.26036960943 - parameters are 2.01339989257 8.01969425191 4.83041653652\n",
      "Iteration 900 - loss is 8.55976175605 - parameters are 2.01131065418 8.01518028168 4.83010018475\n",
      "Iteration 1000 - loss is 11.4066214181 - parameters are 2.0169945713 8.02036740581 4.83131014875\n",
      "Epoch 223\n",
      "Iteration 100 - loss is 9.00307600078 - parameters are 2.00567998898 8.01040769073 4.83025013869\n",
      "Iteration 200 - loss is 10.0363154114 - parameters are 2.00895395164 8.01136908529 4.83093191902\n",
      "Iteration 300 - loss is 7.74954612444 - parameters are 2.00638630758 8.01092213324 4.83080111299\n",
      "Iteration 400 - loss is 9.42077898373 - parameters are 2.01046707929 8.01709415517 4.8314194483\n",
      "Iteration 500 - loss is 9.05427148774 - parameters are 2.00187711885 8.00608088059 4.83044911903\n",
      "Iteration 600 - loss is 8.11477383371 - parameters are 2.01364018704 8.0160822913 4.83206786563\n",
      "Iteration 700 - loss is 9.19144402262 - parameters are 2.01206349044 8.01422115033 4.8319090908\n",
      "Iteration 800 - loss is 7.25636455008 - parameters are 2.0132538707 8.01954448641 4.83254470125\n",
      "Iteration 900 - loss is 8.5567197885 - parameters are 2.01117356955 8.01503692859 4.83222596874\n",
      "Iteration 1000 - loss is 11.3961640351 - parameters are 2.01684804436 8.02021237642 4.83343113463\n",
      "Epoch 224\n",
      "Iteration 100 - loss is 8.99358203764 - parameters are 2.00555572853 8.01027532319 4.83237028624\n",
      "Iteration 200 - loss is 10.0272483048 - parameters are 2.00881231888 8.0112197642 4.83304557266\n",
      "Iteration 300 - loss is 7.74803942128 - parameters are 2.00625663964 8.01078407741 4.83291328624\n",
      "Iteration 400 - loss is 9.42156477126 - parameters are 2.01032954843 8.01695297187 4.83352773295\n",
      "Iteration 500 - loss is 9.04739415152 - parameters are 2.00174218089 8.00594206329 4.83255506455\n",
      "Iteration 600 - loss is 8.11047957472 - parameters are 2.0134965303 8.0159371615 4.83416912035\n",
      "Iteration 700 - loss is 9.18984632571 - parameters are 2.01192014038 8.01407601508 4.83400730698\n",
      "Iteration 800 - loss is 7.25249770879 - parameters are 2.01311016904 8.01939709003 4.83463919198\n",
      "Iteration 900 - loss is 8.5537977125 - parameters are 2.01103866365 8.01489584383 4.83431811675\n",
      "Iteration 1000 - loss is 11.3859421694 - parameters are 2.01670384519 8.02005979879 4.83551856078\n",
      "Epoch 225\n",
      "Iteration 100 - loss is 8.98432274255 - parameters are 2.00543344424 8.01014505088 4.83445688772\n",
      "Iteration 200 - loss is 10.0184157648 - parameters are 2.00867293571 8.01107280325 4.83512578321\n",
      "Iteration 300 - loss is 7.74662028646 - parameters are 2.00612903359 8.01064820592 4.83499204031\n",
      "Iteration 400 - loss is 9.42240372861 - parameters are 2.01019420239 8.01681402062 4.83560266008\n",
      "Iteration 500 - loss is 9.04068108037 - parameters are 2.0016093877 8.00580544273 4.83462769003\n",
      "Iteration 600 - loss is 8.10632847511 - parameters are 2.01335515498 8.01579432623 4.83623712945\n",
      "Iteration 700 - loss is 9.18833676918 - parameters are 2.01177906835 8.01393317638 4.83607232618\n",
      "Iteration 800 - loss is 7.24876453434 - parameters are 2.01296875034 8.01925202504 4.83670054495\n",
      "Iteration 900 - loss is 8.55099136586 - parameters are 2.0109059015 8.01475699126 4.8363771644\n",
      "Iteration 1000 - loss is 11.3759498711 - parameters are 2.01656193643 8.01990963391 4.83757296162\n",
      "Epoch 226\n",
      "Iteration 100 - loss is 8.97529172917 - parameters are 2.00531310432 8.01001684041 4.8365104773\n",
      "Iteration 200 - loss is 10.0098111983 - parameters are 2.00853576603 8.01092816493 4.83717308321\n",
      "Iteration 300 - loss is 7.74528532613 - parameters are 2.00600345627 8.010514484 4.83703790734\n",
      "Iteration 400 - loss is 9.42329295088 - parameters are 2.0100610061 8.01667726592 4.83764476086\n",
      "Iteration 500 - loss is 9.03412791827 - parameters are 2.00147870482 8.00567098392 4.83666752601\n",
      "Iteration 600 - loss is 8.10231589497 - parameters are 2.0132160245 8.015653749 4.83827242228\n",
      "Iteration 700 - loss is 9.18691197623 - parameters are 2.01164023775 8.01379259767 4.83810467696\n",
      "Iteration 800 - loss is 7.24516062269 - parameters are 2.01282957795 8.01910925435 4.83872928777\n",
      "Iteration 900 - loss is 8.54829672421 - parameters are 2.01077524867 8.01462033535 4.83840363869\n",
      "Iteration 1000 - loss is 11.3661813553 - parameters are 2.01642228133 8.01976184342 4.83959486294\n",
      "Epoch 227\n",
      "Iteration 100 - loss is 8.96648279725 - parameters are 2.00519467751 8.00989065895 4.83853158054\n",
      "Iteration 200 - loss is 10.0014282084 - parameters are 2.00840077434 8.01078581234 4.8391879966\n",
      "Iteration 300 - loss is 7.74403126386 - parameters are 2.00587987509 8.01038287743 4.83905141087\n",
      "Iteration 400 - loss is 9.42422964456 - parameters are 2.00992992508 8.01654267286 4.83965455786\n",
      "Iteration 500 - loss is 9.02773043406 - parameters are 2.00135009838 8.00553865243 4.83867509447\n",
      "Iteration 600 - loss is 8.09843734323 - parameters are 2.01307910285 8.01551539393 4.84027551966\n",
      "Iteration 700 - loss is 9.18556868643 - parameters are 2.01150361262 8.01365424296 4.84010487934\n",
      "Iteration 800 - loss is 7.24168171225 - parameters are 2.01269261584 8.01896874146 4.84072593954\n",
      "Iteration 900 - loss is 8.54570989656 - parameters are 2.01064667129 8.01448584113 4.84039805813\n",
      "Iteration 1000 - loss is 11.3566309972 - parameters are 2.01628484375 8.01961638955 4.84158478205\n",
      "Epoch 228\n",
      "Iteration 100 - loss is 8.95788992694 - parameters are 2.00507813306 8.00976647415 4.84052071454\n",
      "Iteration 200 - loss is 9.99326058778 - parameters are 2.00826792573 8.01064570917 4.84117103888\n",
      "Iteration 300 - loss is 7.74285493678 - parameters are 2.00575825796 8.01025335253 4.84103306603\n",
      "Iteration 400 - loss is 9.42521112367 - parameters are 2.0098009254 8.01641020709 4.84163256525\n",
      "Iteration 500 - loss is 9.02148451762 - parameters are 2.00122353502 8.0054084144 4.84065090898\n",
      "Iteration 600 - loss is 8.09468847293 - parameters are 2.01294435464 8.01537922568 4.842246934\n",
      "Iteration 700 - loss is 9.18430375188 - parameters are 2.01136915754 8.01351807684 4.84207344499\n",
      "Iteration 800 - loss is 7.23832367927 - parameters are 2.01255782854 8.01883045046 4.84269101099\n",
      "Iteration 900 - loss is 8.54322712093 - parameters are 2.01052013607 8.0143534742 4.84236093285\n",
      "Iteration 1000 - loss is 11.3472933273 - parameters are 2.01614958812 8.01947323515 4.84354322792\n",
      "Epoch 229\n",
      "Iteration 100 - loss is 8.94950727328 - parameters are 2.00496344074 8.00964425424 4.84247838806\n",
      "Iteration 200 - loss is 9.98530231332 - parameters are 2.00813718584 8.0105078197 4.84312271724\n",
      "Iteration 300 - loss is 7.74175329175 - parameters are 2.00563857335 8.0101258762 4.84298337964\n",
      "Iteration 400 - loss is 9.42623480603 - parameters are 2.00967397368 8.01627983481 4.84357928891\n",
      "Iteration 500 - loss is 9.01538617629 - parameters are 2.00109898196 8.0052802365 4.84259547485\n",
      "Iteration 600 - loss is 8.09106507656 - parameters are 2.01281174504 8.01524520952 4.84418716948\n",
      "Iteration 700 - loss is 9.18311413348 - parameters are 2.01123683771 8.01338406449 4.84401087731\n",
      "Iteration 800 - loss is 7.23508253343 - parameters are 2.01242518119 8.018694346 4.84462500463\n",
      "Iteration 900 - loss is 8.54084476015 - parameters are 2.01039561023 8.01422320071 4.8442927648\n",
      "Iteration 1000 - loss is 11.3381630271 - parameters are 2.01601647948 8.01933234367 4.84547070136\n",
      "Epoch 230\n",
      "Iteration 100 - loss is 8.94132916089 - parameters are 2.0048505708 8.00952396791 4.84440510169\n",
      "Iteration 200 - loss is 9.97754754022 - parameters are 2.00800852088 8.01037210877 4.84504353073\n",
      "Iteration 300 - loss is 7.74072338176 - parameters are 2.00552079021 8.01000041582 4.84490285036\n",
      "Iteration 400 - loss is 9.42729820966 - parameters are 2.0095490371 8.01615152276 4.84549522657\n",
      "Iteration 500 - loss is 9.00943153127 - parameters are 2.00097640694 8.00515408594 4.84450928924\n",
      "Iteration 600 - loss is 8.08756308161 - parameters are 2.01268123978 8.01511331125 4.84609672214\n",
      "Iteration 700 - loss is 9.1819968973 - parameters are 2.01110661888 8.01325217162 4.84591767162\n",
      "Iteration 800 - loss is 7.23195441353 - parameters are 2.01229463948 8.01856039332 4.84652841487\n",
      "Iteration 900 - loss is 8.53855929779 - parameters are 2.01027306157 8.01409498735 4.84619404782\n",
      "Iteration 1000 - loss is 11.3292349242 - parameters are 2.01588548342 8.01919367913 4.84736769508\n",
      "Epoch 231\n",
      "Iteration 100 - loss is 8.93335007884 - parameters are 2.00473949397 8.0094055844 4.84630134792\n",
      "Iteration 200 - loss is 9.96999059655 - parameters are 2.00788189761 8.01023854179 4.84693397033\n",
      "Iteration 300 - loss is 7.73976236236 - parameters are 2.00540487804 8.00987693934 4.84679196882\n",
      "Iteration 400 - loss is 9.42839894931 - parameters are 2.00942608337 8.01602523821 4.84738086796\n",
      "Iteration 500 - loss is 9.00361681423 - parameters are 2.00085577825 8.00502993047 4.84639284131\n",
      "Iteration 600 - loss is 8.08417854626 - parameters are 2.01255280516 8.01498349723 4.84797608004\n",
      "Iteration 700 - loss is 9.18094921109 - parameters are 2.01097846737 8.01312236453 4.84779431524\n",
      "Iteration 800 - loss is 7.22893558332 - parameters are 2.01216616967 8.01842855821 4.84840172818\n",
      "Iteration 900 - loss is 8.53636733423 - parameters are 2.01015245836 8.01396880135 4.84806526782\n",
      "Iteration 1000 - loss is 11.3205039884 - parameters are 2.01575656609 8.01905720617 4.84923469387\n",
      "Epoch 232\n",
      "Iteration 100 - loss is 8.92556467564 - parameters are 2.00463018148 8.0092890734 4.84816761135\n",
      "Iteration 200 - loss is 9.96262597799 - parameters are 2.00775728335 8.01010708473 4.84879451913\n",
      "Iteration 300 - loss is 7.7388674883 - parameters are 2.0052908068 8.00975541519 4.84865121776\n",
      "Iteration 400 - loss is 9.42953473308 - parameters are 2.00930508072 8.01590094896 4.84923669493\n",
      "Iteration 500 - loss is 8.99793836398 - parameters are 2.00073706466 8.00490773835 4.84824661235\n",
      "Iteration 600 - loss is 8.08090765514 - parameters are 2.01242640804 8.01485573435 4.8498257234\n",
      "Iteration 700 - loss is 9.17996834093 - parameters are 2.01085235003 8.01299461002 4.84964128769\n",
      "Iteration 800 - loss is 7.22602242752 - parameters are 2.01203973857 8.018298807 4.85024542319\n",
      "Iteration 900 - loss is 8.53426558287 - parameters are 2.01003376945 8.01384461047 4.84990690289\n",
      "Iteration 1000 - loss is 11.3119653272 - parameters are 2.01562969421 8.01892288994 4.85107217473\n",
      "Epoch 233\n",
      "Iteration 100 - loss is 8.91796775439 - parameters are 2.00452260502 8.00917440514 4.85000436877\n",
      "Iteration 200 - loss is 9.95544834266 - parameters are 2.00763464592 8.0099777041 4.85062565246\n",
      "Iteration 300 - loss is 7.73803611017 - parameters are 2.00517854697 8.00963581234 4.85048107215\n",
      "Iteration 400 - loss is 9.43070335915 - parameters are 2.00918599792 8.01577862333 4.85106318155\n",
      "Iteration 500 - loss is 8.99239262325 - parameters are 2.00062023549 8.00478747834 4.85007107591\n",
      "Iteration 600 - loss is 8.07774671535 - parameters are 2.0123020158 8.01472999004 4.8516461247\n",
      "Iteration 700 - loss is 9.17905164791 - parameters are 2.01072823428 8.01286887547 4.85145906074\n",
      "Iteration 800 - loss is 7.22321144786 - parameters are 2.01191531352 8.01817110659 4.85205997083\n",
      "Iteration 900 - loss is 8.5322508664 - parameters are 2.00991696415 8.01372238298 4.85171942341\n",
      "Iteration 1000 - loss is 11.3036141821 - parameters are 2.01550483503 8.0187906962 4.85288060699\n",
      "Epoch 234\n",
      "Iteration 100 - loss is 8.91055426815 - parameters are 2.00441673675 8.00906155027 4.85181208931\n",
      "Iteration 200 - loss is 9.94845250614 - parameters are 2.00751395368 8.00985036694 4.852427838\n",
      "Iteration 300 - loss is 7.73726567128 - parameters are 2.00506806949 8.00951810024 4.85228199933\n",
      "Iteration 400 - loss is 9.43190271268 - parameters are 2.00906880422 8.01565823015 4.85286079432\n",
      "Iteration 500 - loss is 8.98697613557 - parameters are 2.00050526053 8.00466911972 4.85186669794\n",
      "Iteration 600 - loss is 8.07469215247 - parameters are 2.01217959636 8.01460623225 4.85343774884\n",
      "Iteration 700 - loss is 9.17819658504 - parameters are 2.01060608805 8.01274512874 4.85324809859\n",
      "Iteration 800 - loss is 7.22049925938 - parameters are 2.01179286241 8.01804542438 4.85384583448\n",
      "Iteration 900 - loss is 8.53032011329 - parameters are 2.0098020123 8.01360208769 4.85350329223\n",
      "Iteration 1000 - loss is 11.2954459243 - parameters are 2.01538195634 8.01866059122 4.85466045241\n",
      "Epoch 235\n",
      "Iteration 100 - loss is 8.90331931533 - parameters are 2.00431254927 8.00895047997 4.85359123454\n",
      "Iteration 200 - loss is 9.94163343664 - parameters are 2.00739517552 8.00972504083 4.85420153591\n",
      "Iteration 300 - loss is 7.73655370449 - parameters are 2.0049593458 8.00940224884 4.85405445912\n",
      "Iteration 400 - loss is 9.43313076274 - parameters are 2.00895346939 8.01553973874 4.85462999218\n",
      "Iteration 500 - loss is 8.98168554227 - parameters are 2.00039211009 8.00455263227 4.85363393688\n",
      "Iteration 600 - loss is 8.07174050681 - parameters are 2.01205911816 8.01448442945 4.85520105324\n",
      "Iteration 700 - loss is 9.17740069413 - parameters are 2.0104858798 8.01262333824 4.85500885798\n",
      "Iteration 800 - loss is 7.21788258674 - parameters are 2.01167235363 8.01792172831 4.85560347005\n",
      "Iteration 900 - loss is 8.52847035433 - parameters are 2.00968888421 8.01348369386 4.85525896474\n",
      "Iteration 1000 - loss is 11.2874560511 - parameters are 2.01526102643 8.01853254184 4.85641216537\n",
      "Epoch 236\n",
      "Iteration 100 - loss is 8.89625813535 - parameters are 2.00421001564 8.00884116585 4.85534225864\n",
      "Iteration 200 - loss is 9.93498625035 - parameters are 2.00727828082 8.00960169387 4.85594719896\n",
      "Iteration 300 - loss is 7.73589782929 - parameters are 2.00485234779 8.00928822856 4.85579890395\n",
      "Iteration 400 - loss is 9.43438555935 - parameters are 2.00883996368 8.0154231189 4.85637122676\n",
      "Iteration 500 - loss is 8.97651757952 - parameters are 2.00028075494 8.00443798623 4.8553732438\n",
      "Iteration 600 - loss is 8.06888842972 - parameters are 2.01194055016 8.0143645506 4.85693648796\n",
      "Iteration 700 - loss is 9.17666160287 - parameters are 2.0103675785 8.01250347287 4.85674178832\n",
      "Iteration 800 - loss is 7.21535826072 - parameters are 2.01155375612 8.01779998683 4.85733332614\n",
      "Iteration 900 - loss is 8.52669871926 - parameters are 2.00957755069 8.01336717128 4.85698688903\n",
      "Iteration 1000 - loss is 11.2796401823 - parameters are 2.01514201415 8.01840651543 4.85813619292\n",
      "Epoch 237\n",
      "Iteration 100 - loss is 8.88936610439 - parameters are 2.00410910936 8.00873357998 4.85706560848\n",
      "Iteration 200 - loss is 9.92850620691 - parameters are 2.00716323945 8.00948029465 4.85766527264\n",
      "Iteration 300 - loss is 7.73529574889 - parameters are 2.00474704781 8.0091760103 4.857515779\n",
      "Iteration 400 - loss is 9.43566523072 - parameters are 2.00872825784 8.01530834096 4.85808494238\n",
      "Iteration 500 - loss is 8.97146907553 - parameters are 2.00017116634 8.00432515233 4.85708506255\n",
      "Iteration 600 - loss is 8.06613268004 - parameters are 2.01182386182 8.01424656516 4.85864449585\n",
      "Iteration 700 - loss is 9.17597702196 - parameters are 2.01025115363 8.01238550203 4.85844733178\n",
      "Iteration 800 - loss is 7.21292321478 - parameters are 2.01143703929 8.0176801689 4.85903584412\n",
      "Iteration 900 - loss is 8.52500243358 - parameters are 2.00946798302 8.01325249023 4.85868750598\n",
      "Iteration 1000 - loss is 11.2719940565 - parameters are 2.01502488882 8.01828247985 4.85983297494\n",
      "Epoch 238\n",
      "Iteration 100 - loss is 8.88263873121 - parameters are 2.00400980436 8.00862769488 4.85876172375\n",
      "Iteration 200 - loss is 9.92218870501 - parameters are 2.00705002179 8.00936081229 4.8593561953\n",
      "Iteration 300 - loss is 7.7347452474 - parameters are 2.00464341867 8.00906556544 4.85920552228\n",
      "Iteration 400 - loss is 9.4369679804 - parameters are 2.00861832309 8.01519537567 4.85977157626\n",
      "Iteration 500 - loss is 8.96653694778 - parameters are 2.00006331602 8.00421410178 4.85876982984\n",
      "Iteration 600 - loss is 8.06347012064 - parameters are 2.01170902309 8.01413044311 4.86032551263\n",
      "Iteration 700 - loss is 9.17534474234 - parameters are 2.01013657518 8.01226939563 4.86012592345\n",
      "Iteration 800 - loss is 7.2105744818 - parameters are 2.01132217306 8.01756224397 4.86071145832\n",
      "Iteration 900 - loss is 8.52337881541 - parameters are 2.00936015295 8.01313962144 4.8603612494\n",
      "Iteration 1000 - loss is 11.2645135274 - parameters are 2.01490962028 8.01816040353 4.86150294425\n",
      "Epoch 239\n",
      "Iteration 100 - loss is 8.8760716532 - parameters are 2.003912075 8.00852348353 4.86043103709\n",
      "Iteration 200 - loss is 9.91602927816 - parameters are 2.00693859868 8.00924321639 4.86102039824\n",
      "Iteration 300 - loss is 7.73424418717 - parameters are 2.0045414336 8.00895686581 4.86086856478\n",
      "Iteration 400 - loss is 9.43829208472 - parameters are 2.0085101311 8.01508419428 4.86143155859\n",
      "Iteration 500 - loss is 8.96171820038 - parameters are 1.99995717615 8.00410480625 4.86042797537\n",
      "Iteration 600 - loss is 8.06089771513 - parameters are 2.01159600442 8.01401615486 4.86197996705\n",
      "Iteration 700 - loss is 9.17476263253 - parameters are 2.0100238136 8.01215512404 4.86177799143\n",
      "Iteration 800 - loss is 7.20830919081 - parameters are 2.01120912785 8.01744618199 4.86236059606\n",
      "Iteration 900 - loss is 8.52182527248 - parameters are 2.00925403268 8.01302853612 4.86200854614\n",
      "Iteration 1000 - loss is 11.2571945611 - parameters are 2.01479617884 8.01804025535 4.86314652672\n",
      "Epoch 240\n",
      "Iteration 100 - loss is 8.86966063248 - parameters are 2.00381589605 8.00842091931 4.86207397419\n",
      "Iteration 200 - loss is 9.9100235906 - parameters are 2.00682894146 8.00912747704 4.86265830583\n",
      "Iteration 300 - loss is 7.73379050616 - parameters are 2.0044410663 8.00884988368 4.86250533058\n",
      "Iteration 400 - loss is 9.43963589019 - parameters are 2.00840365403 8.01497476849 4.86306531265\n",
      "Iteration 500 - loss is 8.95700992146 - parameters are 1.99985271939 8.00399723784 4.86205992193\n",
      "Iteration 600 - loss is 8.0584125246 - parameters are 2.01148477673 8.01390367134 4.86360828097\n",
      "Iteration 700 - loss is 9.17422863602 - parameters are 2.00991283984 8.01204265812 4.86340395696\n",
      "Iteration 800 - loss is 7.20612456399 - parameters are 2.01109787455 8.01733195338 4.86398367782\n",
      "Iteration 900 - loss is 8.52033929921 - parameters are 2.00914959487 8.01291920596 4.86362981619\n",
      "Iteration 1000 - loss is 11.2500332321 - parameters are 2.01468453532 8.01792200472 4.8647641414\n",
      "Epoch 241\n",
      "Iteration 100 - loss is 8.86340155218 - parameters are 2.00372124269 8.00831997606 4.86369095392\n",
      "Iteration 200 - loss is 9.90416743326 - parameters are 2.00672102191 8.00901356479 4.86427033567\n",
      "Iteration 300 - loss is 7.73338221541 - parameters are 2.00434229087 8.00874459178 4.86411623694\n",
      "Iteration 400 - loss is 9.44099781099 - parameters are 2.00829886447 8.01486707047 4.86467325495\n",
      "Iteration 500 - loss is 8.9524092807 - parameters are 1.99974991882 8.00389136914 4.86366608557\n",
      "Iteration 600 - loss is 8.0560117045 - parameters are 2.01137531142 8.01379296391 4.86521086947\n",
      "Iteration 700 - loss is 9.1737407688 - parameters are 2.00980362531 8.01193196918 4.86500423451\n",
      "Iteration 800 - loss is 7.20401791357 - parameters are 2.01098838453 8.01721952905 4.86558111732\n",
      "Iteration 900 - loss is 8.51891847384 - parameters are 2.00904681264 8.01281160309 4.86522547281\n",
      "Iteration 1000 - loss is 11.2430257208 - parameters are 2.01457466098 8.01780562154 4.86635620059\n",
      "Epoch 242\n",
      "Iteration 100 - loss is 8.85729041279 - parameters are 2.00362809051 8.00822062802 4.86528238842\n",
      "Iteration 200 - loss is 9.89845671997 - parameters are 2.00661481228 8.00890145069 4.86585689861\n",
      "Iteration 300 - loss is 7.73301739659 - parameters are 2.00424508185 8.00864096329 4.86570169444\n",
      "Iteration 400 - loss is 9.44237632664 - parameters are 2.00819573545 8.01476107281 4.8662557953\n",
      "Iteration 500 - loss is 8.94791352689 - parameters are 1.99964874794 8.00378717314 4.86524687562\n",
      "Iteration 600 - loss is 8.05369250167 - parameters are 2.01126758034 8.01368400441 4.86678814098\n",
      "Iteration 700 - loss is 9.1732971169 - parameters are 2.00969614191 8.01182302902 4.86657923191\n",
      "Iteration 800 - loss is 7.20198663903 - parameters are 2.0108806296 8.01710888036 4.86715332168\n",
      "Iteration 900 - loss is 8.51756045575 - parameters are 2.00894565951 8.01270570007 4.86679592263\n",
      "Iteration 1000 - loss is 11.2361683097 - parameters are 2.01446652757 8.01769107618 4.86792311002\n",
      "Epoch 243\n",
      "Iteration 100 - loss is 8.85132332861 - parameters are 2.00353641549 8.00812284986 4.86684868323\n",
      "Iteration 200 - loss is 9.89288748366 - parameters are 2.00651028527 8.00879110624 4.86741839897\n",
      "Iteration 300 - loss is 7.73269419963 - parameters are 2.00414941419 8.00853897178 4.86726210709\n",
      "Iteration 400 - loss is 9.44376997965 - parameters are 2.00809424047 8.01465674854 4.86781333695\n",
      "Iteration 500 - loss is 8.94351998559 - parameters are 1.99954918072 8.00368462328 4.86680269488\n",
      "Iteration 600 - loss is 8.05145225134 - parameters are 2.01116155581 8.01357676512 4.86834049741\n",
      "Iteration 700 - loss is 9.17289583409 - parameters are 2.00959036196 8.01171580986 4.86812935045\n",
      "Iteration 800 - loss is 7.20002822425 - parameters are 2.01077458207 8.01699997914 4.86870069146\n",
      "Iteration 900 - loss is 8.5162629828 - parameters are 2.00884610946 8.01260146993 4.86834156579\n",
      "Iteration 1000 - loss is 11.2294573813 - parameters are 2.01436010729 8.01757833949 4.86946526888\n",
      "Epoch 244\n",
      "Iteration 100 - loss is 8.84549652439 - parameters are 2.00344619402 8.00802661664 4.8683902374\n",
      "Iteration 200 - loss is 9.8874558728 - parameters are 2.00640741403 8.00868250339 4.86895523454\n",
      "Iteration 300 - loss is 7.73241084047 - parameters are 2.00405526323 8.00843859129 4.86879787239\n",
      "Iteration 400 - loss is 9.44517737328 - parameters are 2.00799435343 8.01455407116 4.86934627669\n",
      "Iteration 500 - loss is 8.93922605685 - parameters are 1.99945119153 8.00358369344 4.86833393968\n",
      "Iteration 600 - loss is 8.04928837437 - parameters are 2.0110572106 8.01347121877 4.86986833419\n",
      "Iteration 700 - loss is 9.17253513958 - parameters are 2.00948625826 8.0116102844 4.869654985\n",
      "Iteration 800 - loss is 7.19814023476 - parameters are 2.01067021466 8.01689279766 4.87022362081\n",
      "Iteration 900 - loss is 8.51502386874 - parameters are 2.00874813688 8.01249888612 4.86986279597\n",
      "Iteration 1000 - loss is 11.2228894145 - parameters are 2.0142553728 8.01746738279 4.87098306999\n",
      "Epoch 245\n",
      "Iteration 100 - loss is 8.83980633198 - parameters are 2.00335740285 8.00793190382 4.86990744357\n",
      "Iteration 200 - loss is 9.88215814782 - parameters are 2.00630617211 8.00857561454 4.87046779677\n",
      "Iteration 300 - loss is 7.73216559881 - parameters are 2.00396260474 8.00833979623 4.87030938151\n",
      "Iteration 400 - loss is 9.44659716941 - parameters are 2.00789604867 8.01445301453 4.87085500494\n",
      "Iteration 500 - loss is 8.93502921302 - parameters are 1.99935475516 8.0034843579 4.86984100001\n",
      "Iteration 600 - loss is 8.04719837447 - parameters are 2.0109545179 8.01336733853 4.87137204043\n",
      "Iteration 700 - loss is 9.17221331585 - parameters are 2.00938380403 8.01150642573 4.87115652409\n",
      "Iteration 800 - loss is 7.1963203152 - parameters are 2.01056750055 8.01678730864 4.87172249759\n",
      "Iteration 900 - loss is 8.51384100074 - parameters are 2.00865171658 8.01239792251 4.87136000058\n",
      "Iteration 1000 - loss is 11.2164609823 - parameters are 2.01415229719 8.01735817785 4.87247689986\n",
      "Epoch 246\n",
      "Iteration 100 - loss is 8.83424918716 - parameters are 2.00327001912 8.00783868727 4.87140068808\n",
      "Iteration 200 - loss is 9.8769906778 - parameters are 2.00620653353 8.00847041255 4.87195647081\n",
      "Iteration 300 - loss is 7.73195681598 - parameters are 2.00387141486 8.00824256146 4.87179701932\n",
      "Iteration 400 - loss is 9.44802808642 - parameters are 2.00779930092 8.01435355299 4.87233990589\n",
      "Iteration 500 - loss is 8.93092699659 - parameters are 1.99925984681 8.00338659135 4.87132425961\n",
      "Iteration 600 - loss is 8.04517983559 - parameters are 2.01085345137 8.01326509798 4.87285199902\n",
      "Iteration 700 - loss is 9.17192870653 - parameters are 2.00928297294 8.01140420742 4.87263435004\n",
      "Iteration 800 - loss is 7.1945661867 - parameters are 2.01046641336 8.01668348525 4.87319770341\n",
      "Iteration 900 - loss is 8.512712337 - parameters are 2.00855682377 8.01229855339 4.87283356082\n",
      "Iteration 1000 - loss is 11.2101687486 - parameters are 2.01405085399 8.0172506969 4.87394713883\n",
      "Epoch 247\n",
      "Iteration 100 - loss is 8.82882162649 - parameters are 2.00318402035 8.00774694324 4.87287035113\n",
      "Iteration 200 - loss is 9.8719499371 - parameters are 2.00610847272 8.00836687067 4.87342163568\n",
      "Iteration 300 - loss is 7.73178289287 - parameters are 2.00378167012 8.00814686222 4.87326116456\n",
      "Iteration 400 - loss is 9.44946889717 - parameters are 2.00770408535 8.01425566124 4.87380135755\n",
      "Iteration 500 - loss is 8.92691701813 - parameters are 1.99916644208 8.00329036889 4.87278409607\n",
      "Iteration 600 - loss is 8.04323041929 - parameters are 2.01075398505 8.01316447114 4.87430858671\n",
      "Iteration 700 - loss is 9.17167971435 - parameters are 2.00918373907 8.01130360344 4.87408883904\n",
      "Iteration 800 - loss is 7.19287564445 - parameters are 2.01036692713 8.01658130106 4.8746496138\n",
      "Iteration 900 - loss is 8.51163590446 - parameters are 2.00846343407 8.01220075346 4.87428385178\n",
      "Iteration 1000 - loss is 11.2040094662 - parameters are 2.01395101716 8.0171449126 4.87539416112\n",
      "Epoch 248\n",
      "Iteration 100 - loss is 8.82352028436 - parameters are 2.00309938439 8.00765664834 4.87431680677\n",
      "Iteration 200 - loss is 9.86703250221 - parameters are 2.00601196451 8.00826496263 4.8748636643\n",
      "Iteration 300 - loss is 7.73164228793 - parameters are 2.00369334745 8.00805267416 4.87470218989\n",
      "Iteration 400 - loss is 9.4509184271 - parameters are 2.00761037752 8.01415931443 4.87523973189\n",
      "Iteration 500 - loss is 8.92299695428 - parameters are 1.99907451697 8.00319566603 4.87422088095\n",
      "Iteration 600 - loss is 8.04134786233 - parameters are 2.01065609345 8.01306543244 4.87574217421\n",
      "Iteration 700 - loss is 9.17146479915 - parameters are 2.00908607694 8.01120458817 4.87552036126\n",
      "Iteration 800 - loss is 7.19124655532 - parameters are 2.01026901631 8.01648073009 4.87607859826\n",
      "Iteration 900 - loss is 8.51060979648 - parameters are 2.00837152351 8.01210449784 4.87571124254\n",
      "Iteration 1000 - loss is 11.1979799738 - parameters are 2.01385276108 8.01704079808 4.87681833499\n",
      "Epoch 249\n",
      "Iteration 100 - loss is 8.81834189001 - parameters are 2.00301608949 8.00756777959 4.87574042312\n",
      "Iteration 200 - loss is 9.86223504866 - parameters are 2.00591698414 8.00816466253 4.87628292364\n",
      "Iteration 300 - loss is 7.73153351524 - parameters are 2.00360642414 8.00795997329 4.87612046199\n",
      "Iteration 400 - loss is 9.45237555229 - parameters are 2.00751815338 8.01406448806 4.87665539495\n",
      "Iteration 500 - loss is 8.91916454583 - parameters are 1.99898404786 8.00310245865 4.87563497985\n",
      "Iteration 600 - loss is 8.03952997421 - parameters are 2.01055975145 8.01296795671 4.87715312632\n",
      "Iteration 700 - loss is 9.17128247599 - parameters are 2.00898996147 8.01110713641 4.87692928095\n",
      "Iteration 800 - loss is 7.18967685556 - parameters are 2.01017265579 8.01638174676 4.87748502039\n",
      "Iteration 900 - loss is 8.50963217073 - parameters are 2.00828106847 8.01200976203 4.87711609629\n",
      "Iteration 1000 - loss is 11.1920771935 - parameters are 2.01375606055 8.01693832685 4.87822002279\n",
      "Epoch 250\n",
      "Iteration 100 - loss is 8.81328326477 - parameters are 2.00293411424 8.00748031436 4.87714156238\n",
      "Iteration 200 - loss is 9.85755434801 - parameters are 2.00582350726 8.00806594492 4.8776797748\n",
      "Iteration 300 - loss is 7.73145514265 - parameters are 2.00352087784 8.00786873605 4.87751634171\n",
      "Iteration 400 - loss is 9.45383919766 - parameters are 2.00742738927 8.01397115806 4.87804870688\n",
      "Iteration 500 - loss is 8.91541759579 - parameters are 1.99889501152 8.00301072305 4.87702675252\n",
      "Iteration 600 - loss is 8.03777463489 - parameters are 2.01046493435 8.01287201919 4.87854180197\n",
      "Iteration 700 - loss is 9.17113131324 - parameters are 2.00889536798 8.01101122337 4.87831595654\n",
      "Iteration 800 - loss is 7.18816454854 - parameters are 2.01007782083 8.0162843259 4.87886923798\n",
      "Iteration 900 - loss is 8.50870124708 - parameters are 2.00819204573 8.01191652194 4.8784987704\n",
      "Iteration 1000 - loss is 11.1862981288 - parameters are 2.01366089077 8.01683747289 4.87959958109\n",
      "Epoch 251\n",
      "Iteration 100 - loss is 8.80834131926 - parameters are 2.00285343756 8.00739423037 4.87852058096\n",
      "Iteration 200 - loss is 9.85298726496 - parameters are 2.00573150991 8.00796878475 4.87905457308\n",
      "Iteration 300 - loss is 7.73140578991 - parameters are 2.00343668657 8.00777893922 4.87889018411\n",
      "Iteration 400 - loss is 9.45530833524 - parameters are 2.00733806192 8.01387930072 4.87942002209\n",
      "Iteration 500 - loss is 8.91175396759 - parameters are 1.99880738509 8.00292043587 4.87839655296\n",
      "Iteration 600 - loss is 8.0360797925 - parameters are 2.01037161786 8.01277759553 4.87990855439\n",
      "Iteration 700 - loss is 9.17100993086 - parameters are 2.0088022722 8.01091682464 4.8796807407\n",
      "Iteration 800 - loss is 7.18670770263 - parameters are 2.00998448712 8.01618844275 4.88023160307\n",
      "Iteration 900 - loss is 8.50781530551 - parameters are 2.00810443247 8.01182475384 4.87985961654\n",
      "Iteration 1000 - loss is 11.180639862 - parameters are 2.01356722734 8.01673821056 4.88095736075\n",
      "Epoch 252\n",
      "Iteration 100 - loss is 8.80351305079 - parameters are 2.00277403873 8.00730950572 4.87987782958\n",
      "Iteration 200 - loss is 9.84853075454 - parameters are 2.00564096851 8.00787315734 4.88040766812\n",
      "Iteration 300 - loss is 7.731384127 - parameters are 2.00335382871 8.00769055996 4.88024233856\n",
      "Iteration 400 - loss is 9.45678198241 - parameters are 2.00725014844 8.01378889272 4.8807696893\n",
      "Iteration 500 - loss is 8.90817158329 - parameters are 1.99872114609 8.00283157415 4.87974472953\n",
      "Iteration 600 - loss is 8.03444346118 - parameters are 2.01027977808 8.01268466173 4.88125373113\n",
      "Iteration 700 - loss is 9.17091699861 - parameters are 2.00871065026 8.01082391622 4.8810239805\n",
      "Iteration 800 - loss is 7.18530444908 - parameters are 2.00989263073 8.01609407294 4.88157246211\n",
      "Iteration 900 - loss is 8.50697268424 - parameters are 2.00801820621 8.0117344344 4.88119898073\n",
      "Iteration 1000 - loss is 11.1750995518 - parameters are 2.01347504626 8.01664051466 4.88229370702\n",
      "Epoch 253\n",
      "Iteration 100 - loss is 8.79879554073 - parameters are 2.00269589737 8.00722611884 4.88121365334\n",
      "Iteration 200 - loss is 9.84418185937 - parameters are 2.00555185987 8.00777903844 4.88173940397\n",
      "Iteration 300 - loss is 7.73138887238 - parameters are 2.003272283 8.0076035758 4.88157314887\n",
      "Iteration 400 - loss is 9.45825920032 - parameters are 2.00716362628 8.01369991111 4.8820980517\n",
      "Iteration 500 - loss is 8.90466842189 - parameters are 1.9986362724 8.00274411529 4.88107162499\n",
      "Iteration 600 - loss is 8.03286371895 - parameters are 2.01018939148 8.01259319421 4.88257767421\n",
      "Iteration 700 - loss is 9.17085123441 - parameters are 2.00862047866 8.01073247447 4.88234601743\n",
      "Iteration 800 - loss is 7.18395298003 - parameters are 2.00980222812 8.01600119249 4.88289215597\n",
      "Iteration 900 - loss is 8.50617177772 - parameters are 2.00793334483 8.01164554065 4.88251720349\n",
      "Iteration 1000 - loss is 11.1696744317 - parameters are 2.01338432391 8.01654436036 4.88360895961\n",
      "Epoch 254\n",
      "Iteration 100 - loss is 8.79418595207 - parameters are 2.00261899341 8.00714404853 4.88252839184\n",
      "Iteration 200 - loss is 9.83993770707 - parameters are 2.00546416118 8.00768640416 4.88305011918\n",
      "Iteration 300 - loss is 7.73141879136 - parameters are 2.00319202849 8.00751796464 4.88288295334\n",
      "Iteration 400 - loss is 9.45973909226 - parameters are 2.00707847329 8.0136123333 4.88340544694\n",
      "Iteration 500 - loss is 8.90124251763 - parameters are 1.99855274225 8.00265803704 4.88237757664\n",
      "Iteration 600 - loss is 8.03133870572 - parameters are 2.01010043491 8.01250316975 4.88388072016\n",
      "Iteration 700 - loss is 9.17081140267 - parameters are 2.00853173428 8.01064247616 4.88364718754\n",
      "Iteration 800 - loss is 7.18265154649 - parameters are 2.00971325613 8.0159097778 4.88419102011\n",
      "Iteration 900 - loss is 8.50541103488 - parameters are 2.00784982659 8.01155805001 4.88381461987\n",
      "Iteration 1000 - loss is 11.1643618072 - parameters are 2.01329503706 8.01644972326 4.88490345285\n",
      "Epoch 255\n",
      "Iteration 100 - loss is 8.78968152699 - parameters are 2.00254330711 8.0070632739 4.88382237924\n",
      "Iteration 200 - loss is 9.83579550763 - parameters are 2.00537784997 8.00759523102 4.88434014689\n",
      "Iteration 300 - loss is 7.73147269454 - parameters are 2.00311304461 8.00743370471 4.88417208485\n",
      "Iteration 400 - loss is 9.46122080215 - parameters are 2.00699466767 8.01352613706 4.88469220732\n",
      "Iteration 500 - loss is 8.89789195842 - parameters are 1.99847053422 8.00257331753 4.88366291638\n",
      "Iteration 600 - loss is 8.02986662124 - parameters are 2.01001288562 8.0124145655 4.88516320014\n",
      "Iteration 700 - loss is 9.17079631279 - parameters are 2.00844439439 8.01055389839 4.88492782151\n",
      "Iteration 800 - loss is 7.18139845652 - parameters are 2.00962569196 8.01581980566 4.88546938461\n",
      "Iteration 900 - loss is 8.50468895726 - parameters are 2.00776763009 8.01147194023 4.8850915596\n",
      "Iteration 1000 - loss is 11.1591590542 - parameters are 2.01320716285 8.01635657932 4.8861775157\n",
      "Epoch 256\n",
      "Iteration 100 - loss is 8.78527958448 - parameters are 2.00246881906 8.00698377442 4.88509594436\n",
      "Iteration 200 - loss is 9.831752551 - parameters are 2.00529290416 8.00750549588 4.88560981491\n",
      "Iteration 300 - loss is 7.73154943625 - parameters are 2.00303531109 8.0073507746 4.88544087101\n",
      "Iteration 400 - loss is 9.46270351306 - parameters are 2.00691218794 8.01344130054 4.88595865981\n",
      "Iteration 500 - loss is 8.89461488422 - parameters are 1.99838962725 8.00248993521 4.88492797083\n",
      "Iteration 600 - loss is 8.02844572324 - parameters are 2.0099267212 8.01232735897 4.88642544004\n",
      "Iteration 700 - loss is 9.17080481757 - parameters are 2.0083584366 8.01046671866 4.88618824473\n",
      "Iteration 800 - loss is 7.18019207336 - parameters are 2.00953951321 8.01573125321 4.88672757429\n",
      "Iteration 900 - loss is 8.50400409736 - parameters are 2.00768673426 8.01138718944 4.8863483471\n",
      "Iteration 1000 - loss is 11.1540636167 - parameters are 2.01312067879 8.0162649049 4.88743147185\n",
      "Epoch 257\n",
      "Iteration 100 - loss is 8.78097751813 - parameters are 2.00239551016 8.00690552986 4.88634941079\n",
      "Iteration 200 - loss is 9.82780620465 - parameters are 2.00520930201 8.007417176 4.88685944582\n",
      "Iteration 300 - loss is 7.73164791308 - parameters are 2.002958808 8.00726915324 4.88668963415\n",
      "Iteration 400 - loss is 9.46418644577 - parameters are 2.00683101302 8.01335780219 4.88720512617\n",
      "Iteration 500 - loss is 8.89140948556 - parameters are 1.99831000062 8.00240786891 4.88617306137\n",
      "Iteration 600 - loss is 8.02707432555 - parameters are 2.00984191961 8.01224152805 4.88766776053\n",
      "Iteration 700 - loss is 9.1708358118 - parameters are 2.00827383891 8.01038091481 4.88742877741\n",
      "Iteration 800 - loss is 7.17903081364 - parameters are 2.00945469782 8.01564409796 4.88796590877\n",
      "Iteration 900 - loss is 8.50335505692 - parameters are 2.00760711841 8.0113037761 4.88758530167\n",
      "Iteration 1000 - loss is 11.1490730052 - parameters are 2.01303556275 8.01617467673 4.88866563985\n",
      "Epoch 258\n",
      "Iteration 100 - loss is 8.77677279388 - parameters are 2.00232336162 8.00682852035 4.88758309693\n",
      "Iteration 200 - loss is 9.82395391124 - parameters are 2.00512702215 8.00733024897 4.88808935705\n",
      "Iteration 300 - loss is 7.73176706245 - parameters are 2.00288351573 8.0071888199 4.88791869147\n",
      "Iteration 400 - loss is 9.46566885739 - parameters are 2.00675112211 8.01327562086 4.888431923\n",
      "Iteration 500 - loss is 8.88827400206 - parameters are 1.99823163393 8.00232709776 4.88739850426\n",
      "Iteration 600 - loss is 8.02575079633 - parameters are 2.00975845917 8.01215705096 4.88889047714\n",
      "Iteration 700 - loss is 9.17088823081 - parameters are 2.00819057966 8.01029646505 4.88864973463\n",
      "Iteration 800 - loss is 7.1779131457 - parameters are 2.00937122407 8.0155583178 4.88918470258\n",
      "Iteration 900 - loss is 8.50274048534 - parameters are 2.00752876214 8.01122167903 4.88880273745\n",
      "Iteration 1000 - loss is 11.1441847947 - parameters are 2.01295179296 8.01608587192 4.88988033317\n",
      "Epoch 259\n",
      "Iteration 100 - loss is 8.77266294791 - parameters are 2.00225235494 8.0067527263 4.88879731611\n",
      "Iteration 200 - loss is 9.82019318641 - parameters are 2.00504604352 8.00724469277 4.88929986097\n",
      "Iteration 300 - loss is 7.73190586121 - parameters are 2.002809415 8.00710975417 4.88912835512\n",
      "Iteration 400 - loss is 9.46715004002 - parameters are 2.0066724948 8.01319473568 4.88963936188\n",
      "Iteration 500 - loss is 8.885206721 - parameters are 1.99815450711 8.00224760124 4.88860461071\n",
      "Iteration 600 - loss is 8.0244735563 - parameters are 2.00967631853 8.01207390627 4.89009390042\n",
      "Iteration 700 - loss is 9.17096104909 - parameters are 2.00810863753 8.01021334792 4.88985142646\n",
      "Iteration 800 - loss is 7.17683758787 - parameters are 2.00928907062 8.01547389095 4.89038426523\n",
      "Iteration 900 - loss is 8.50215907808 - parameters are 2.0074516454 8.01114087738 4.8900009636\n",
      "Iteration 1000 - loss is 11.1393966227 - parameters are 2.01286934799 8.01599846794 4.89107586024\n",
      "Epoch 260\n",
      "Iteration 100 - loss is 8.76864558457 - parameters are 2.00218247193 8.00667812846 4.88999237666\n",
      "Iteration 200 - loss is 9.81652161654 - parameters are 2.00496634544 8.0071604857 4.89049126497\n",
      "Iteration 300 - loss is 7.73206332431 - parameters are 2.00273648682 8.00703193598 4.89031893225\n",
      "Iteration 400 - loss is 9.46862931947 - parameters are 2.00659511098 8.01311512616 4.89082774939\n",
      "Iteration 500 - loss is 8.88220597594 - parameters are 1.99807860042 8.00216935918 4.88979168697\n",
      "Iteration 600 - loss is 8.02324107712 - parameters are 2.00959547671 8.0119920729 4.8912783359\n",
      "Iteration 700 - loss is 9.17105327901 - parameters are 2.00802799156 8.01013154232 4.89103415799\n",
      "Iteration 800 - loss is 7.17580270695 - parameters are 2.00920821645 8.01539079598 4.89156490127\n",
      "Iteration 900 - loss is 8.50160957519 - parameters are 2.00737574846 8.01106135062 4.89118028435\n",
      "Iteration 1000 - loss is 11.1347061875 - parameters are 2.01278820678 8.0159124426 4.89225252461\n",
      "Epoch 261\n",
      "Iteration 100 - loss is 8.76471837437 - parameters are 2.0021136947 8.00660470787 4.89116858198\n",
      "Iteration 200 - loss is 9.81293685667 - parameters are 2.00488790753 8.00707760643 4.8916638715\n",
      "Iteration 300 - loss is 7.73223850352 - parameters are 2.00266471252 8.00695534558 4.89149072512\n",
      "Iteration 400 - loss is 9.47010605404 - parameters are 2.00651895085 8.01303677211 4.89199738723\n",
      "Iteration 500 - loss is 8.87927014538 - parameters are 1.99800389445 8.00209235169 4.8909600344\n",
      "Iteration 600 - loss is 8.02205187966 - parameters are 2.00951591306 8.0119115301 4.89244408428\n",
      "Iteration 700 - loss is 9.17116396946 - parameters are 2.00794862113 8.01005102747 4.89219822949\n",
      "Iteration 800 - loss is 7.17480711655 - parameters are 2.00912864091 8.0153090118 4.89272691043\n",
      "Iteration 900 - loss is 8.50109075979 - parameters are 2.00730105191 8.01098307859 4.89234099907\n",
      "Iteration 1000 - loss is 11.1301112469 - parameters are 2.01270834858 8.01582777411 4.89341062495\n",
      "Epoch 262\n",
      "Iteration 100 - loss is 8.76087905204 - parameters are 2.00204600563 8.00653244589 4.89232623064\n",
      "Iteration 200 - loss is 9.80943662844 - parameters are 2.00481070975 8.00699603396 4.89281797822\n",
      "Iteration 300 - loss is 7.73243048613 - parameters are 2.00259407373 8.00687996351 4.89264403117\n",
      "Iteration 400 - loss is 9.47157963324 - parameters are 2.00644399497 8.01295965367 4.89314857229\n",
      "Iteration 500 - loss is 8.87639765144 - parameters are 1.99793037008 8.00201655922 4.89210994954\n",
      "Iteration 600 - loss is 8.02090453256 - parameters are 2.00943760724 8.01183225746 4.89359144145\n",
      "Iteration 700 - loss is 9.17129220468 - parameters are 2.00787050594 8.00997178294 4.8933439364\n",
      "Iteration 800 - loss is 7.17384947565 - parameters are 2.00905032364 8.01522851768 4.89387058762\n",
      "Iteration 900 - loss is 8.50060145671 - parameters are 2.00722753666 8.01090604139 4.89348340236\n",
      "Iteration 1000 - loss is 11.125609616 - parameters are 2.01262975299 8.01574444097 4.89455045521\n",
      "Epoch 263\n",
      "Iteration 100 - loss is 8.75712541466 - parameters are 2.0019793874 8.00646132416 4.89346561644\n",
      "Iteration 200 - loss is 9.80601871808 - parameters are 2.00473473239 8.00691574762 4.89395387805\n",
      "Iteration 300 - loss is 7.73263839378 - parameters are 2.00252455236 8.00680577066 4.89377914309\n",
      "Iteration 400 - loss is 9.47304947671 - parameters are 2.00637022418 8.01288375129 4.89428159673\n",
      "Iteration 500 - loss is 8.87358695865 - parameters are 1.99785800852 8.00194196254 4.89324172423\n",
      "Iteration 600 - loss is 8.01979765057 - parameters are 2.00936053926 8.01175423488 4.89472069858\n",
      "Iteration 700 - loss is 9.17143710304 - parameters are 2.00779362601 8.00989378861 4.89447156947\n",
      "Iteration 800 - loss is 7.17292848712 - parameters are 2.00897324464 8.01514929319 4.89499622308\n",
      "Iteration 900 - loss is 8.5001405311 - parameters are 2.0071551839 8.0108302195 4.8946077841\n",
      "Iteration 1000 - loss is 11.1211991657 - parameters are 2.01255239993 8.01566242207 4.89567230461\n",
      "Epoch 264\n",
      "Iteration 100 - loss is 8.75345531979 - parameters are 2.00191382297 8.00639132462 4.89458702852\n",
      "Iteration 200 - loss is 9.80268097452 - parameters are 2.00465995605 8.00683672707 4.8950718592\n",
      "Iteration 300 - loss is 7.73286138127 - parameters are 2.00245613064 8.00673274819 4.89489634891\n",
      "Iteration 400 - loss is 9.47451503307 - parameters are 2.00629761963 8.01280904574 4.89539674803\n",
      "Iteration 500 - loss is 8.87083657266 - parameters are 1.99778679125 8.0018685427 4.89435564564\n",
      "Iteration 600 - loss is 8.01872989318 - parameters are 2.00928468946 8.01167744258 4.8958321422\n",
      "Iteration 700 - loss is 9.17159781582 - parameters are 2.00771796171 8.00981702468 4.89558141481\n",
      "Iteration 800 - loss is 7.17204289631 - parameters are 2.00889738422 8.01507131824 4.8961041024\n",
      "Iteration 900 - loss is 8.49970688709 - parameters are 2.00708397516 8.01075559366 4.89571442957\n",
      "Iteration 1000 - loss is 11.1168778215 - parameters are 2.01247626966 8.01558169661 4.89677645779\n",
      "Epoch 265\n",
      "Iteration 100 - loss is 8.74986668376 - parameters are 2.00184929556 8.0063224295 4.89569075138\n",
      "Iteration 200 - loss is 9.79942130749 - parameters are 2.00458636163 8.0067589523 4.89617220532\n",
      "Iteration 300 - loss is 7.73309863543 - parameters are 2.00238879107 8.00666087757 4.89599593206\n",
      "Iteration 400 - loss is 9.47597577879 - parameters are 2.00622616279 8.01273551809 4.89649430912\n",
      "Iteration 500 - loss is 8.8681450391 - parameters are 1.99771670009 8.00179628109 4.89545199636\n",
      "Iteration 600 - loss is 8.01769996314 - parameters are 2.00921003846 8.01160186111 4.89692605427\n",
      "Iteration 700 - loss is 9.17177352619 - parameters are 2.0076434937 8.00974147169 4.89667375397\n",
      "Iteration 800 - loss is 7.17119148967 - parameters are 2.008822723 8.01499457305 4.89719450663\n",
      "Iteration 900 - loss is 8.4992994665 - parameters are 2.00701389223 8.01068214494 4.89680361951\n",
      "Iteration 1000 - loss is 11.1126435615 - parameters are 2.01240134273 8.01550224413 4.89786319484\n",
      "Epoch 266\n",
      "Iteration 100 - loss is 8.7463574799 - parameters are 2.00178578867 8.00625462131 4.896777065\n",
      "Iteration 200 - loss is 9.79623768573 - parameters are 2.00451393036 8.00668240361 4.89725519553\n",
      "Iteration 300 - loss is 7.73334937401 - parameters are 2.00232251642 8.00659014059 4.89707817147\n",
      "Iteration 400 - loss is 9.47743121723 - parameters are 2.00615583541 8.01266314971 4.8975745584\n",
      "Iteration 500 - loss is 8.86551094242 - parameters are 1.99764771712 8.00172515936 4.89653105448\n",
      "Iteration 600 - loss is 8.01670660507 - parameters are 2.00913656722 8.01152747132 4.89800271227\n",
      "Iteration 700 - loss is 9.17196344804 - parameters are 2.00757020296 8.00966711045 4.89774886401\n",
      "Iteration 800 - loss is 7.17037309343 - parameters are 2.00874924193 8.01491903818 4.89826771234\n",
      "Iteration 900 - loss is 8.49891724766 - parameters are 2.00694491722 8.01060985472 4.89787563017\n",
      "Iteration 1000 - loss is 11.1084944152 - parameters are 2.01232760002 8.0154240445 4.89893279139\n",
      "Epoch 267\n",
      "Iteration 100 - loss is 8.74292573691 - parameters are 2.00172328606 8.00618788285 4.89784624489\n",
      "Iteration 200 - loss is 9.79312813522 - parameters are 2.00444264375 8.00660706162 4.89832110451\n",
      "Iteration 300 - loss is 7.73361284463 - parameters are 2.00225728976 8.00652051928 4.8981433416\n",
      "Iteration 400 - loss is 9.47888087755 - parameters are 2.00608661955 8.01259192227 4.89863776982\n",
      "Iteration 500 - loss is 8.86293290477 - parameters are 1.99757982472 8.00165515948 4.89759309366\n",
      "Iteration 600 - loss is 8.01574860416 - parameters are 2.009064257 8.01145425437 4.89906238923\n",
      "Iteration 700 - loss is 9.17216682496 - parameters are 2.00749807077 8.00959392211 4.89880701759\n",
      "Iteration 800 - loss is 7.16958657236 - parameters are 2.00867692225 8.01484469447 4.89932399169\n",
      "Iteration 900 - loss is 8.49855924413 - parameters are 2.00687703253 8.01053870466 4.89893073341\n",
      "Iteration 1000 - loss is 11.1044284622 - parameters are 2.01225502272 8.01534707789 4.89998551868\n",
      "Epoch 268\n",
      "Iteration 100 - loss is 8.73956953724 - parameters are 2.00166177177 8.00612219718 4.8988985622\n",
      "Iteration 200 - loss is 9.79009073748 - parameters are 2.00437248362 8.00653290725 4.89937020253\n",
      "Iteration 300 - loss is 7.73388832379 - parameters are 2.00219309443 8.00645199601 4.89919171257\n",
      "Iteration 400 - loss is 9.48032431379 - parameters are 2.00601849755 8.01252181774 4.89968421301\n",
      "Iteration 500 - loss is 8.86040958492 - parameters are 1.99751300556 8.00158626368 4.8986383832\n",
      "Iteration 600 - loss is 8.01482478485 - parameters are 2.00899308937 8.0113821917 4.90010535387\n",
      "Iteration 700 - loss is 9.17238292923 - parameters are 2.00742707873 8.00952188811 4.899848483\n",
      "Iteration 800 - loss is 7.16883082845 - parameters are 2.00860574551 8.01477152307 4.90036361251\n",
      "Iteration 900 - loss is 8.49822450357 - parameters are 2.00681022081 8.01046867673 4.89996919675\n",
      "Iteration 1000 - loss is 11.1004438304 - parameters are 2.01218359231 8.01527132481 4.90102164363\n",
      "Epoch 269\n",
      "Iteration 100 - loss is 8.7362870155 - parameters are 2.00160123007 8.00605754763 4.89993428372\n",
      "Iteration 200 - loss is 9.78712362795 - parameters are 2.00430343208 8.00645992174 4.90040275561\n",
      "Iteration 300 - loss is 7.73417511579 - parameters are 2.00212991401 8.0063845534 4.90022355016\n",
      "Iteration 400 - loss is 9.48176110387 - parameters are 2.00595145202 8.01245281835 4.90071415327\n",
      "Iteration 500 - loss is 8.85793967721 - parameters are 1.99744724257 8.00151845449 4.89966718812\n",
      "Iteration 600 - loss is 8.01393400955 - parameters are 2.00892304616 8.01131126508 4.9011318706\n",
      "Iteration 700 - loss is 9.17261106081 - parameters are 2.0073572087 8.00945099018 4.90087352429\n",
      "Iteration 800 - loss is 7.16810479978 - parameters are 2.00853569354 8.01469950545 4.90138683836\n",
      "Iteration 900 - loss is 8.49791210664 - parameters are 2.00674446502 8.01039975316 4.90099128346\n",
      "Iteration 1000 - loss is 11.096538695 - parameters are 2.01211329058 8.01519676607 4.9020414289\n",
      "Epoch 270\n",
      "Iteration 100 - loss is 8.73307635698 - parameters are 2.0015416455 8.00599391781 4.90095367202\n",
      "Iteration 200 - loss is 9.78422499436 - parameters are 2.00423547152 8.00638808661 4.90141902548\n",
      "Iteration 300 - loss is 7.73447255186 - parameters are 2.00206773238 8.00631817435 4.90123911596\n",
      "Iteration 400 - loss is 9.48319084875 - parameters are 2.00588546588 8.01238490664 4.90172785168\n",
      "Iteration 500 - loss is 8.85552191054 - parameters are 1.99738251897 8.00145171473 4.90067976921\n",
      "Iteration 600 - loss is 8.01307517748 - parameters are 2.00885410953 8.01124145654 4.90214219964\n",
      "Iteration 700 - loss is 9.17285054645 - parameters are 2.00728844288 8.00938121034 4.90188240128\n",
      "Iteration 800 - loss is 7.16740745933 - parameters are 2.00846674848 8.01462862336 4.90239392861\n",
      "Iteration 900 - loss is 8.49762116588 - parameters are 2.00667974838 8.01033191648 4.90199725261\n",
      "Iteration 1000 - loss is 11.0927112772 - parameters are 2.0120440996 8.01512338278 4.90304513298\n",
      "Epoch 271\n",
      "Iteration 100 - loss is 8.72993579616 - parameters are 2.00148300284 8.00593129157 4.90195698548\n",
      "Iteration 200 - loss is 9.78139307517 - parameters are 2.00416858462 8.00631738368 4.90241926975\n",
      "Iteration 300 - loss is 7.73477998919 - parameters are 2.00200653366 8.00625284203 4.90223866736\n",
      "Iteration 400 - loss is 9.48461317149 - parameters are 2.00582052229 8.01231806542 4.90272556517\n",
      "Iteration 500 - loss is 8.85315504735 - parameters are 1.99731881826 8.00138602747 4.90167638311\n",
      "Iteration 600 - loss is 8.01224722345 - parameters are 2.00878626191 8.0111727484 4.90313659704\n",
      "Iteration 700 - loss is 9.17310073869 - parameters are 2.0072207637 8.00931253091 4.90287536967\n",
      "Iteration 800 - loss is 7.16673781385 - parameters are 2.00839889276 8.01455885884 4.90338513849\n",
      "Iteration 900 - loss is 8.49735082465 - parameters are 2.00661605439 8.01026514951 4.90298735915\n",
      "Iteration 1000 - loss is 11.0889598427 - parameters are 2.01197600174 8.01505115635 4.90403301025\n",
      "Epoch 272\n",
      "Iteration 100 - loss is 8.72686361527 - parameters are 2.00142528713 8.00586965304 4.90294447836\n",
      "Iteration 200 - loss is 9.77862615811 - parameters are 2.00410275434 8.00624779506 4.9034037419\n",
      "Iteration 300 - loss is 7.73509681003 - parameters are 2.00194630223 8.0061885399 4.90322245768\n",
      "Iteration 400 - loss is 9.48602771643 - parameters are 2.0057566047 8.01225227776 4.90370754659\n",
      "Iteration 500 - loss is 8.85083788273 - parameters are 1.99725612417 8.00132137605 4.90265728237\n",
      "Iteration 600 - loss is 8.01144911675 - parameters are 2.00871948602 8.01110512328 4.90411531481\n",
      "Iteration 700 - loss is 9.17336101504 - parameters are 2.00715415392 8.00924493449 4.90385268107\n",
      "Iteration 800 - loss is 7.16609490277 - parameters are 2.00833210908 8.01449019422 4.90436071919\n",
      "Iteration 900 - loss is 8.49710025615 - parameters are 2.0065533668 8.01019943532 4.90396185398\n",
      "Iteration 1000 - loss is 11.0852827006 - parameters are 2.01190897963 8.01498006851 4.90500531103\n",
      "Epoch 273\n",
      "Iteration 100 - loss is 8.72385814294 - parameters are 2.00136848362 8.00580898659 4.90391640091\n",
      "Iteration 200 - loss is 9.77592257872 - parameters are 2.0040379639 8.00617930315 4.90437269138\n",
      "Iteration 300 - loss is 7.73542242083 - parameters are 2.00188702271 8.00612525164 4.90419073618\n",
      "Iteration 400 - loss is 9.48743414836 - parameters are 2.00569369683 8.01218752702 4.90467404476\n",
      "Iteration 500 - loss is 8.84856924341 - parameters are 1.99719442072 8.00125774411 4.90362271554\n",
      "Iteration 600 - loss is 8.01067986004 - parameters are 2.00865376484 8.01103856406 4.90507860092\n",
      "Iteration 700 - loss is 9.17363077707 - parameters are 2.00708859655 8.00917840393 4.90481458312\n",
      "Iteration 800 - loss is 7.16547779718 - parameters are 2.0082663804 8.01442261211 4.90532091788\n",
      "Iteration 900 - loss is 8.49686866241 - parameters are 2.00649166963 8.01013475726 4.90492098399\n",
      "Iteration 1000 - loss is 11.0816782023 - parameters are 2.01184301621 8.01491010125 4.90596228166\n",
      "Epoch 274\n",
      "Iteration 100 - loss is 8.72091775283 - parameters are 2.00131257783 8.00574927684 4.90487299934\n",
      "Iteration 200 - loss is 9.77328071888 - parameters are 2.0039741968 8.00611189061 4.90532636369\n",
      "Iteration 300 - loss is 7.73575625144 - parameters are 2.00182867999 8.00606296124 4.90514374819\n",
      "Iteration 400 - loss is 9.48883215174 - parameters are 2.00563178265 8.0121237968 4.90562530452\n",
      "Iteration 500 - loss is 8.84634798694 - parameters are 1.99713369217 8.0011951155 4.9045729272\n",
      "Iteration 600 - loss is 8.00993848824 - parameters are 2.00858908163 8.01097305389 4.90602669942\n",
      "Iteration 700 - loss is 9.17390944964 - parameters are 2.00702407488 8.00911292238 4.90576131949\n",
      "Iteration 800 - loss is 7.16488559876 - parameters are 2.00820169 8.01435609539 4.9062659778\n",
      "Iteration 900 - loss is 8.49665527331 - parameters are 2.00643094716 8.01007109894 4.90586499216\n",
      "Iteration 1000 - loss is 11.0781447401 - parameters are 2.01177809467 8.01484123685 4.90690416456\n",
      "Epoch 275\n",
      "Iteration 100 - loss is 8.71804086234 - parameters are 2.0012575555 8.00569050866 4.90581451599\n",
      "Iteration 200 - loss is 9.77069900553 - parameters are 2.0039114368 8.00604554039 4.90626500039\n",
      "Iteration 300 - loss is 7.73609775421 - parameters are 2.00177125919 8.00600165292 4.9060817351\n",
      "Iteration 400 - loss is 9.49022142993 - parameters are 2.00557084638 8.01206107099 4.90656156685\n",
      "Iteration 500 - loss is 8.84417300074 - parameters are 1.99707392305 8.00113347437 4.90550815804\n",
      "Iteration 600 - loss is 8.00922406759 - parameters are 2.00852541994 8.01090857619 4.90695985046\n",
      "Iteration 700 - loss is 9.17419648001 - parameters are 2.00696057247 8.00904847326 4.90669312999\n",
      "Iteration 800 - loss is 7.16431743882 - parameters are 2.00813802138 8.01429062722 4.90719613835\n",
      "Iteration 900 - loss is 8.49645934571 - parameters are 2.00637118391 8.01000844425 4.90679411759\n",
      "Iteration 1000 - loss is 11.0746807463 - parameters are 2.01171419848 8.0147734579 4.9078311983\n",
      "Epoch 276\n",
      "Iteration 100 - loss is 8.71522593134 - parameters are 2.00120340259 8.00563266715 4.90674118933\n",
      "Iteration 200 - loss is 9.76817590927 - parameters are 2.00384966792 8.00598023571 4.90718883923\n",
      "Iteration 300 - loss is 7.7364464033 - parameters are 2.00171474565 8.00594131113 4.90700493449\n",
      "Iteration 400 - loss is 9.49160170444 - parameters are 2.00551087251 8.01199933371 4.90748306886\n",
      "Iteration 500 - loss is 8.84204320132 - parameters are 1.99701509812 8.00107280509 4.90642864492\n",
      "Iteration 600 - loss is 8.00853569456 - parameters are 2.00846276355 8.01084511466 4.90787829037\n",
      "Iteration 700 - loss is 9.17449133715 - parameters are 2.00689807314 8.00898504023 4.90761025061\n",
      "Iteration 800 - loss is 7.16377247736 - parameters are 2.00807535834 8.01422619102 4.90811163507\n",
      "Iteration 900 - loss is 8.49628016254 - parameters are 2.00631236465 8.00994677731 4.90770859559\n",
      "Iteration 1000 - loss is 11.0712846922 - parameters are 2.01165131137 8.01470674723 4.90874361765\n",
      "Epoch 277\n",
      "Iteration 100 - loss is 8.71247146098 - parameters are 2.00115010529 8.00557573765 4.90765325403\n",
      "Iteration 200 - loss is 9.7657099431 - parameters are 2.00378887445 8.00591596006 4.90809811417\n",
      "Iteration 300 - loss is 7.73680169387 - parameters are 2.00165912498 8.00588192061 4.90791358015\n",
      "Iteration 400 - loss is 9.49297271425 - parameters are 2.00545184577 8.01193856935 4.90839004394\n",
      "Iteration 500 - loss is 8.83995753339 - parameters are 1.9969572024 8.00101309231 4.90733462095\n",
      "Iteration 600 - loss is 8.00787249492 - parameters are 2.00840109651 8.01078265323 4.90878225173\n",
      "Iteration 700 - loss is 9.17479351095 - parameters are 2.00683656097 8.00892260724 4.90851291358\n",
      "Iteration 800 - loss is 7.1632499021 - parameters are 2.00801368492 8.01416277049 4.90901269981\n",
      "Iteration 900 - loss is 8.49611703189 - parameters are 2.00625447442 8.00988608251 4.90860865772\n",
      "Iteration 1000 - loss is 11.0679550866 - parameters are 2.01158941733 8.01464108796 4.90964165365\n",
      "Epoch 278\n",
      "Iteration 100 - loss is 8.70977599245 - parameters are 2.00109765002 8.00551970575 4.90855094104\n",
      "Iteration 200 - loss is 9.76329966121 - parameters are 2.0037290409 8.00585269719 4.90899305544\n",
      "Iteration 300 - loss is 7.73716314135 - parameters are 2.001604383 8.00582346632 4.90880790215\n",
      "Iteration 400 - loss is 9.49433421509 - parameters are 2.00539375113 8.01187876254 4.90928272171\n",
      "Iteration 500 - loss is 8.83791496914 - parameters are 1.99690022114 8.00095432089 4.90822631551\n",
      "Iteration 600 - loss is 8.00723362281 - parameters are 2.00834040315 8.0107211761 4.90967196343\n",
      "Iteration 700 - loss is 9.17510251148 - parameters are 2.00677602029 8.00886115846 4.90940134746\n",
      "Iteration 800 - loss is 7.16274892762 - parameters are 2.00795298541 8.01410034958 4.9098995607\n",
      "Iteration 900 - loss is 8.49596928625 - parameters are 2.00619749845 8.00982634448 4.90949453187\n",
      "Iteration 1000 - loss is 11.0646904752 - parameters are 2.0115285006 8.01457646348 4.91052553367\n",
      "Epoch 279\n",
      "Iteration 100 - loss is 8.70713810586 - parameters are 2.00104602341 8.00546455724 4.90943447764\n",
      "Iteration 200 - loss is 9.76094365771 - parameters are 2.00367015206 8.00579043109 4.90987388962\n",
      "Iteration 300 - loss is 7.73753028075 - parameters are 2.00155050575 8.00576593345 4.9096881269\n",
      "Iteration 400 - loss is 9.49568597878 - parameters are 2.00533657381 8.01181989814 4.91016132819\n",
      "Iteration 500 - loss is 8.83591450738 - parameters are 1.99684413983 8.00089647595 4.90910395436\n",
      "Iteration 600 - loss is 8.00661825981 - parameters are 2.008280668 8.01066066774 4.91054765071\n",
      "Iteration 700 - loss is 9.17541786831 - parameters are 2.0067164357 8.00880067835 4.91027577716\n",
      "Iteration 800 - loss is 7.1622687945 - parameters are 2.00789324438 8.01403891248 4.91077244225\n",
      "Iteration 900 - loss is 8.49583628165 - parameters are 2.00614142225 8.0097675481 4.9103664423\n",
      "Iteration 1000 - loss is 11.0614894394 - parameters are 2.0114685457 8.01451285743 4.91139548145\n",
      "Epoch 280\n",
      "Iteration 100 - loss is 8.70455641914 - parameters are 2.0009952123 8.00541027817 4.91030408749\n",
      "Iteration 200 - loss is 9.7586405655 - parameters are 2.00361219294 8.00572914604 4.91074083969\n",
      "Iteration 300 - loss is 7.73790266596 - parameters are 2.00149747952 8.00570930744 4.91055447724\n",
      "Iteration 400 - loss is 9.49702779263 - parameters are 2.00528029926 8.01176196128 4.91102608578\n",
      "Iteration 500 - loss is 8.83395517288 - parameters are 1.99678894418 8.00083954285 4.90996775965\n",
      "Iteration 600 - loss is 8.0060256141 - parameters are 2.0082218759 8.01060111283 4.91140953522\n",
      "Iteration 700 - loss is 9.17573912983 - parameters are 2.00665779201 8.00874115158 4.91113642402\n",
      "Iteration 800 - loss is 7.16180876844 - parameters are 2.00783444661 8.01397844365 4.91163156542\n",
      "Iteration 900 - loss is 8.49571739687 - parameters are 2.00608623155 8.00970967847 4.9112246097\n",
      "Iteration 1000 - loss is 11.0583505954 - parameters are 2.01140953737 8.01445025374 4.9122517172\n",
      "Epoch 281\n",
      "Iteration 100 - loss is 8.70202958691 - parameters are 2.00094520376 8.00535685478 4.9111599907\n",
      "Iteration 200 - loss is 9.75638905511 - parameters are 2.00355514881 8.00566882653 4.91159412508\n",
      "Iteration 300 - loss is 7.7382798691 - parameters are 2.0014452908 8.00565357396 4.91140717243\n",
      "Iteration 400 - loss is 9.49835945876 - parameters are 2.00522491316 8.0117049373 4.91187721336\n",
      "Iteration 500 - loss is 8.83203601556 - parameters are 1.99673462015 8.00078350718 4.91081795001\n",
      "Iteration 600 - loss is 8.00545491956 - parameters are 2.00816401187 8.01054249632 4.91225783512\n",
      "Iteration 700 - loss is 9.17606586259 - parameters are 2.00660007432 8.0086825631 4.91198350585\n",
      "Iteration 800 - loss is 7.16136813947 - parameters are 2.00777657716 8.01391892779 4.91247714762\n",
      "Iteration 900 - loss is 8.49561203274 - parameters are 2.0060319123 8.00965272096 4.91206925127\n",
      "Iteration 1000 - loss is 11.0552725934 - parameters are 2.01135146059 8.01438863657 4.91309445762\n",
      "Epoch 282\n",
      "Iteration 100 - loss is 8.69955629947 - parameters are 2.00089598505 8.00530427355 4.91200240387\n",
      "Iteration 200 - loss is 9.75418783362 - parameters are 2.00349900516 8.00560945732 4.91243396174\n",
      "Iteration 300 - loss is 7.73866147988 - parameters are 2.0013939263 8.0055987189 4.91224642827\n",
      "Iteration 400 - loss is 9.49968079356 - parameters are 2.00517040144 8.0116488118 4.91271492631\n",
      "Iteration 500 - loss is 8.83015610983 - parameters are 1.99668115391 8.00072835475 4.9116547406\n",
      "Iteration 600 - loss is 8.00490543497 - parameters are 2.00810706122 8.01048480338 4.91309276507\n",
      "Iteration 700 - loss is 9.17639765065 - parameters are 2.00654326793 8.00862489807 4.91281723704\n",
      "Iteration 800 - loss is 7.16094622119 - parameters are 2.0077196213 8.01386034985 4.91330940286\n",
      "Iteration 900 - loss is 8.49551961133 - parameters are 2.00597845068 8.00959666116 4.91290058074\n",
      "Iteration 1000 - loss is 11.0522541161 - parameters are 2.01129430061 8.01432799033 4.91392391596\n",
      "Epoch 283\n",
      "Iteration 100 - loss is 8.69713528179 - parameters are 2.00084754362 8.00525252116 4.91283154019\n",
      "Iteration 200 - loss is 9.7520356436 - parameters are 2.00344374771 8.0055510234 4.91326056219\n",
      "Iteration 300 - loss is 7.73904710495 - parameters are 2.00134337294 8.00554472839 4.91307245713\n",
      "Iteration 400 - loss is 9.50099162708 - parameters are 2.00511675022 8.01159357057 4.91353943661\n",
      "Iteration 500 - loss is 8.82831455389 - parameters are 1.99662853186 8.0006740716 4.91247834315\n",
      "Iteration 600 - loss is 8.00437644323 - parameters are 2.00805100947 8.01042801943 4.91391453634\n",
      "Iteration 700 - loss is 9.17673409499 - parameters are 2.0064873584 8.0085681419 4.91363782852\n",
      "Iteration 800 - loss is 7.16054234996 - parameters are 2.00766356454 8.013802695 4.9141285417\n",
      "Iteration 900 - loss is 8.49543957531 - parameters are 2.00592583309 8.00954148487 4.91371880847\n",
      "Iteration 1000 - loss is 11.0492938788 - parameters are 2.01123804289 8.01426829968 4.9147403021\n",
      "Epoch 284\n",
      "Iteration 100 - loss is 8.69476529246 - parameters are 2.00079986717 8.00520158452 4.91364760943\n",
      "Iteration 200 - loss is 9.74993126202 - parameters are 2.00338936243 8.00549351002 4.91407413556\n",
      "Iteration 300 - loss is 7.73943636735 - parameters are 2.00129361785 8.00549158876 4.91388546799\n",
      "Iteration 400 - loss is 9.50229180247 - parameters are 2.00506394587 8.01153919965 4.91435095288\n",
      "Iteration 500 - loss is 8.82651046908 - parameters are 1.99657674061 8.000620644 4.91328896604\n",
      "Iteration 600 - loss is 8.00386725055 - parameters are 2.00799584236 8.01037213012 4.91472335685\n",
      "Iteration 700 - loss is 9.17707481291 - parameters are 2.0064323315 8.00851228023 4.91444548791\n",
      "Iteration 800 - loss is 7.16015588421 - parameters are 2.00760839264 8.01374594867 4.91493477138\n",
      "Iteration 900 - loss is 8.49537138722 - parameters are 2.00587404615 8.00948717814 4.91452414144\n",
      "Iteration 1000 - loss is 11.0463906275 - parameters are 2.01118267312 8.01420954955 4.91554382256\n",
      "Epoch 285\n",
      "Iteration 100 - loss is 8.69244512279 - parameters are 2.00075294354 8.00515145074 4.91445081804\n",
      "Iteration 200 - loss is 9.74787349931 - parameters are 2.00333583548 8.00543690264 4.91487488767\n",
      "Iteration 300 - loss is 7.73982890589 - parameters are 2.00124464838 8.00543928657 4.91468566654\n",
      "Iteration 400 - loss is 9.5035811755 - parameters are 2.00501197497 8.01148568531 4.91514968041\n",
      "Iteration 500 - loss is 8.8247429992 - parameters are 1.99652576698 8.00056805842 4.91408681433\n",
      "Iteration 600 - loss is 8.00337718574 - parameters are 2.00794154589 8.01031712131 4.91551943119\n",
      "Iteration 700 - loss is 9.17741943746 - parameters are 2.00637817324 8.00845729893 4.91524041952\n",
      "Iteration 800 - loss is 7.15978620368 - parameters are 2.00755409157 8.01369009651 4.91572829586\n",
      "Iteration 900 - loss is 8.49531452884 - parameters are 2.00582307669 8.00943372723 4.91531678339\n",
      "Iteration 1000 - loss is 11.0435431387 - parameters are 2.01112817725 8.01415172506 4.9163346806\n",
      "Epoch 286\n",
      "Iteration 100 - loss is 8.69017359588 - parameters are 2.0007067608 8.00510210711 4.91524136921\n",
      "Iteration 200 - loss is 9.74586119835 - parameters are 2.00328315328 8.00538118695 4.91566302109\n",
      "Iteration 300 - loss is 7.74022437463 - parameters are 2.00119645207 8.00538780859 4.91547325518\n",
      "Iteration 400 - loss is 9.50485961396 - parameters are 2.00496082431 8.01143301402 4.91593582123\n",
      "Iteration 500 - loss is 8.82301130991 - parameters are 1.99647559803 8.00051630157 4.91487208983\n",
      "Iteration 600 - loss is 8.00290559947 - parameters are 2.00788810627 8.01026297912 4.91630296073\n",
      "Iteration 700 - loss is 9.17776761686 - parameters are 2.00632486985 8.00840318407 4.91602282442\n",
      "Iteration 800 - loss is 7.15943270878 - parameters are 2.00750064754 8.01363512439 4.91650931583\n",
      "Iteration 900 - loss is 8.4952685005 - parameters are 2.00577291176 8.00938111861 4.9160969348\n",
      "Iteration 1000 - loss is 11.0407502187 - parameters are 2.01107454141 8.01409481161 4.91711307626\n",
      "Epoch 287\n",
      "Iteration 100 - loss is 8.68794956567 - parameters are 2.0006613072 8.00505354117 4.91601946288\n",
      "Iteration 200 - loss is 9.74389323354 - parameters are 2.00323130243 8.00532634888 4.91643873514\n",
      "Iteration 300 - loss is 7.74062244229 - parameters are 2.00114901665 8.00533714179 4.9162484331\n",
      "Iteration 400 - loss is 9.50612699723 - parameters are 2.00491048089 8.01138117247 4.91670957417\n",
      "Iteration 500 - loss is 8.82131458812 - parameters are 1.99642622098 8.00046536034 4.91564499116\n",
      "Iteration 600 - loss is 8.00245186357 - parameters are 2.00783550991 8.01020968984 4.91707414363\n",
      "Iteration 700 - loss is 9.17811901399 - parameters are 2.00627240779 8.00834992199 4.91679290048\n",
      "Iteration 800 - loss is 7.15909481986 - parameters are 2.00744804696 8.01358101841 4.91727802883\n",
      "Iteration 900 - loss is 8.49523282051 - parameters are 2.0057235386 8.00932933899 4.91686479296\n",
      "Iteration 1000 - loss is 11.038010702 - parameters are 2.01102175199 8.0140387948 4.91787920638\n",
      "Epoch 288\n",
      "Iteration 100 - loss is 8.68577191611 - parameters are 2.00061657118 8.00500574062 4.91678529583\n",
      "Iteration 200 - loss is 9.74196850989 - parameters are 2.00318026977 8.00527237459 4.917202226\n",
      "Iteration 300 - loss is 7.74102279178 - parameters are 2.00110233007 8.00528727338 4.91701139635\n",
      "Iteration 400 - loss is 9.50738321578 - parameters are 2.00486093192 8.01133014757 4.9174711349\n",
      "Iteration 500 - loss is 8.8196520414 - parameters are 1.9963776233 8.00041522186 4.91640571376\n",
      "Iteration 600 - loss is 8.00201537034 - parameters are 2.00778374346 8.01015724003 4.91783317491\n",
      "Iteration 700 - loss is 9.17847330589 - parameters are 2.00622077371 8.0082974992 4.91755084243\n",
      "Iteration 800 - loss is 7.15877197665 - parameters are 2.00739627646 8.0135277649 4.91803462924\n",
      "Iteration 900 - loss is 8.49520702454 - parameters are 2.00567494467 8.00927837527 4.91762055204\n",
      "Iteration 1000 - loss is 11.0353234516 - parameters are 2.01096979558 8.01398366049 4.91863326471\n",
      "Epoch 289\n",
      "Iteration 100 - loss is 8.6836395603 - parameters are 2.00057254137 8.00495869336 4.91753906172\n",
      "Iteration 200 - loss is 9.74008596211 - parameters are 2.00313004235 8.00521925043 4.91795368673\n",
      "Iteration 300 - loss is 7.74142511965 - parameters are 2.00105638045 8.00523819073 4.91776233783\n",
      "Iteration 400 - loss is 9.50862817067 - parameters are 2.00481216482 8.01127992641 4.91822069599\n",
      "Iteration 500 - loss is 8.81802289739 - parameters are 1.99632979262 8.00036587345 4.91715444999\n",
      "Iteration 600 - loss is 8.00159553193 - parameters are 2.00773279378 8.01010561643 4.9185802465\n",
      "Iteration 700 - loss is 9.17883018319 - parameters are 2.00616995452 8.00824590245 4.91829684193\n",
      "Iteration 800 - loss is 7.15846363754 - parameters are 2.0073453229 8.0134753504 4.91877930837\n",
      "Iteration 900 - loss is 8.49519066502 - parameters are 2.00562711762 8.00922821456 4.91836440314\n",
      "Iteration 1000 - loss is 11.0326873574 - parameters are 2.01091865899 8.01392939474 4.91937544189\n",
      "Epoch 290\n",
      "Iteration 100 - loss is 8.68155143965 - parameters are 2.00052920656 8.00491238751 4.91828095111\n",
      "Iteration 200 - loss is 9.73824455375 - parameters are 2.00308060739 8.00516696299 4.91869330732\n",
      "Iteration 300 - loss is 7.74182913565 - parameters are 2.00101115611 8.00518988143 4.91850144743\n",
      "Iteration 400 - loss is 9.50986177317 - parameters are 2.00476416721 8.01123049632 4.91895844696\n",
      "Iteration 500 - loss is 8.81642640327 - parameters are 1.99628271681 8.00031730262 4.91789138914\n",
      "Iteration 600 - loss is 8.00119177966 - parameters are 2.00768264794 8.010054806 4.91931554726\n",
      "Iteration 700 - loss is 9.17918934971 - parameters are 2.00611993728 8.00819511869 4.91903108756\n",
      "Iteration 800 - loss is 7.15816927903 - parameters are 2.00729517335 8.01342376165 4.91951225448\n",
      "Iteration 900 - loss is 8.49518331061 - parameters are 2.0055800453 8.00917884419 4.91909653431\n",
      "Iteration 1000 - loss is 11.030101336 - parameters are 2.01086832922 8.01387598384 4.92010592556\n",
      "Epoch 291\n",
      "Iteration 100 - loss is 8.6795065231 - parameters are 2.00048655575 8.00486681134 4.91901115157\n",
      "Iteration 200 - loss is 9.73644327641 - parameters are 2.00303195237 8.00511549907 4.91942127475\n",
      "Iteration 300 - loss is 7.7422345622 - parameters are 2.00096664556 8.00514233328 4.91922891197\n",
      "Iteration 400 - loss is 9.51108394426 - parameters are 2.00471692689 8.01118184481 4.9196845743\n",
      "Iteration 500 - loss is 8.81486182519 - parameters are 1.99623638388 8.0002694971 4.91861671752\n",
      "Iteration 600 - loss is 8.00080356344 - parameters are 2.0076332932 8.0100047959 4.92003926309\n",
      "Iteration 700 - loss is 9.17955052194 - parameters are 2.0060707093 8.00814513509 4.91975376496\n",
      "Iteration 800 - loss is 7.15788839515 - parameters are 2.00724581506 8.01337298562 4.92023365285\n",
      "Iteration 900 - loss is 8.49518454563 - parameters are 2.00553371576 8.00913025166 4.91981713063\n",
      "Iteration 1000 - loss is 11.0275643296 - parameters are 2.01081879351 8.01382341428 4.92082490037\n",
      "Epoch 292\n",
      "Iteration 100 - loss is 8.67750380634 - parameters are 2.0004445781 8.00482195332 4.91972984768\n",
      "Iteration 200 - loss is 9.73468114887 - parameters are 2.00298406493 8.00506484567 4.92013777305\n",
      "Iteration 300 - loss is 7.74264113399 - parameters are 2.00092283749 8.00509553425 4.91994491536\n",
      "Iteration 400 - loss is 9.51229461426 - parameters are 2.00467043189 8.01113395959 4.92039926157\n",
      "Iteration 500 - loss is 8.81332844777 - parameters are 1.99619078209 8.00022244479 4.91933061847\n",
      "Iteration 600 - loss is 8.00043035115 - parameters are 2.00758471705 8.0099555735 4.92075157692\n",
      "Iteration 700 - loss is 9.17991342859 - parameters are 2.00602225809 8.008095939 4.92046505677\n",
      "Iteration 800 - loss is 7.15762049684 - parameters are 2.0071972355 8.01332300949 4.92094368583\n",
      "Iteration 900 - loss is 8.49519396955 - parameters are 2.00548811723 8.0090824247 4.92052637423\n",
      "Iteration 1000 - loss is 11.0250753057 - parameters are 2.01077003928 8.01377167281 4.92153254805\n",
      "Epoch 293\n",
      "Iteration 100 - loss is 8.67554231104 - parameters are 2.00040326293 8.00477780213 4.92043722109\n",
      "Iteration 200 - loss is 9.73295721635 - parameters are 2.00293693291 8.00501499001 4.92084298329\n",
      "Iteration 300 - loss is 7.74304859749 - parameters are 2.00087972077 8.00504947252 4.92064963855\n",
      "Iteration 400 - loss is 9.51349372242 - parameters are 2.00462467038 8.01108682857 4.92110268939\n",
      "Iteration 500 - loss is 8.8118255736 - parameters are 1.99614589985 8.00017613381 4.92003327241\n",
      "Iteration 600 - loss is 8.00007162808 - parameters are 2.00753690715 8.00990712637 4.92145266877\n",
      "Iteration 700 - loss is 9.18027781018 - parameters are 2.00597457132 8.008047518 4.92116514278\n",
      "Iteration 800 - loss is 7.15736511145 - parameters are 2.00714942235 8.01327382061 4.92164253287\n",
      "Iteration 900 - loss is 8.49521119645 - parameters are 2.00544323814 8.00903535122 4.92122444436\n",
      "Iteration 1000 - loss is 11.0226332563 - parameters are 2.01072205416 8.01372074633 4.92222904744\n",
      "Epoch 294\n",
      "Iteration 100 - loss is 8.67362108416 - parameters are 2.00036259976 8.00473434659 4.92113345058\n",
      "Iteration 200 - loss is 9.73127054972 - parameters are 2.00289054437 8.00496591949 4.92153708372\n",
      "Iteration 300 - loss is 7.74345671057 - parameters are 2.00083728444 8.00500413644 4.92134325965\n",
      "Iteration 400 - loss is 9.51468121651 - parameters are 2.00457963078 8.01104043984 4.92179503555\n",
      "Iteration 500 - loss is 8.81035252271 - parameters are 1.99610172576 8.00013055244 4.92072485693\n",
      "Iteration 600 - loss is 7.99972689636 - parameters are 2.00748985138 8.00985944228 4.92214271583\n",
      "Iteration 700 - loss is 9.18064341858 - parameters are 2.00592763691 8.00799985983 4.9218541999\n",
      "Iteration 800 - loss is 7.15712178221 - parameters are 2.00710236347 8.01322540657 4.92233037057\n",
      "Iteration 900 - loss is 8.4952358546 - parameters are 2.00539906709 8.00898901933 4.92191151743\n",
      "Iteration 1000 - loss is 11.0202371969 - parameters are 2.01067482598 8.01367062199 4.92291457455\n",
      "Epoch 295\n",
      "Iteration 100 - loss is 8.6717391972 - parameters are 2.00032257825 8.00469157572 4.92181871208\n",
      "Iteration 200 - loss is 9.72962024478 - parameters are 2.00284488752 8.00491762174 4.92222024973\n",
      "Iteration 300 - loss is 7.74386524205 - parameters are 2.00079551773 8.00495951456 4.92202595394\n",
      "Iteration 400 - loss is 9.51585705249 - parameters are 2.00453530164 8.0109947817 4.92247647498\n",
      "Iteration 500 - loss is 8.80890863212 - parameters are 1.99605824861 8.00008568918 4.92140554677\n",
      "Iteration 600 - loss is 7.99939567443 - parameters are 2.00744353781 8.00981250918 4.92282189246\n",
      "Iteration 700 - loss is 9.18101001665 - parameters are 2.00588144294 8.00795295247 4.92253240225\n",
      "Iteration 800 - loss is 7.15689006766 - parameters are 2.00705604693 8.01317775513 4.92300737274\n",
      "Iteration 900 - loss is 8.49526758588 - parameters are 2.00535559288 8.00894341731 4.92258776705\n",
      "Iteration 1000 - loss is 11.0178861666 - parameters are 2.01062834275 8.01362128714 4.9235893026\n",
      "Epoch 296\n",
      "Iteration 100 - loss is 8.66989574553 - parameters are 2.00028318824 8.0046494787 4.92249317874\n",
      "Iteration 200 - loss is 9.72800542151 - parameters are 2.0027999508 8.00487008455 4.92289265393\n",
      "Iteration 300 - loss is 7.74427397133 - parameters are 2.00075441003 8.0049155956 4.9226978939\n",
      "Iteration 400 - loss is 9.5170211941 - parameters are 2.00449167172 8.01094984262 4.92314717988\n",
      "Iteration 500 - loss is 8.80749325536 - parameters are 1.99601545736 8.00004153267 4.92207551394\n",
      "Iteration 600 - loss is 7.99907749651 - parameters are 2.00739795468 8.00976631523 4.92349037026\n",
      "Iteration 700 - loss is 9.18137737779 - parameters are 2.00583597769 8.00790678405 4.92319992118\n",
      "Iteration 800 - loss is 7.15666954122 - parameters are 2.00701046096 8.01313085426 4.92367371042\n",
      "Iteration 900 - loss is 8.49530604541 - parameters are 2.00531280447 8.00889853364 4.92325336407\n",
      "Iteration 1000 - loss is 11.0155792269 - parameters are 2.01058259268 8.0135727293 4.92425340205\n",
      "Epoch 297\n",
      "Iteration 100 - loss is 8.66808984772 - parameters are 2.00024441973 8.0046080449 4.92315702097\n",
      "Iteration 200 - loss is 9.72642522344 - parameters are 2.0027557228 8.00482329593 4.92355446621\n",
      "Iteration 300 - loss is 7.74468268799 - parameters are 2.0007139509 8.00487236847 4.92335924929\n",
      "Iteration 400 - loss is 9.51817361255 - parameters are 2.00444872995 8.01090561125 4.92380731968\n",
      "Iteration 500 - loss is 8.80610576203 - parameters are 1.99597334116 7.99999807177 4.92273492767\n",
      "Iteration 600 - loss is 7.99877191209 - parameters are 2.00735309045 8.00972084877 4.92414831813\n",
      "Iteration 700 - loss is 9.18174528561 - parameters are 2.00579122962 8.00786134291 4.92385692532\n",
      "Iteration 800 - loss is 7.15645979065 - parameters are 2.00696559401 8.01308469211 4.92432955195\n",
      "Iteration 900 - loss is 8.49535090105 - parameters are 2.00527069101 8.00885435699 4.92390847664\n",
      "Iteration 1000 - loss is 11.0133154611 - parameters are 2.01053756417 8.01352493623 4.92490704069\n",
      "Epoch 298\n",
      "Iteration 100 - loss is 8.6663206449 - parameters are 2.00020626287 8.00456726385 4.92381040646\n",
      "Iteration 200 - loss is 9.72487881692 - parameters are 2.00271219232 8.00477724408 4.92420585376\n",
      "Iteration 300 - loss is 7.74509119143 - parameters are 2.00067413009 8.00482982225 4.9240101872\n",
      "Iteration 400 - loss is 9.51931428618 - parameters are 2.00440646545 8.01086207643 4.92445706116\n",
      "Iteration 500 - loss is 8.80474553737 - parameters are 1.99593188932 7.99995529549 4.92338395456\n",
      "Iteration 600 - loss is 7.99847848546 - parameters are 2.00730893373 8.00967609831 4.92479590225\n",
      "Iteration 700 - loss is 9.18211353351 - parameters are 2.00574718738 8.00781661758 4.92450358065\n",
      "Iteration 800 - loss is 7.15626041763 - parameters are 2.0069214347 8.01303925703 4.92497506301\n",
      "Iteration 900 - loss is 8.495401833 - parameters are 2.00522924181 8.0088108762 4.92455327026\n",
      "Iteration 1000 - loss is 11.0110939743 - parameters are 2.01049324581 8.01347789585 4.92555038361\n",
      "Epoch 299\n",
      "Iteration 100 - loss is 8.66458730013 - parameters are 2.000168708 8.00452712523 4.92445350026\n",
      "Iteration 200 - loss is 9.72336539046 - parameters are 2.00266934832 8.00473191737 4.92484698111\n",
      "Iteration 300 - loss is 7.74549929048 - parameters are 2.00063493747 8.00478794618 4.92465087204\n",
      "Iteration 400 - loss is 9.52044320011 - parameters are 2.0043648675 8.01081922716 4.92509656843\n",
      "Iteration 500 - loss is 8.8034119818 - parameters are 1.99589109132 7.99991319302 4.92402275854\n",
      "Iteration 600 - loss is 7.99819679519 - parameters are 2.00726547334 8.00963205256 4.92543328621\n",
      "Iteration 700 - loss is 9.18248192437 - parameters are 2.0057038398 8.00777259674 4.9251400505\n",
      "Iteration 800 - loss is 7.15607103728 - parameters are 2.00687797184 8.01299453754 4.92561040664\n",
      "Iteration 900 - loss is 8.49545853335 - parameters are 2.00518844636 8.00876808027 4.92518790777\n",
      "Iteration 1000 - loss is 11.0089138921 - parameters are 2.01044962635 8.01343159628 4.92618359331\n",
      "Epoch 300\n",
      "Iteration 100 - loss is 8.66288899778 - parameters are 2.00013174556 8.00448761891 4.9250864648\n",
      "Iteration 200 - loss is 9.72188415415 - parameters are 2.00262717993 8.00468730436 4.9254780102\n",
      "Iteration 300 - loss is 7.7459068031 - parameters are 2.00059636311 8.0047467297 4.92528146563\n",
      "Iteration 400 - loss is 9.52156034597 - parameters are 2.00432392555 8.01077705264 4.92572600301\n",
      "Iteration 500 - loss is 8.80210451053 - parameters are 1.99585093681 7.99987175373 4.92465150096\n",
      "Iteration 600 - loss is 7.99792643374 - parameters are 2.00722269825 8.0095887004 4.92606063099\n",
      "Iteration 700 - loss is 9.1828502702 - parameters are 2.00566117588 8.00772926928 4.92576649561\n",
      "Iteration 800 - loss is 7.15589127771 - parameters are 2.0068351944 8.01295052235 4.9262357433\n",
      "Iteration 900 - loss is 8.49552070571 - parameters are 2.00514829431 8.00872595841 4.92581254947\n",
      "Iteration 1000 - loss is 11.0067743607 - parameters are 2.01040669475 8.01338602585 4.92680682971\n",
      "Epoch 301\n",
      "Iteration 100 - loss is 8.66122494294 - parameters are 2.00009536619 8.00444873491 4.92570945994\n",
      "Iteration 200 - loss is 9.720434339 - parameters are 2.00258567647 8.0046433938 4.92609910039\n",
      "Iteration 300 - loss is 7.74631355602 - parameters are 2.00055839722 8.0047061624 4.92590212723\n",
      "Iteration 400 - loss is 9.52266572159 - parameters are 2.00428362923 8.01073554222 4.92634552385\n",
      "Iteration 500 - loss is 8.80082255317 - parameters are 1.99581141562 7.99983096716 4.92527034058\n",
      "Iteration 600 - loss is 7.99766700694 - parameters are 2.00718059764 8.0095460309 4.92667809501\n",
      "Iteration 700 - loss is 9.18321839175 - parameters are 2.00561918481 8.00768662427 4.92638307419\n",
      "Iteration 800 - loss is 7.15572077965 - parameters are 2.00679309154 8.01290720034 4.92685123091\n",
      "Iteration 900 - loss is 8.49558806479 - parameters are 2.0051087755 8.00868449998 4.92642735309\n",
      "Iteration 1000 - loss is 11.004674546 - parameters are 2.01036444012 8.01334117304 4.92742025021\n",
      "Epoch 302\n",
      "Iteration 100 - loss is 8.65959436086 - parameters are 2.00005956065 8.0044104634 4.926322643\n",
      "Iteration 200 - loss is 9.71901519635 - parameters are 2.00254482742 8.00460017461 4.92671040852\n",
      "Iteration 300 - loss is 7.74671938441 - parameters are 2.00052103017 8.00466623402 4.92651301356\n",
      "Iteration 400 - loss is 9.52375933069 - parameters are 2.00424396832 8.01069468543 4.92695528742\n",
      "Iteration 500 - loss is 8.79956555333 - parameters are 1.99577251771 7.99979082299 4.92587943369\n",
      "Iteration 600 - loss is 7.99741813362 - parameters are 2.00713916083 8.00950403328 4.9272858342\n",
      "Iteration 700 - loss is 9.18358611829 - parameters are 2.00557785595 8.00764465092 4.92698994193\n",
      "Iteration 800 - loss is 7.15555919597 - parameters are 2.00675165258 8.01286456058 4.92745702488\n",
      "Iteration 900 - loss is 8.49566033606 - parameters are 2.00506987989 8.0086436945 4.92703247388\n",
      "Iteration 1000 - loss is 11.0026136332 - parameters are 2.01032285175 8.01329702654 4.92802400968\n",
      "Epoch 303\n",
      "Iteration 100 - loss is 8.65799649638 - parameters are 2.00002431986 8.00437279472 4.92692616881\n",
      "Iteration 200 - loss is 9.71762599732 - parameters are 2.00250462244 8.00455763589 4.92731208895\n",
      "Iteration 300 - loss is 7.74712413157 - parameters are 2.00048425248 8.00462693449 4.92711427887\n",
      "Iteration 400 - loss is 9.52484118263 - parameters are 2.00420493278 8.01065447195 4.92755544766\n",
      "Iteration 500 - loss is 8.79833296821 - parameters are 1.99573423324 7.9997513111 4.92647893407\n",
      "Iteration 600 - loss is 7.99717944514 - parameters are 2.00709837732 8.00946269695 4.92788400201\n",
      "Iteration 700 - loss is 9.18395328718 - parameters are 2.00553717882 8.00760333864 4.92758725205\n",
      "Iteration 800 - loss is 7.15540619135 - parameters are 2.00671086704 8.01282259231 4.92805327817\n",
      "Iteration 900 - loss is 8.49573725534 - parameters are 2.00503159763 8.00860353168 4.92762806462\n",
      "Iteration 1000 - loss is 11.0005908261 - parameters are 2.01028191911 8.0132535752 4.92861826056\n",
      "Epoch 304\n",
      "Iteration 100 - loss is 8.6564306134 - parameters are 1.9999896349 8.00433571935 4.92752018975\n",
      "Iteration 200 - loss is 9.71626603219 - parameters are 2.00246505134 8.00451576691 4.9279042936\n",
      "Iteration 300 - loss is 7.74752764865 - parameters are 2.00044805482 8.00458825388 4.92770607497\n",
      "Iteration 400 - loss is 9.52591129211 - parameters are 2.0041665127 8.01061489165 4.9281461561\n",
      "Iteration 500 - loss is 8.79712426829 - parameters are 1.99569655249 7.99971242151 4.92706899309\n",
      "Iteration 600 - loss is 7.99695058503 - parameters are 2.00705823679 8.00942201148 4.92847274945\n",
      "Iteration 700 - loss is 9.18431974369 - parameters are 2.0054971431 8.00756267701 4.92817515537\n",
      "Iteration 800 - loss is 7.15526144185 - parameters are 2.00667072457 8.01278128493 4.92864014132\n",
      "Iteration 900 - loss is 8.49581856846 - parameters are 2.00499391901 8.00856400136 4.92821427567\n",
      "Iteration 1000 - loss is 10.998605347 - parameters are 2.01024163183 8.01321080806 4.9292031529\n",
      "Epoch 305\n",
      "Iteration 100 - loss is 8.65489599432 - parameters are 1.99995549695 8.00429922793 4.92810485578\n",
      "Iteration 200 - loss is 9.71493460991 - parameters are 2.00242610409 8.0044745571 4.92848717196\n",
      "Iteration 300 - loss is 7.74792979433 - parameters are 2.00041242803 8.00455018244 4.92828855126\n",
      "Iteration 400 - loss is 9.52696967895 - parameters are 2.00412869837 8.01057593453 4.92872756188\n",
      "Iteration 500 - loss is 8.79593893694 - parameters are 1.99565946592 7.99967414439 4.9276497597\n",
      "Iteration 600 - loss is 7.99673120859 - parameters are 2.00701872907 8.0093819666 4.92905222515\n",
      "Iteration 700 - loss is 9.1846853406 - parameters are 2.00545773866 8.00752265574 4.92875380028\n",
      "Iteration 800 - loss is 7.15512463455 - parameters are 2.006631215 8.01274062802 4.92921776247\n",
      "Iteration 900 - loss is 8.49590403095 - parameters are 2.0049568345 8.00852509359 4.92879125503\n",
      "Iteration 1000 - loss is 10.996656436 - parameters are 2.01020197969 8.01316871433 4.92977883432\n",
      "Epoch 306\n",
      "Iteration 100 - loss is 8.65339193959 - parameters are 1.99992189737 8.00426331125 4.9286803145\n",
      "Iteration 200 - loss is 9.71363105756 - parameters are 2.00238777084 8.00443399608 4.92906087118\n",
      "Iteration 300 - loss is 7.74833043455 - parameters are 2.00037736306 8.00451271054 4.92886185478\n",
      "Iteration 400 - loss is 9.52801636783 - parameters are 2.0040914802 8.01053759077 4.92929981175\n",
      "Iteration 500 - loss is 8.79477647006 - parameters are 1.99562296412 7.99963647009 4.9282213805\n",
      "Iteration 600 - loss is 7.99652098248 - parameters are 2.00697984416 8.00934255222 4.9296225754\n",
      "Iteration 700 - loss is 9.18504993802 - parameters are 2.00541895551 8.00748326474 4.92932333286\n",
      "Iteration 800 - loss is 7.1549954672 - parameters are 2.00659232833 8.01270061132 4.92978628743\n",
      "Iteration 900 - loss is 8.49599340768 - parameters are 2.00492033469 8.00848679852 4.92935914832\n",
      "Iteration 1000 - loss is 10.9947433507 - parameters are 2.01016295267 8.01312728339 4.93034545015\n",
      "Epoch 307\n",
      "Iteration 100 - loss is 8.65191776716 - parameters are 1.99988882763 8.00422796023 4.92924671116\n",
      "Iteration 200 - loss is 9.71235471982 - parameters are 2.00235004187 8.00439407361 4.92962553606\n",
      "Iteration 300 - loss is 7.74872944224 - parameters are 2.00034285103 8.00447582873 4.92942613023\n",
      "Iteration 400 - loss is 9.52905138803 - parameters are 2.00405484876 8.01049985069 4.92986305015\n",
      "Iteration 500 - loss is 8.79363637579 - parameters are 1.99558703786 7.99959938909 4.92878399978\n",
      "Iteration 600 - loss is 7.9963195844 - parameters are 2.0069415722 8.00930375838 4.93018394414\n",
      "Iteration 700 - loss is 9.18541340304 - parameters are 2.00538078382 8.00744449407 4.92988389686\n",
      "Iteration 800 - loss is 7.15487364786 - parameters are 2.00655405471 8.01266122473 4.9303458597\n",
      "Iteration 900 - loss is 8.49608647252 - parameters are 2.00488441034 8.00844910651 4.92991809889\n",
      "Iteration 1000 - loss is 10.9928653652 - parameters are 2.01012454088 8.01308650478 4.9309031434\n",
      "Epoch 308\n",
      "Iteration 100 - loss is 8.65047281203 - parameters are 1.99985627937 8.00419316594 4.92980418872\n",
      "Iteration 200 - loss is 9.71110495847 - parameters are 2.00231290763 8.00435477963 4.93018130913\n",
      "Iteration 300 - loss is 7.74912669705 - parameters are 2.00030888319 8.00443952771 4.92998152002\n",
      "Iteration 400 - loss is 9.53007477324 - parameters are 2.00401879478 8.01046270478 4.93041741924\n",
      "Iteration 500 - loss is 8.79251817413 - parameters are 1.99555167801 7.99956289203 4.92933775953\n",
      "Iteration 600 - loss is 7.9961267027 - parameters are 2.00690390352 8.00926557531 4.93073647306\n",
      "Iteration 700 - loss is 9.18577560949 - parameters are 2.00534321393 8.00740633394 4.93043563374\n",
      "Iteration 800 - loss is 7.15475889457 - parameters are 2.00651638445 8.0126224583 4.93089662049\n",
      "Iteration 900 - loss is 8.49618300808 - parameters are 2.00484905235 8.00841200802 4.93046824781\n",
      "Iteration 1000 - loss is 10.9910217707 - parameters are 2.01008673458 8.01304636821 4.93145205481\n",
      "Epoch 309\n",
      "Iteration 100 - loss is 8.64905642576 - parameters are 1.99982424432 8.00415891962 4.93035288786\n",
      "Iteration 200 - loss is 9.70988115194 - parameters are 2.00227635873 8.00431610422 4.93072833064\n",
      "Iteration 300 - loss is 7.7495220851 - parameters are 2.00027545094 8.0044037983 4.93052816433\n",
      "Iteration 400 - loss is 9.53108656127 - parameters are 2.00398330914 8.01042614367 4.93096305893\n",
      "Iteration 500 - loss is 8.79142139667 - parameters are 1.99551687564 7.9995269697 4.9298827995\n",
      "Iteration 600 - loss is 7.99594203605 - parameters are 2.00686682857 8.00922799337 4.9312803016\n",
      "Iteration 700 - loss is 9.18613643774 - parameters are 2.00530623632 8.00736877472 4.93097868275\n",
      "Iteration 800 - loss is 7.15465093502 - parameters are 2.006479308 8.01258430227 4.9314387088\n",
      "Iteration 900 - loss is 8.49628280538 - parameters are 2.00481425176 8.00837549371 4.93100973389\n",
      "Iteration 1000 - loss is 10.9892118739 - parameters are 2.01004952422 8.01300686357 4.9319923229\n",
      "Epoch 310\n",
      "Iteration 100 - loss is 8.64766797606 - parameters are 1.99979271438 8.0041252126 4.93089294705\n",
      "Iteration 200 - loss is 9.70868269479 - parameters are 2.00224038591 8.00427803764 4.93126673863\n",
      "Iteration 300 - loss is 7.74991549872 - parameters are 2.0002425458 8.0043686315 4.93106620109\n",
      "Iteration 400 - loss is 9.53208679394 - parameters are 2.00394838285 8.01039015814 4.9315001069\n",
      "Iteration 500 - loss is 8.79034558624 - parameters are 1.99548262193 7.99949161304 4.93041925723\n",
      "Iteration 600 - loss is 7.99576529311 - parameters are 2.00683033798 8.00919100309 4.93181556698\n",
      "Iteration 700 - loss is 9.18649577437 - parameters are 2.00526984163 8.00733180692 4.93151318092\n",
      "Iteration 800 - loss is 7.15454950625 - parameters are 2.00644281598 8.012546747 4.93197226141\n",
      "Iteration 900 - loss is 8.49638566357 - parameters are 2.00477999976 8.00833955436 4.93154269379\n",
      "Iteration 1000 - loss is 10.9874349976 - parameters are 2.01001290038 8.01296798089 4.93252408401\n",
      "Epoch 311\n",
      "Iteration 100 - loss is 8.6463068463 - parameters are 1.99976168155 8.00409203639 4.93142450256\n",
      "Iteration 200 - loss is 9.70750899731 - parameters are 2.00220498007 8.00424057029 4.93179666896\n",
      "Iteration 300 - loss is 7.75030683626 - parameters are 2.00021015945 8.00433401843 4.93159576607\n",
      "Iteration 400 - loss is 9.53307551678 - parameters are 2.00391400706 8.01035473911 4.93202869866\n",
      "Iteration 500 - loss is 8.78929029663 - parameters are 1.9954489082 7.99945681312 4.93094726807\n",
      "Iteration 600 - loss is 7.99559619219 - parameters are 2.0067944225 8.00915459513 4.93234240427\n",
      "Iteration 700 - loss is 9.18685351199 - parameters are 2.00523402064 8.00729542123 4.93203926312\n",
      "Iteration 800 - loss is 7.1544543543 - parameters are 2.00640689916 8.01250978302 4.93249741296\n",
      "Iteration 900 - loss is 8.49649138963 - parameters are 2.00474628769 8.00830418089 4.93206726197\n",
      "Iteration 1000 - loss is 10.9856904798 - parameters are 2.00997685377 8.01292971035 4.93304747229\n",
      "Epoch 312\n",
      "Iteration 100 - loss is 8.64497243511 - parameters are 1.99973113798 8.0040593826 4.93194768852\n",
      "Iteration 200 - loss is 9.70635948504 - parameters are 2.00217013224 8.00420369272 4.93231825534\n",
      "Iteration 300 - loss is 7.7506960018 - parameters are 2.00017828367 8.00429995036 4.93211699288\n",
      "Iteration 400 - loss is 9.53405277887 - parameters are 2.00388017308 8.01031987765 4.93254896759\n",
      "Iteration 500 - loss is 8.78825509233 - parameters are 1.99541572591 7.99942256115 4.93146696526\n",
      "Iteration 600 - loss is 7.99543446098 - parameters are 2.00675907306 8.00911876033 4.93286094639\n",
      "Iteration 700 - loss is 9.18720954902 - parameters are 2.00519876428 8.00725960845 4.93255706206\n",
      "Iteration 800 - loss is 7.15436523397 - parameters are 2.00637154845 8.012473401 4.93301429592\n",
      "Iteration 900 - loss is 8.49659979814 - parameters are 2.004713107 8.00826936439 4.93258357077\n",
      "Iteration 1000 - loss is 10.9839776731 - parameters are 2.00994137529 8.01289204232 4.9335626198\n",
      "Epoch 313\n",
      "Iteration 100 - loss is 8.64366415596 - parameters are 1.99970107592 8.004027243 4.93246263691\n",
      "Iteration 200 - loss is 9.70523359837 - parameters are 2.00213583362 8.00416739563 4.93283162935\n",
      "Iteration 300 - loss is 7.75108290496 - parameters are 2.0001469104 8.00426641869 4.93263001302\n",
      "Iteration 400 - loss is 9.53501863267 - parameters are 2.00384687235 8.01028556498 4.93306104493\n",
      "Iteration 500 - loss is 8.78723954817 - parameters are 1.99538306668 7.99938884851 4.93197847989\n",
      "Iteration 600 - loss is 7.9952798362 - parameters are 2.0067242807 8.00908348963 4.93337132416\n",
      "Iteration 700 - loss is 9.18756378942 - parameters are 2.00516406364 8.00722435956 4.93306670839\n",
      "Iteration 800 - loss is 7.1542819085 - parameters are 2.00633675489 8.01243759177 4.93352304071\n",
      "Iteration 900 - loss is 8.49671071097 - parameters are 2.0046804493 8.00823509608 4.93309175046\n",
      "Iteration 1000 - loss is 10.9822959449 - parameters are 2.00990645595 8.01285496728 4.9340696565\n",
      "Epoch 314\n",
      "Iteration 100 - loss is 8.64238143676 - parameters are 1.99967148777 8.00399560948 4.93296947765\n",
      "Iteration 200 - loss is 9.70413079209 - parameters are 2.00210207552 8.00413166989 4.93333692051\n",
      "Iteration 300 - loss is 7.75146746068 - parameters are 2.00011603169 8.00423341496 4.9331349559\n",
      "Iteration 400 - loss is 9.53597313379 - parameters are 2.00381409643 8.01025179244 4.93356505987\n",
      "Iteration 500 - loss is 8.78624324913 - parameters are 1.99535092222 7.99935566668 4.932481941\n",
      "Iteration 600 - loss is 7.99513206333 - parameters are 2.00669003663 8.00904877415 4.93387366632\n",
      "Iteration 700 - loss is 9.18791614252 - parameters are 2.00512990993 8.00718966566 4.93356833066\n",
      "Iteration 800 - loss is 7.15420414929 - parameters are 2.00630250968 8.0124023463 4.93402377565\n",
      "Iteration 900 - loss is 8.49682395708 - parameters are 2.00464830633 8.00820136729 4.93359192922\n",
      "Iteration 1000 - loss is 10.9806446768 - parameters are 2.00987208692 8.0128184759 4.93456871028\n",
      "Epoch 315\n",
      "Iteration 100 - loss is 8.64112371946 - parameters are 1.99964236604 8.00396447406 4.93346833858\n",
      "Iteration 200 - loss is 9.70305053501 - parameters are 2.00206884941 8.00409650647 4.93383425628\n",
      "Iteration 300 - loss is 7.75184958904 - parameters are 2.00008563973 8.00420093085 4.93363194889\n",
      "Iteration 400 - loss is 9.53691634088 - parameters are 2.00378183705 8.01021855152 4.93406113954\n",
      "Iteration 500 - loss is 8.78526579002 - parameters are 1.9953192844 7.99932300728 4.9329774756\n",
      "Iteration 600 - loss is 7.99499089633 - parameters are 2.00665633218 8.00901460514 4.93436809959\n",
      "Iteration 700 - loss is 9.1882665228 - parameters are 2.0050962945 8.007155518 4.9340620554\n",
      "Iteration 800 - loss is 7.15413173568 - parameters are 2.00626880417 8.0123676557 4.93451662705\n",
      "Iteration 900 - loss is 8.49693937221 - parameters are 2.00461666994 8.00816816954 4.93408423322\n",
      "Iteration 1000 - loss is 10.9790232639 - parameters are 2.0098382595 8.01278255896 4.93505990703\n",
      "Epoch 316\n",
      "Iteration 100 - loss is 8.6398904597 - parameters are 1.99961370335 8.00393382887 4.93395934553\n",
      "Iteration 200 - loss is 9.70199230959 - parameters are 2.00203614687 8.00406189653 4.93432376209\n",
      "Iteration 300 - loss is 7.752229215 - parameters are 2.00005572681 8.00416895817 4.93412111736\n",
      "Iteration 400 - loss is 9.53784831539 - parameters are 2.00375008603 8.01018583384 4.93454940907\n",
      "Iteration 500 - loss is 8.78430677523 - parameters are 1.99528814522 7.9992908621 4.93346520865\n",
      "Iteration 600 - loss is 7.99485609736 - parameters are 2.00662315884 8.00898097398 4.93485474867\n",
      "Iteration 700 - loss is 9.1886148497 - parameters are 2.00506320886 8.00712190797 4.93454800715\n",
      "Iteration 800 - loss is 7.1540644546 - parameters are 2.00623562981 8.01233351122 4.93500171922\n",
      "Iteration 900 - loss is 8.49705679871 - parameters are 2.00458553214 8.00813549444 4.93456878662\n",
      "Iteration 1000 - loss is 10.977431115 - parameters are 2.00980496515 8.01274720742 4.93554337064\n",
      "Epoch 317\n",
      "Iteration 100 - loss is 8.6386811264 - parameters are 1.99958549244 8.0039036662 4.93444262234\n",
      "Iteration 200 - loss is 9.70095561149 - parameters are 2.00200395964 8.00402783133 4.93480556141\n",
      "Iteration 300 - loss is 7.75260626828 - parameters are 2.00002628538 8.00413748884 4.93460258467\n",
      "Iteration 400 - loss is 9.53876912146 - parameters are 2.00371883535 8.01015363115 4.93502999161\n",
      "Iteration 500 - loss is 8.7833658185 - parameters are 1.9952574968 7.999259223 4.93394526319\n",
      "Iteration 600 - loss is 7.99472743652 - parameters are 2.00659050821 8.00894787219 4.93533373631\n",
      "Iteration 700 - loss is 9.18896104742 - parameters are 2.00503064462 8.00708882708 4.93502630846\n",
      "Iteration 800 - loss is 7.15400210041 - parameters are 2.00620297823 8.01229990425 4.93547917449\n",
      "Iteration 900 - loss is 8.49717608527 - parameters are 2.00455488505 8.00810333375 4.93504571162\n",
      "Iteration 1000 - loss is 10.975867652 - parameters are 2.00977219543 8.01271241236 4.93601922302\n",
      "Epoch 318\n",
      "Iteration 100 - loss is 8.63749520142 - parameters are 1.99955772618 8.00387397842 4.9349182909\n",
      "Iteration 200 - loss is 9.69993994929 - parameters are 2.00197227959 8.00399430229 4.93527977575\n",
      "Iteration 300 - loss is 7.75298068311 - parameters are 1.99999730798 8.00410651494 4.93507647225\n",
      "Iteration 400 - loss is 9.53967882572 - parameters are 2.0036880771 8.01012193533 4.93550300835\n",
      "Iteration 500 - loss is 8.78244254265 - parameters are 1.99522733138 7.99922808202 4.93441776026\n",
      "Iteration 600 - loss is 7.9946046916 - parameters are 2.00655837204 8.00891529144 4.93580518329\n",
      "Iteration 700 - loss is 9.18930504473 - parameters are 2.00499859356 8.007056267 4.93549707995\n",
      "Iteration 800 - loss is 7.15394447461 - parameters are 2.00617084117 8.01226682632 4.93594911328\n",
      "Iteration 900 - loss is 8.4972970867 - parameters are 2.00452472092 8.00807167937 4.93551512851\n",
      "Iteration 1000 - loss is 10.9743323094 - parameters are 2.00973994207 8.012678165 4.93648758419\n",
      "Epoch 319\n",
      "Iteration 100 - loss is 8.63633217921 - parameters are 1.99953039754 8.00384475805 4.93538647115\n",
      "Iteration 200 - loss is 9.69894484406 - parameters are 2.0019410987 8.00396130097 4.93574652469\n",
      "Iteration 300 - loss is 7.75335239811 - parameters are 1.99996878727 8.00407602866 4.9355428996\n",
      "Iteration 400 - loss is 9.54057749719 - parameters are 2.00365780351 8.0100907384 4.93596857858\n",
      "Iteration 500 - loss is 8.78153657936 - parameters are 1.99519764134 7.9991974313 4.93488281903\n",
      "Iteration 600 - loss is 7.9944876478 - parameters are 2.0065267422 8.00888322351 4.93626920851\n",
      "Iteration 700 - loss is 9.18964677481 - parameters are 2.00496704756 8.00702421951 4.93596044033\n",
      "Iteration 800 - loss is 7.1538913856 - parameters are 2.00613921049 8.01223426909 4.93641165409\n",
      "Iteration 900 - loss is 8.49741966374 - parameters are 2.00449503211 8.00804052331 4.93597715565\n",
      "Iteration 1000 - loss is 10.9728245345 - parameters are 2.00970819691 8.01264445673 4.93694857225\n",
      "Epoch 320\n",
      "Iteration 100 - loss is 8.6351915665 - parameters are 1.99950349961 8.00381599772 4.93584728116\n",
      "Iteration 200 - loss is 9.69796982906 - parameters are 2.00191040908 8.00392881904 4.93620592592\n",
      "Iteration 300 - loss is 7.75372135606 - parameters are 1.99994071604 8.00404602229 4.93600198433\n",
      "Iteration 400 - loss is 9.5414652071 - parameters are 2.00362800693 8.01006003249 4.93642681969\n",
      "Iteration 500 - loss is 8.78064756892 - parameters are 1.99516841916 7.99916726311 4.93534055675\n",
      "Iteration 600 - loss is 7.99437609752 - parameters are 2.00649561069 8.00885166031 4.93672592896\n",
      "Iteration 700 - loss is 9.18998617507 - parameters are 2.00493599865 8.00699267654 4.93641650644\n",
      "Iteration 800 - loss is 7.15384264849 - parameters are 2.0061080782 8.01220222434 4.93686691354\n",
      "Iteration 900 - loss is 8.49754368283 - parameters are 2.00446581112 8.00800985771 4.93643190953\n",
      "Iteration 1000 - loss is 10.9713437864 - parameters are 2.00967695191 8.01261127903 4.93740230342\n",
      "Epoch 321\n",
      "Iteration 100 - loss is 8.63407288193 - parameters are 1.99947702558 8.00378769018 4.93630083711\n",
      "Iteration 200 - loss is 9.69701444937 - parameters are 2.00188020298 8.00389684832 4.93665809529\n",
      "Iteration 300 - loss is 7.75408750378 - parameters are 1.99991308719 8.00401648829 4.9364538422\n",
      "Iteration 400 - loss is 9.54234202877 - parameters are 2.0035986798 8.01002980987 4.93687784722\n",
      "Iteration 500 - loss is 8.77977516003 - parameters are 1.99513965745 7.99913756984 4.93579108884\n",
      "Iteration 600 - loss is 7.99426984014 - parameters are 2.00646496965 8.0088205939 4.9371754598\n",
      "Iteration 700 - loss is 9.19032318696 - parameters are 2.00490543898 8.00696163012 4.93686539327\n",
      "Iteration 800 - loss is 7.15379808483 - parameters are 2.00607743643 8.01217068401 4.93731500642\n",
      "Iteration 900 - loss is 8.49766901592 - parameters are 2.00443705055 8.00797967485 4.93687950482\n",
      "Iteration 1000 - loss is 10.9698895362 - parameters are 2.00964619919 8.01257862355 4.93784889212\n",
      "Epoch 322\n",
      "Iteration 100 - loss is 8.63297565575 - parameters are 1.99945096875 8.00375982829 4.93674725335\n",
      "Iteration 200 - loss is 9.6960782616 - parameters are 2.00185047277 8.00386538077 4.93710314678\n",
      "Iteration 300 - loss is 7.75445079194 - parameters are 1.99988589373 8.0039874192 4.93689858713\n",
      "Iteration 400 - loss is 9.54320803744 - parameters are 2.00356981474 8.01000006292 4.93732177489\n",
      "Iteration 500 - loss is 8.77891900955 - parameters are 1.99511134895 7.99910834401 4.93623452889\n",
      "Iteration 600 - loss is 7.99416868173 - parameters are 2.00643481134 8.00879001644 4.93761791437\n",
      "Iteration 700 - loss is 9.19065775586 - parameters are 2.00487536082 8.00693107243 4.93730721399\n",
      "Iteration 800 - loss is 7.15375752243 - parameters are 2.00604727744 8.01213964014 4.93775604571\n",
      "Iteration 900 - loss is 8.49779554026 - parameters are 2.00440874315 8.00794996711 4.93732005436\n",
      "Iteration 1000 - loss is 10.9684612668 - parameters are 2.00961593097 8.01254648206 4.93828845092\n",
      "Epoch 323\n",
      "Iteration 100 - loss is 8.63189942951 - parameters are 1.99942532253 8.00373240501 4.93718664244\n",
      "Iteration 200 - loss is 9.69516083351 - parameters are 2.00182121093 8.00383440844 4.93754119262\n",
      "Iteration 300 - loss is 7.75481117491 - parameters are 1.99985912878 8.0039588077 4.93733633124\n",
      "Iteration 400 - loss is 9.54406331021 - parameters are 2.00354140443 8.00997078414 4.93775871461\n",
      "Iteration 500 - loss is 8.77807878234 - parameters are 1.99508348648 7.99907957824 4.93667098868\n",
      "Iteration 600 - loss is 7.99407243492 - parameters are 2.00640512813 8.00875992023 4.93805340422\n",
      "Iteration 700 - loss is 9.19098983087 - parameters are 2.00484575656 8.00690099576 4.93774207998\n",
      "Iteration 800 - loss is 7.15372079515 - parameters are 2.00601759359 8.01210908491 4.93819014258\n",
      "Iteration 900 - loss is 8.49792313825 - parameters are 2.00438088175 8.007920727 4.9377536692\n",
      "Iteration 1000 - loss is 10.967058472 - parameters are 2.0095861396 8.01251484645 4.93872109065\n",
      "Epoch 324\n",
      "Iteration 100 - loss is 8.63084375577 - parameters are 1.99940008043 8.00370541345 4.93761911513\n",
      "Iteration 200 - loss is 9.69426174378 - parameters are 2.00179241007 8.00380392354 4.93797234321\n",
      "Iteration 300 - loss is 7.75516861062 - parameters are 1.99983278558 8.00393064657 4.93776718488\n",
      "Iteration 400 - loss is 9.54490792584 - parameters are 2.0035134417 8.00994196616 4.93818877653\n",
      "Iteration 500 - loss is 8.77725415098 - parameters are 1.99505606302 7.99905126529 4.93710057825\n",
      "Iteration 600 - loss is 7.99398091862 - parameters are 2.00637591252 8.00873029769 4.93848203911\n",
      "Iteration 700 - loss is 9.19131936472 - parameters are 2.00481661872 8.00687139254 4.93817010087\n",
      "Iteration 800 - loss is 7.1536877427 - parameters are 2.00598837739 8.01207901061 4.93861740646\n",
      "Iteration 900 - loss is 8.49805169722 - parameters are 2.0043534593 8.00789194716 4.93818045867\n",
      "Iteration 1000 - loss is 10.9656806569 - parameters are 2.00955681755 8.01248370876 4.93914692035\n",
      "Epoch 325\n",
      "Iteration 100 - loss is 8.62980819778 - parameters are 1.99937523608 8.00367884678 4.93804478044\n",
      "Iteration 200 - loss is 9.69338058165 - parameters are 2.0017640629 8.00377391838 4.93839670725\n",
      "Iteration 300 - loss is 7.75552306042 - parameters are 1.99980685746 8.00390292871 4.93819125665\n",
      "Iteration 400 - loss is 9.5457419647 - parameters are 2.00348591948 8.00991360171 4.93861206905\n",
      "Iteration 500 - loss is 8.77644479564 - parameters are 1.99502907162 7.99902339801 4.93752340588\n",
      "Iteration 600 - loss is 7.99389395784 - parameters are 2.00634715713 8.00870114135 4.93890392709\n",
      "Iteration 700 - loss is 9.19164631354 - parameters are 2.00478793994 8.0068422553 4.93859138454\n",
      "Iteration 800 - loss is 7.15365821042 - parameters are 2.00595962145 8.01204940966 4.93903794505\n",
      "Iteration 900 - loss is 8.49818110928 - parameters are 2.00432646889 8.00786362032 4.93860053032\n",
      "Iteration 1000 - loss is 10.9643273373 - parameters are 2.00952795742 8.01245306114 4.93956604736\n",
      "Epoch 326\n",
      "Iteration 100 - loss is 8.62879232923 - parameters are 1.99935078319 8.00365269831 4.93846374567\n",
      "Iteration 200 - loss is 9.69251694667 - parameters are 2.00173616227 8.00374438542 4.93881439169\n",
      "Iteration 300 - loss is 7.7558744889 - parameters are 1.99978133787 8.00387564714 4.93860865346\n",
      "Iteration 400 - loss is 9.54656550861 - parameters are 2.00345883083 8.00988568366 4.93902869888\n",
      "Iteration 500 - loss is 8.77565040385 - parameters are 1.99500250546 7.99899596939 4.93793957814\n",
      "Iteration 600 - loss is 7.99381138349 - parameters are 2.00631885469 8.00867244387 4.93931917452\n",
      "Iteration 700 - loss is 9.19197063683 - parameters are 2.00475971297 8.00681357669 4.93900603718\n",
      "Iteration 800 - loss is 7.15363204915 - parameters are 2.00593131851 8.01202027462 4.93945186435\n",
      "Iteration 900 - loss is 8.49831127114 - parameters are 2.00429990367 8.00783573936 4.93901399004\n",
      "Iteration 1000 - loss is 10.9629980393 - parameters are 2.0094995519 8.01242289587 4.93997857733\n",
      "Epoch 327\n",
      "Iteration 100 - loss is 8.62779573395 - parameters are 1.99932671558 8.00362696146 4.93887611641\n",
      "Iteration 200 - loss is 9.69167044838 - parameters are 2.00170870113 8.0037153172 4.93922550182\n",
      "Iteration 300 - loss is 7.7562228638 - parameters are 1.99975622035 8.00384879497 4.93901948049\n",
      "Iteration 400 - loss is 9.54737864075 - parameters are 2.00343216888 8.00985820497 4.93943877101\n",
      "Iteration 500 - loss is 8.77487067032 - parameters are 1.99497635783 7.99896897251 4.93834919993\n",
      "Iteration 600 - loss is 7.99373303221 - parameters are 2.00629099806 8.00864419802 4.93972788603\n",
      "Iteration 700 - loss is 9.19229229724 - parameters are 2.00473193067 8.0067853495 4.93941416329\n",
      "Iteration 800 - loss is 7.15360911498 - parameters are 2.00590346142 8.01199159812 4.93985926868\n",
      "Iteration 900 - loss is 8.49844208393 - parameters are 2.00427375695 8.00780829723 4.93942094204\n",
      "Iteration 1000 - loss is 10.9616922994 - parameters are 2.00947159383 8.01239320534 4.94038461422\n",
      "Epoch 328\n",
      "Iteration 100 - loss is 8.62681800566 - parameters are 1.99930302716 8.00360162973 4.9392819966\n",
      "Iteration 200 - loss is 9.69084070606 - parameters are 2.00168167255 8.00368670641 4.93963014124\n",
      "Iteration 300 - loss is 7.75656815589 - parameters are 1.99973149855 8.00382236546 4.93942384129\n",
      "Iteration 400 - loss is 9.54818144556 - parameters are 2.00340592691 8.00983115871 4.93984238879\n",
      "Iteration 500 - loss is 8.77410529673 - parameters are 1.99495062212 7.99894240056 4.93875237447\n",
      "Iteration 600 - loss is 7.99365874615 - parameters are 2.00626358021 8.00861639668 4.94013016463\n",
      "Iteration 700 - loss is 9.19261126046 - parameters are 2.00470458603 8.00675756659 4.93981586573\n",
      "Iteration 800 - loss is 7.15358926913 - parameters are 2.00587604313 8.01196337296 4.94026026071\n",
      "Iteration 900 - loss is 8.4985734531 - parameters are 2.00424802212 8.00778128703 4.93982148887\n",
      "Iteration 1000 - loss is 10.960409664 - parameters are 2.00944407614 8.01236398207 4.94078426035\n",
      "Epoch 329\n",
      "Iteration 100 - loss is 8.62585874769 - parameters are 1.99927971195 8.00357669673 4.93968148851\n",
      "Iteration 200 - loss is 9.69002734848 - parameters are 2.00165506968 8.00365854585 4.94002841193\n",
      "Iteration 300 - loss is 7.75691033876 - parameters are 1.99970716624 8.00379635192 4.93982183776\n",
      "Iteration 400 - loss is 9.54897400861 - parameters are 2.00338009829 8.00980453807 4.94023965395\n",
      "Iteration 500 - loss is 8.77335399161 - parameters are 1.99492529183 7.99891624684 4.93914920339\n",
      "Iteration 600 - loss is 7.99358837279 - parameters are 2.00623659419 8.00858903284 4.94052611171\n",
      "Iteration 700 - loss is 9.19292749512 - parameters are 2.00467767214 8.00673022098 4.94021124574\n",
      "Iteration 800 - loss is 7.15357237775 - parameters are 2.00584905673 8.01193559201 4.94065494149\n",
      "Iteration 900 - loss is 8.49870528819 - parameters are 2.00422269267 8.00775470195 4.94021573148\n",
      "Iteration 1000 - loss is 10.9591496893 - parameters are 2.00941699188 8.01233521871 4.94117761645\n",
      "Epoch 330\n",
      "Iteration 100 - loss is 8.62491757275 - parameters are 1.99925676405 8.00355215618 4.94007469283\n",
      "Iteration 200 - loss is 9.6892300136 - parameters are 2.00162888583 8.00363082842 4.94042041425\n",
      "Iteration 300 - loss is 7.75724938881 - parameters are 1.99968321725 8.00377074781 4.94021357019\n",
      "Iteration 400 - loss is 9.54975641656 - parameters are 2.0033546765 8.00977833635 4.94063066658\n",
      "Iteration 500 - loss is 8.77261647011 - parameters are 1.99490036055 7.99889050477 4.93953978666\n",
      "Iteration 600 - loss is 7.99352176481 - parameters are 2.00621003321 8.00856209963 4.94091582704\n",
      "Iteration 700 - loss is 9.19324097265 - parameters are 2.00465118219 8.00670330576 4.94060040293\n",
      "Iteration 800 - loss is 7.15355831177 - parameters are 2.00582249539 8.01190824828 4.94104341048\n",
      "Iteration 900 - loss is 8.49883750273 - parameters are 2.00419776221 8.00772853529 4.94060376919\n",
      "Iteration 1000 - loss is 10.957911941 - parameters are 2.00939033422 8.01230690801 4.94156478163\n",
      "Epoch 331\n",
      "Iteration 100 - loss is 8.62399410267 - parameters are 1.99923417767 8.00352800191 4.94046170862\n",
      "Iteration 200 - loss is 9.68844834834 - parameters are 2.00160311437 8.00360354713 4.94080624697\n",
      "Iteration 300 - loss is 7.75758528506 - parameters are 1.99965964555 8.00374554668 4.9405991373\n",
      "Iteration 400 - loss is 9.55052875702 - parameters are 2.00332965511 8.00975254695 4.94101552522\n",
      "Iteration 500 - loss is 8.77189245384 - parameters are 1.994875822 7.99886516786 4.93992422271\n",
      "Iteration 600 - loss is 7.99345877986 - parameters are 2.00618389055 8.00853559024 4.94129940881\n",
      "Iteration 700 - loss is 9.19355166717 - parameters are 2.0046251095 8.00667681416 4.94098343537\n",
      "Iteration 800 - loss is 7.15354694672 - parameters are 2.00579635241 8.01188133488 4.94142576555\n",
      "Iteration 900 - loss is 8.4989700141 - parameters are 2.00417322444 8.00770278046 4.9409856998\n",
      "Iteration 1000 - loss is 10.956695994 - parameters are 2.00936409641 8.01227904283 4.94194585343\n",
      "Epoch 332\n",
      "Iteration 100 - loss is 8.62308796814 - parameters are 1.99921194709 8.00350422781 4.94084263341\n",
      "Iteration 200 - loss is 9.68768200835 - parameters are 2.00157774879 8.00357669513 4.94118600732\n",
      "Iteration 300 - loss is 7.75791800905 - parameters are 1.99963644516 8.00372074217 4.94097863622\n",
      "Iteration 400 - loss is 9.55129111847 - parameters are 2.00330502781 8.00972716337 4.94139432683\n",
      "Iteration 500 - loss is 8.77118167076 - parameters are 1.99485166996 7.99884022972 4.9403026084\n",
      "Iteration 600 - loss is 7.99339928048 - parameters are 2.00615815962 8.00850949801 4.94167695367\n",
      "Iteration 700 - loss is 9.19385955535 - parameters are 2.00459944748 8.00665073951 4.94136043958\n",
      "Iteration 800 - loss is 7.15353816261 - parameters are 2.00577062118 8.01185484503 4.94180210306\n",
      "Iteration 900 - loss is 8.49910274337 - parameters are 2.00414907315 8.00767743096 4.94136161952\n",
      "Iteration 1000 - loss is 10.9555014323 - parameters are 2.00933827184 8.01225161616 4.94232092789\n",
      "Epoch 333\n",
      "Iteration 100 - loss is 8.62219880855 - parameters are 1.9991900667 8.0034808279 4.94121756317\n",
      "Iteration 200 - loss is 9.68693065775 - parameters are 2.0015527827 8.00355026565 4.94155979097\n",
      "Iteration 300 - loss is 7.75824754476 - parameters are 1.99961361023 8.00369632804 4.94135216258\n",
      "Iteration 400 - loss is 9.55204359019 - parameters are 2.00328078838 8.00970217922 4.94176716685\n",
      "Iteration 500 - loss is 8.77048385492 - parameters are 1.99482789835 7.99881568408 4.94067503906\n",
      "Iteration 600 - loss is 7.99334313383 - parameters are 2.00613283391 8.00848381637 4.94204855675\n",
      "Iteration 700 - loss is 9.19416461637 - parameters are 2.00457418965 8.00662507522 4.94173151052\n",
      "Iteration 800 - loss is 7.15353184376 - parameters are 2.00574529522 8.01182877205 4.9421725178\n",
      "Iteration 900 - loss is 8.49923561516 - parameters are 2.00412530226 8.00765248041 4.94173162308\n",
      "Iteration 1000 - loss is 10.9543278487 - parameters are 2.00931285398 8.01222462109 4.94269009948\n",
      "Epoch 334\n",
      "Iteration 100 - loss is 8.62132627167 - parameters are 1.99916853098 8.00345779627 4.94158659237\n",
      "Iteration 200 - loss is 9.68619396893 - parameters are 2.00152820979 8.00352425203 4.9419276921\n",
      "Iteration 300 - loss is 7.75857387846 - parameters are 1.99959113499 8.00367229813 4.94171981048\n",
      "Iteration 400 - loss is 9.55278626218 - parameters are 2.00325693069 8.00967758821 4.94213413922\n",
      "Iteration 500 - loss is 8.76979874641 - parameters are 1.99480450115 7.99879152473 4.94104160853\n",
      "Iteration 600 - loss is 7.99329021165 - parameters are 2.00610790703 8.00845853884 4.94241431166\n",
      "Iteration 700 - loss is 9.19446683173 - parameters are 2.00454932962 8.00659981484 4.94209674168\n",
      "Iteration 800 - loss is 7.15352787866 - parameters are 2.00572036811 8.01180310938 4.94253710311\n",
      "Iteration 900 - loss is 8.49936855756 - parameters are 2.00410190576 8.00762792253 4.94209580367\n",
      "Iteration 1000 - loss is 10.9531748447 - parameters are 2.00928783641 8.01219805081 4.94305346122\n",
      "Epoch 335\n",
      "Iteration 100 - loss is 8.62047001351 - parameters are 1.99914733447 8.00343512714 4.94194981396\n",
      "Iteration 200 - loss is 9.68547162229 - parameters are 2.00150402385 8.00349864773 4.94228980339\n",
      "Iteration 300 - loss is 7.75889699866 - parameters are 1.99956901377 8.0036486464 4.94208167254\n",
      "Iteration 400 - loss is 9.55351922505 - parameters are 2.00323344873 8.00965338415 4.94249533639\n",
      "Iteration 500 - loss is 8.76912609114 - parameters are 1.99478147246 7.99876774561 4.94140240914\n",
      "Iteration 600 - loss is 7.99324039003 - parameters are 2.00608337269 8.00843365907 4.94277431054\n",
      "Iteration 700 - loss is 9.19476618521 - parameters are 2.00452486114 8.006574952 4.94245622508\n",
      "Iteration 800 - loss is 7.15352615982 - parameters are 2.00569583358 8.01177785055 4.94289595083\n",
      "Iteration 900 - loss is 8.49950150194 - parameters are 2.00407887773 8.00760375112 4.94245425305\n",
      "Iteration 1000 - loss is 10.9520420301 - parameters are 2.00926321283 8.01217189865 4.94341110465\n",
      "Epoch 336\n",
      "Iteration 100 - loss is 8.61962969807 - parameters are 1.99912647184 8.00341281478 4.94230731945\n",
      "Iteration 200 - loss is 9.68476330605 - parameters are 2.00148021878 8.00347344629 4.94264621606\n",
      "Iteration 300 - loss is 7.75921689596 - parameters are 1.99954724097 8.00362536687 4.94243783991\n",
      "Iteration 400 - loss is 9.55424257001 - parameters are 2.00321033656 8.00962956094 4.94285084934\n",
      "Iteration 500 - loss is 8.76846564072 - parameters are 1.99475880647 7.99874434071 4.9417575318\n",
      "Iteration 600 - loss is 7.99319354932 - parameters are 2.00605922471 8.00840917078 4.94312864409\n",
      "Iteration 700 - loss is 9.19506266274 - parameters are 2.004500778 8.00655048044 4.94281005127\n",
      "Iteration 800 - loss is 7.15352658366 - parameters are 2.00567168542 8.01175298921 4.94324915134\n",
      "Iteration 900 - loss is 8.49963438288 - parameters are 2.00405621238 8.0075799601 4.94280706151\n",
      "Iteration 1000 - loss is 10.950929023 - parameters are 2.00923897701 8.01214615801 4.94376311984\n",
      "Epoch 337\n",
      "Iteration 100 - loss is 8.61880499711 - parameters are 1.99910593781 8.00339085358 4.9426591989\n",
      "Iteration 200 - loss is 9.68406871604 - parameters are 2.00145678858 8.00344864138 4.94299701988\n",
      "Iteration 300 - loss is 7.759533563 - parameters are 1.9995258111 8.0036024537 4.94278840231\n",
      "Iteration 400 - loss is 9.55495638871 - parameters are 2.00318758836 8.00960611258 4.94320076762\n",
      "Iteration 500 - loss is 8.7678171523 - parameters are 1.99473649744 7.99872130414 4.94210706594\n",
      "Iteration 600 - loss is 7.99314957396 - parameters are 2.00603545698 8.00838506781 4.94347740155\n",
      "Iteration 700 - loss is 9.19535625234 - parameters are 2.00447707415 8.006526394 4.94315830938\n",
      "Iteration 800 - loss is 7.15352905036 - parameters are 2.00564791754 8.01172851908 4.94359679362\n",
      "Iteration 900 - loss is 8.49976713803 - parameters are 2.00403390396 8.00755654348 4.94315431792\n",
      "Iteration 1000 - loss is 10.9498354496 - parameters are 2.00921512284 8.01212082241 4.94410959548\n",
      "Epoch 338\n",
      "Iteration 100 - loss is 8.61799559003 - parameters are 1.99908572718 8.003369238 4.94300554093\n",
      "Iteration 200 - loss is 9.68338755546 - parameters are 2.00143372732 8.00342422675 4.94334230323\n",
      "Iteration 300 - loss is 7.75984699434 - parameters are 1.99950471874 8.0035799011 4.94313344805\n",
      "Iteration 400 - loss is 9.55566077326 - parameters are 2.00316519838 8.00958303317 4.94354517938\n",
      "Iteration 500 - loss is 8.76718038847 - parameters are 1.99471453975 7.99869863011 4.94245109961\n",
      "Iteration 600 - loss is 7.99310835235 - parameters are 2.0060120635 8.0083613441 4.94382067077\n",
      "Iteration 700 - loss is 9.19564694399 - parameters are 2.00445374358 8.0065026866 4.94350108711\n",
      "Iteration 800 - loss is 7.15353346373 - parameters are 2.00562452394 8.01170443402 4.94393896524\n",
      "Iteration 900 - loss is 8.499899708 - parameters are 2.00401194687 8.00753349536 4.94349610974\n",
      "Iteration 1000 - loss is 10.9487609437 - parameters are 2.0091916443 8.01209588547 4.94445061882\n",
      "Epoch 339\n",
      "Iteration 100 - loss is 8.61720116357 - parameters are 1.99906583487 8.00334796259 4.94334643278\n",
      "Iteration 200 - loss is 9.68271953475 - parameters are 2.0014110292 8.00340019624 4.94368215306\n",
      "Iteration 300 - loss is 7.76015718639 - parameters are 1.99948395858 8.0035577034 4.94347306403\n",
      "Iteration 400 - loss is 9.55635581612 - parameters are 2.00314316096 8.0095603169 4.94388417135\n",
      "Iteration 500 - loss is 8.76655511707 - parameters are 1.99469292785 7.99867631289 4.94278971947\n",
      "Iteration 600 - loss is 7.99306977674 - parameters are 2.00598903838 8.00833799366 4.9441585382\n",
      "Iteration 700 - loss is 9.19593472957 - parameters are 2.00443078042 8.00647935227 4.94383847081\n",
      "Iteration 800 - loss is 7.15353973112 - parameters are 2.00560149872 8.01168072794 4.94427575236\n",
      "Iteration 900 - loss is 8.50003203626 - parameters are 2.00399033554 8.00751080993 4.94383252305\n",
      "Iteration 1000 - loss is 10.947705147 - parameters are 2.00916853545 8.01207134091 4.94478627576\n",
      "Epoch 340\n",
      "Iteration 100 - loss is 8.6164214117 - parameters are 1.99904625585 8.003327022 4.94368196031\n",
      "Iteration 200 - loss is 9.68206437133 - parameters are 2.00138868848 8.00337654383 4.94401665497\n",
      "Iteration 300 - loss is 7.76046413733 - parameters are 1.99946352537 8.00353585501 4.94380733578\n",
      "Iteration 400 - loss is 9.55704161002 - parameters are 2.00312147056 8.00953795805 4.94421782892\n",
      "Iteration 500 - loss is 8.76594111109 - parameters are 1.99467165629 7.99865434686 4.94312301079\n",
      "Iteration 600 - loss is 7.99303374309 - parameters are 2.0059663758 8.00831501063 4.94449108894\n",
      "Iteration 700 - loss is 9.19621960276 - parameters are 2.00440817886 8.00645638514 4.94417054545\n",
      "Iteration 800 - loss is 7.15354776325 - parameters are 2.00557883606 8.01165739489 4.94460723981\n",
      "Iteration 900 - loss is 8.50016406902 - parameters are 2.00396906452 8.00748848147 4.94416364259\n",
      "Iteration 1000 - loss is 10.9466677085 - parameters are 2.00914579049 8.01204718255 4.94511665084\n",
      "Epoch 341\n",
      "Iteration 100 - loss is 8.61565603541 - parameters are 1.99902698517 8.00330641095 4.94401220801\n",
      "Iteration 200 - loss is 9.68142178944 - parameters are 2.00136669952 8.00335326354 4.9443458932\n",
      "Iteration 300 - loss is 7.760767847 - parameters are 1.99944341394 8.00351435042 4.94413634748\n",
      "Iteration 400 - loss is 9.55771824795 - parameters are 2.00310012169 8.00951595099 4.94454623612\n",
      "Iteration 500 - loss is 8.76533814856 - parameters are 1.9946507197 7.9986327265 4.9434510575\n",
      "Iteration 600 - loss is 7.99300015094 - parameters are 2.00594407004 8.0082923892 4.94481840674\n",
      "Iteration 700 - loss is 9.19650155898 - parameters are 2.0043859332 8.00643377943 4.94449739465\n",
      "Iteration 800 - loss is 7.15355747414 - parameters are 2.00555653025 8.01163442899 4.94493351108\n",
      "Iteration 900 - loss is 8.50029575514 - parameters are 2.00394812846 8.00746650438 4.94448955174\n",
      "Iteration 1000 - loss is 10.9456482846 - parameters are 2.00912340365 8.01202340431 4.94544182724\n",
      "Epoch 342\n",
      "Iteration 100 - loss is 8.61490474252 - parameters are 1.99900801797 8.00328612425 4.94433725906\n",
      "Iteration 200 - loss is 9.68079151998 - parameters are 2.00134505678 8.00333034952 4.94466995067\n",
      "Iteration 300 - loss is 7.76106831686 - parameters are 1.99942361923 8.00349318422 4.944460182\n",
      "Iteration 400 - loss is 9.55838582307 - parameters are 2.00307910897 8.00949429018 4.94486947564\n",
      "Iteration 500 - loss is 8.76474601239 - parameters are 1.9946301128 7.99861144636 4.94377394223\n",
      "Iteration 600 - loss is 7.99296890331 - parameters are 2.00592211549 8.0082701237 4.94514057403\n",
      "Iteration 700 - loss is 9.19678059528 - parameters are 2.00436403783 8.00641152943 4.94481910072\n",
      "Iteration 800 - loss is 7.15356878098 - parameters are 2.00553457567 8.01161182445 4.94525464832\n",
      "Iteration 900 - loss is 8.50042704605 - parameters are 2.00392752206 8.0074448731 4.94481033256\n",
      "Iteration 1000 - loss is 10.9446465387 - parameters are 2.0091013693 8.0120000002 4.94576188686\n",
      "Epoch 343\n",
      "Iteration 100 - loss is 8.61416724751 - parameters are 1.99898934946 8.00326615678 4.94465719532\n",
      "Iteration 200 - loss is 9.68017330028 - parameters are 2.0013237548 8.003307796 4.94498890899\n",
      "Iteration 300 - loss is 7.76136554987 - parameters are 1.99940413624 8.00347235108 4.94477892088\n",
      "Iteration 400 - loss is 9.55904442866 - parameters are 2.0030584271 8.00947297017 4.94518762889\n",
      "Iteration 500 - loss is 8.76416449025 - parameters are 1.99460983038 7.99859050108 4.94409174628\n",
      "Iteration 600 - loss is 7.99293990657 - parameters are 2.00590050659 8.00824820851 4.94545767193\n",
      "Iteration 700 - loss is 9.1970567103 - parameters are 2.00434248723 8.00638962955 4.94513574468\n",
      "Iteration 800 - loss is 7.15358160404 - parameters are 2.00551296676 8.01158957558 4.9455707324\n",
      "Iteration 900 - loss is 8.5005578956 - parameters are 2.00390724012 8.0074235822 4.94512606584\n",
      "Iteration 1000 - loss is 10.9436621414 - parameters are 2.00907968187 8.01197696434 4.9460769103\n",
      "Epoch 344\n",
      "Iteration 100 - loss is 8.61344327137 - parameters are 1.99897097493 8.00324650353 4.94497209733\n",
      "Iteration 200 - loss is 9.67956687399 - parameters are 2.00130278821 8.00328559731 4.94530284845\n",
      "Iteration 300 - loss is 7.76165955047 - parameters are 1.99938496004 8.00345184575 4.94509264437\n",
      "Iteration 400 - loss is 9.55969415807 - parameters are 2.00303807086 8.00945198559 4.94550077598\n",
      "Iteration 500 - loss is 8.76359337448 - parameters are 1.99458986734 7.99856988538 4.94440454967\n",
      "Iteration 600 - loss is 7.99291307034 - parameters are 2.00587923791 8.00822663812 4.94576978029\n",
      "Iteration 700 - loss is 9.19732990417 - parameters are 2.00432127595 8.00636807427 4.94544740625\n",
      "Iteration 800 - loss is 7.15359586653 - parameters are 2.00549169808 8.01156767679 4.94588184291\n",
      "Iteration 900 - loss is 8.50068826001 - parameters are 2.00388727753 8.00740262631 4.94543683108\n",
      "Iteration 1000 - loss is 10.9426947697 - parameters are 2.0090583359 8.01195429091 4.94638697687\n",
      "Epoch 345\n",
      "Iteration 100 - loss is 8.6127325414 - parameters are 1.99895288974 8.00322715954 4.9452820444\n",
      "Iteration 200 - loss is 9.67897199088 - parameters are 2.00128215171 8.00326374786 4.94561184813\n",
      "Iteration 300 - loss is 7.76195032447 - parameters are 1.99936608581 8.00343166307 4.94540143149\n",
      "Iteration 400 - loss is 9.56033510469 - parameters are 2.00301803511 8.00943133116 4.94580899575\n",
      "Iteration 500 - loss is 8.76303246197 - parameters are 1.99457021862 7.99854959407 4.94471243117\n",
      "Iteration 600 - loss is 7.99288830739 - parameters are 2.00585830407 8.0082054071 4.94607697769\n",
      "Iteration 700 - loss is 9.19760017845 - parameters are 2.00430039865 8.00634685817 4.94575416391\n",
      "Iteration 800 - loss is 7.15361149454 - parameters are 2.00547076426 8.01154612255 4.94618805819\n",
      "Iteration 900 - loss is 8.50081809781 - parameters are 2.00386762926 8.00738200016 4.94574270653\n",
      "Iteration 1000 - loss is 10.9417441077 - parameters are 2.00903732599 8.01193197422 4.94669216465\n",
      "Epoch 346\n",
      "Iteration 100 - loss is 8.61203479108 - parameters are 1.99893508933 8.00320811994 4.94558711456\n",
      "Iteration 200 - loss is 9.67838840665 - parameters are 2.0012618401 8.00324224215 4.9459159858\n",
      "Iteration 300 - loss is 7.76223787901 - parameters are 1.99934750877 8.00341179796 4.94570535996\n",
      "Iteration 400 - loss is 9.56096736187 - parameters are 2.00299831481 8.00941100168 4.94611236581\n",
      "Iteration 500 - loss is 8.76248155402 - parameters are 1.99455087927 7.99852962205 4.94501546829\n",
      "Iteration 600 - loss is 7.99286553352 - parameters are 2.00583769979 8.0081845101 4.94637934149\n",
      "Iteration 700 - loss is 9.19786753607 - parameters are 2.00427985005 8.0063259759 4.94605609489\n",
      "Iteration 800 - loss is 7.15362841692 - parameters are 2.00545016003 8.01152490745 4.94648945533\n",
      "Iteration 900 - loss is 8.50094736967 - parameters are 2.00384829033 8.00736169855 4.94604376919\n",
      "Iteration 1000 - loss is 10.9408098457 - parameters are 2.00901664686 8.01191000864 4.94699255047\n",
      "Epoch 347\n",
      "Iteration 100 - loss is 8.6113497599 - parameters are 1.99891756921 8.00318937994 4.94588738463\n",
      "Iteration 200 - loss is 9.67781588285 - parameters are 2.00124184826 8.00322107477 4.94621533806\n",
      "Iteration 300 - loss is 7.76252222245 - parameters are 1.99932922425 8.00339224541 4.94600450631\n",
      "Iteration 400 - loss is 9.56159102289 - parameters are 2.00297890497 8.00939099204 4.94641096255\n",
      "Iteration 500 - loss is 8.76194045627 - parameters are 1.99453184442 7.99850996428 4.94531373732\n",
      "Iteration 600 - loss is 7.99284466746 - parameters are 2.00581741989 8.00816394187 4.94667694781\n",
      "Iteration 700 - loss is 9.19813198125 - parameters are 2.00425962498 8.0063054222 4.94635327521\n",
      "Iteration 800 - loss is 7.1536465652 - parameters are 2.00542988018 8.01150402613 4.94678611021\n",
      "Iteration 900 - loss is 8.5010760384 - parameters are 2.00382925589 8.00734171638 4.94634009487\n",
      "Iteration 1000 - loss is 10.9398916803 - parameters are 2.00899629329 8.01188838865 4.94728820996\n",
      "Epoch 348\n",
      "Iteration 100 - loss is 8.61067719322 - parameters are 1.99890032495 8.00317093481 4.94618293019\n",
      "Iteration 200 - loss is 9.67725418665 - parameters are 2.00122217114 8.00320024039 4.94650998027\n",
      "Iteration 300 - loss is 7.76280336436 - parameters are 1.99931122762 8.00337300051 4.94629894586\n",
      "Iteration 400 - loss is 9.56220618093 - parameters are 2.0029598007 8.00937129719 4.94670486113\n",
      "Iteration 500 - loss is 8.76140897855 - parameters are 1.99451310926 7.99849061582 4.94560731337\n",
      "Iteration 600 - loss is 7.99282563081 - parameters are 2.00579745924 8.00814369723 4.94696987156\n",
      "Iteration 700 - loss is 9.19839351946 - parameters are 2.00423971833 8.00628519191 4.94664577969\n",
      "Iteration 800 - loss is 7.15366587349 - parameters are 2.0054099196 8.01148347335 4.94707809752\n",
      "Iteration 900 - loss is 8.50120406882 - parameters are 2.00381052112 8.00732204861 4.94663175817\n",
      "Iteration 1000 - loss is 10.9389893145 - parameters are 2.00897626013 8.0118671088 4.94757921756\n",
      "Epoch 349\n",
      "Iteration 100 - loss is 8.61001684209 - parameters are 1.9988833522 8.00315277992 4.94647382566\n",
      "Iteration 200 - loss is 9.67670309074 - parameters are 2.00120280379 8.00317973377 4.9467999866\n",
      "Iteration 300 - loss is 7.76308131546 - parameters are 1.99929351434 8.00335405841 4.94658875273\n",
      "Iteration 400 - loss is 9.562812929 - parameters are 2.00294099719 8.00935191219 4.94699413555\n",
      "Iteration 500 - loss is 8.76088693484 - parameters are 1.99449466906 7.99847157179 4.94589627034\n",
      "Iteration 600 - loss is 7.99280834788 - parameters are 2.00577781281 8.00812377108 4.94725818651\n",
      "Iteration 700 - loss is 9.19865215732 - parameters are 2.00422012508 8.00626527991 4.94693368196\n",
      "Iteration 800 - loss is 7.15368627837 - parameters are 2.00539027326 8.01146324394 4.94736549077\n",
      "Iteration 900 - loss is 8.50133142771 - parameters are 2.0037920813 8.00730269028 4.9469188325\n",
      "Iteration 1000 - loss is 10.9381024572 - parameters are 2.00895654235 8.01184616375 4.94786564652\n",
      "Epoch 350\n",
      "Iteration 100 - loss is 8.60936846316 - parameters are 1.99886664669 8.00313491068 4.94676014426\n",
      "Iteration 200 - loss is 9.67616237315 - parameters are 2.00118374132 8.00315954974 4.94708543005\n",
      "Iteration 300 - loss is 7.7633560875 - parameters are 1.99927607996 8.00333541433 4.94687399988\n",
      "Iteration 400 - loss is 9.56341135994 - parameters are 2.0029224897 8.00933283215 4.94727885862\n",
      "Iteration 500 - loss is 8.7603741431 - parameters are 1.99447651918 7.9984528274 4.94618068097\n",
      "Iteration 600 - loss is 7.99279274565 - parameters are 2.00575847566 8.00810415841 4.94754196521\n",
      "Iteration 700 - loss is 9.19890790259 - parameters are 2.00420084029 8.00624568122 4.9472170545\n",
      "Iteration 800 - loss is 7.15370771887 - parameters are 2.00537093621 8.01144333279 4.9476483623\n",
      "Iteration 900 - loss is 8.50145808372 - parameters are 2.00377393178 8.00728363653 4.94720139014\n",
      "Iteration 1000 - loss is 10.9372308233 - parameters are 2.00893713497 8.01182554821 4.94814756894\n",
      "Epoch 351\n",
      "Iteration 100 - loss is 8.6087318185 - parameters are 1.9988502042 8.00311732261 4.94704195808\n",
      "Iteration 200 - loss is 9.67563181717 - parameters are 2.00116497893 8.00313968324 4.94736638249\n",
      "Iteration 300 - loss is 7.76362769327 - parameters are 1.99925892006 8.00331706359 4.9471547591\n",
      "Iteration 400 - loss is 9.56400156635 - parameters are 2.00290427354 8.00931405228 4.94755910202\n",
      "Iteration 500 - loss is 8.75987042523 - parameters are 1.99445865504 7.99843437794 4.94646061684\n",
      "Iteration 600 - loss is 7.99277875369 - parameters are 2.00573944289 8.00808485428 4.94782127912\n",
      "Iteration 700 - loss is 9.19916076409 - parameters are 2.0041818591 8.00622639088 4.94749596863\n",
      "Iteration 800 - loss is 7.15373013633 - parameters are 2.00535190356 8.0114237349 4.94792678332\n",
      "Iteration 900 - loss is 8.5015840073 - parameters are 2.00375606798 8.00726488257 4.9474795022\n",
      "Iteration 1000 - loss is 10.9363741333 - parameters are 2.0089180331 8.011805257 4.9484250558\n",
      "Epoch 352\n",
      "Iteration 100 - loss is 8.60810667546 - parameters are 1.99883402058 8.00310001127 4.94731933803\n",
      "Iteration 200 - loss is 9.67511121112 - parameters are 2.00114651189 8.00312012926 4.94764291463\n",
      "Iteration 300 - loss is 7.76389614652 - parameters are 1.99924203033 8.00329900157 4.94743110108\n",
      "Iteration 400 - loss is 9.56458364055 - parameters are 2.00288634414 8.00929556784 4.94783493628\n",
      "Iteration 500 - loss is 8.75937560692 - parameters are 1.99444107213 7.99841621875 4.94673614844\n",
      "Iteration 600 - loss is 7.99276630403 - parameters are 2.00572070973 8.00806585384 4.94809619852\n",
      "Iteration 700 - loss is 9.19941075163 - parameters are 2.00416317671 8.00620740404 4.94777049457\n",
      "Iteration 800 - loss is 7.15375347431 - parameters are 2.00533317052 8.01140444534 4.9482008239\n",
      "Iteration 900 - loss is 8.50170917064 - parameters are 2.0037384854 8.00724642366 4.94775323871\n",
      "Iteration 1000 - loss is 10.9355321136 - parameters are 2.00889923191 8.01178528501 4.94869817693\n",
      "Epoch 353\n",
      "Iteration 100 - loss is 8.60749280658 - parameters are 1.99881809175 8.0030829723 4.94759235396\n",
      "Iteration 200 - loss is 9.6746003483 - parameters are 2.00112833553 8.00310088287 4.94791509607\n",
      "Iteration 300 - loss is 7.76416146191 - parameters are 1.9992254065 8.00328122372 4.94770309536\n",
      "Iteration 400 - loss is 9.56515767461 - parameters are 2.00286869698 8.00927737418 4.94810643085\n",
      "Iteration 500 - loss is 8.75888951764 - parameters are 1.99442376603 7.99839834526 4.9470073451\n",
      "Iteration 600 - loss is 7.99275533111 - parameters are 2.00570227143 8.0080471523 4.94836679264\n",
      "Iteration 700 - loss is 9.199657876 - parameters are 2.00414478843 8.00618871593 4.94804070142\n",
      "Iteration 800 - loss is 7.15377767859 - parameters are 2.00531473236 8.01138545925 4.94847055303\n",
      "Iteration 900 - loss is 8.50183354759 - parameters are 2.0037211796 8.00722825517 4.94802266854\n",
      "Iteration 1000 - loss is 10.9347044959 - parameters are 2.00888072668 8.01176562722 4.94896700109\n",
      "Epoch 354\n",
      "Iteration 100 - loss is 8.60688998942 - parameters are 1.99880241369 8.00306620142 4.94786107456\n",
      "Iteration 200 - loss is 9.67409902684 - parameters are 2.00111044528 8.00308193925 4.94818299534\n",
      "Iteration 300 - loss is 7.76442365495 - parameters are 1.99920904437 8.00326372557 4.94797081041\n",
      "Iteration 400 - loss is 9.56572376022 - parameters are 2.0028513276 8.00925946674 4.94837365405\n",
      "Iteration 500 - loss is 8.75841199044 - parameters are 1.99440673235 7.99838075298 4.94727427509\n",
      "Iteration 600 - loss is 7.9927457717 - parameters are 2.00568412336 8.00802874497 4.94863312956\n",
      "Iteration 700 - loss is 9.19990214887 - parameters are 2.00412668961 8.00617032184 4.94830665717\n",
      "Iteration 800 - loss is 7.15380269701 - parameters are 2.00529658445 8.01136677185 4.94873603859\n",
      "Iteration 900 - loss is 8.50195711362 - parameters are 2.00370414623 8.00721037252 4.94828785953\n",
      "Iteration 1000 - loss is 10.9338910174 - parameters are 2.00886251273 8.01174627869 4.94923159592\n",
      "Epoch 355\n",
      "Iteration 100 - loss is 8.60629800644 - parameters are 1.99878698245 8.00304969441 4.94812556749\n",
      "Iteration 200 - loss is 9.67360704954 - parameters are 2.00109283663 8.00306329362 4.94844667984\n",
      "Iteration 300 - loss is 7.76468274197 - parameters are 1.99919293983 8.00324650271 4.94823431361\n",
      "Iteration 400 - loss is 9.56628198875 - parameters are 2.00283423162 8.009241841 4.94863667313\n",
      "Iteration 500 - loss is 8.75794286198 - parameters are 1.99438996682 7.99836343748 4.94753700558\n",
      "Iteration 600 - loss is 7.99273756479 - parameters are 2.00566626095 8.0080106272 4.94889527632\n",
      "Iteration 700 - loss is 9.2001435828 - parameters are 2.00410887569 8.00615221714 4.94856842878\n",
      "Iteration 800 - loss is 7.15382847945 - parameters are 2.00527872219 8.01134837844 4.9489973474\n",
      "Iteration 900 - loss is 8.50207984572 - parameters are 2.00368738098 8.0071927712 4.9485488784\n",
      "Iteration 1000 - loss is 10.9330914206 - parameters are 2.00884458547 8.01172723453 4.94949202803\n",
      "Epoch 356\n",
      "Iteration 100 - loss is 8.60571664491 - parameters are 1.99877179413 8.00303344711 4.94838589929\n",
      "Iteration 200 - loss is 9.6731242238 - parameters are 2.00107550514 8.0030449413 4.94870621595\n",
      "Iteration 300 - loss is 7.76493874007 - parameters are 1.99917708882 8.00322955081 4.94849367127\n",
      "Iteration 400 - loss is 9.56683245117 - parameters are 2.00281740474 8.00922449252 4.9488955543\n",
      "Iteration 500 - loss is 8.75748197234 - parameters are 1.9943734652 7.9983463944 4.94779560271\n",
      "Iteration 600 - loss is 7.99273065157 - parameters are 2.00564867968 8.00799279444 4.94915329891\n",
      "Iteration 700 - loss is 9.20038219113 - parameters are 2.00409134218 8.00613439728 4.94882608211\n",
      "Iteration 800 - loss is 7.15385497774 - parameters are 2.0052611411 8.01133027439 4.94925454522\n",
      "Iteration 900 - loss is 8.50220172236 - parameters are 2.00367087963 8.0071754468 4.94880579086\n",
      "Iteration 1000 - loss is 10.9323054531 - parameters are 2.0088269404 8.01170848996 4.94974836295\n",
      "Epoch 357\n",
      "Iteration 100 - loss is 8.60514569677 - parameters are 1.99875684492 8.00301745542 4.9486421355\n",
      "Iteration 200 - loss is 9.67265036147 - parameters are 2.00105844644 8.00302687766 4.94896166898\n",
      "Iteration 300 - loss is 7.76519166708 - parameters are 1.99916148733 8.00321286559 4.94874894868\n",
      "Iteration 400 - loss is 9.56737523804 - parameters are 2.00280084272 8.00920741695 4.94915036271\n",
      "Iteration 500 - loss is 8.75702916503 - parameters are 1.99435722333 7.99832961946 4.94805013155\n",
      "Iteration 600 - loss is 7.99272497531 - parameters are 2.00563137513 8.0079752422 4.94940726224\n",
      "Iteration 700 - loss is 9.20061798799 - parameters are 2.00407408466 8.00611685776 4.94907968201\n",
      "Iteration 800 - loss is 7.1538821456 - parameters are 2.00524383673 8.01131245515 4.94950769679\n",
      "Iteration 900 - loss is 8.50232272345 - parameters are 2.00365463803 8.00715839495 4.94905866154\n",
      "Iteration 1000 - loss is 10.9315328675 - parameters are 2.00880957305 8.01169004026 4.95000066521\n",
      "Epoch 358\n",
      "Iteration 100 - loss is 8.60458495849 - parameters are 1.99874213103 8.00300171533 4.94889434059\n",
      "Iteration 200 - loss is 9.67218527873 - parameters are 2.00104165623 8.00300909816 4.94921310322\n",
      "Iteration 300 - loss is 7.76544154149 - parameters are 1.99914613143 8.00319644287 4.94900021006\n",
      "Iteration 400 - loss is 9.56791043947 - parameters are 2.00278454138 8.00919060998 4.94940116247\n",
      "Iteration 500 - loss is 8.75658428681 - parameters are 1.99434123713 7.99831310842 4.94830065615\n",
      "Iteration 600 - loss is 7.99272048133 - parameters are 2.00561434294 8.00795796607 4.94965723024\n",
      "Iteration 700 - loss is 9.20085098824 - parameters are 2.00405709878 8.00609959418 4.9493292923\n",
      "Iteration 800 - loss is 7.15390993857 - parameters are 2.00522680473 8.01129491623 4.9497568658\n",
      "Iteration 900 - loss is 8.50244283024 - parameters are 2.00363865207 8.00714161136 4.9493075541\n",
      "Iteration 1000 - loss is 10.9307734213 - parameters are 2.00879247905 8.0116718808 4.95024899827\n",
      "Epoch 359\n",
      "Iteration 100 - loss is 8.60403423101 - parameters are 1.99872764876 8.00298622287 4.94914257803\n",
      "Iteration 200 - loss is 9.671728796 - parameters are 2.00102513029 8.00299159833 4.94946058195\n",
      "Iteration 300 - loss is 7.76568838246 - parameters are 1.99913101725 8.00318027851 4.94924751864\n",
      "Iteration 400 - loss is 9.56843814513 - parameters are 2.00276849661 8.00917406739 4.94964801671\n",
      "Iteration 500 - loss is 8.75614718772 - parameters are 1.99432550255 7.99829685713 4.94854723956\n",
      "Iteration 600 - loss is 7.99271711689 - parameters are 2.00559757882 8.00794096169 4.9499032658\n",
      "Iteration 700 - loss is 9.20108120739 - parameters are 2.00404038026 8.00608260219 4.9495749758\n",
      "Iteration 800 - loss is 7.15393831396 - parameters are 2.00521004081 8.01127765322 4.95000211496\n",
      "Iteration 900 - loss is 8.50256202532 - parameters are 2.00362291773 8.0071250918 4.94955253116\n",
      "Iteration 1000 - loss is 10.930026877 - parameters are 2.0087756541 8.011654007 4.95049342465\n",
      "Epoch 360\n",
      "Iteration 100 - loss is 8.6034933196 - parameters are 1.99871339445 8.00297097415 4.94938691029\n",
      "Iteration 200 - loss is 9.67128073784 - parameters are 2.00100886444 8.00297437377 4.94970416743\n",
      "Iteration 300 - loss is 7.76593220971 - parameters are 1.99911614098 8.00316436845 4.94949093667\n",
      "Iteration 400 - loss is 9.56895844419 - parameters are 2.00275270437 8.00915778502 4.94989098754\n",
      "Iteration 500 - loss is 8.75571772092 - parameters are 1.99431001564 7.99828086151 4.94878994383\n",
      "Iteration 600 - loss is 7.99271483116 - parameters are 2.00558107854 8.00792422481 4.95014543085\n",
      "Iteration 700 - loss is 9.20130866163 - parameters are 2.00402392488 8.00606587751 4.94981679432\n",
      "Iteration 800 - loss is 7.15396723076 - parameters are 2.00519354073 8.01126066177 4.95024350598\n",
      "Iteration 900 - loss is 8.50268029251 - parameters are 2.00360743104 8.00710883212 4.94979365437\n",
      "Iteration 1000 - loss is 10.9292930016 - parameters are 2.00875909395 8.01163641436 4.95073400584\n",
      "Epoch 361\n",
      "Iteration 100 - loss is 8.60296203376 - parameters are 1.99869936452 8.00295596533 4.94962739885\n",
      "Iteration 200 - loss is 9.67084093279 - parameters are 2.00099285459 8.00295742014 4.94994392096\n",
      "Iteration 300 - loss is 7.76617304356 - parameters are 1.99910149888 8.00314870867 4.94973052539\n",
      "Iteration 400 - loss is 9.56947142531 - parameters are 2.00273716068 8.00914175877 4.95013013609\n",
      "Iteration 500 - loss is 8.75529574265 - parameters are 1.99429477248 7.99826511753 4.94902883002\n",
      "Iteration 600 - loss is 7.99271357514 - parameters are 2.00556483794 8.00790775119 4.9503837863\n",
      "Iteration 700 - loss is 9.20153336774 - parameters are 2.0040077285 8.00604941595 4.95005480871\n",
      "Iteration 800 - loss is 7.15399664962 - parameters are 2.00517730035 8.01124393761 4.9504810996\n",
      "Iteration 900 - loss is 8.50279761685 - parameters are 2.00359218811 8.00709282823 4.95003098439\n",
      "Iteration 1000 - loss is 10.9285715669 - parameters are 2.00874279443 8.01161909847 4.95097080238\n",
      "Epoch 362\n",
      "Iteration 100 - loss is 8.60244018709 - parameters are 1.99868555543 8.00294119262 4.94986410421\n",
      "Iteration 200 - loss is 9.67040921333 - parameters are 2.00097709671 8.00294073318 4.95017990286\n",
      "Iteration 300 - loss is 7.76641090485 - parameters are 1.99908708724 8.00313329524 4.94996634509\n",
      "Iteration 400 - loss is 9.56997717664 - parameters are 2.00272186163 8.00912598462 4.95036552255\n",
      "Iteration 500 - loss is 8.75488111216 - parameters are 1.99427976925 7.99824962122 4.94926395825\n",
      "Iteration 600 - loss is 7.99271330159 - parameters are 2.00554885294 8.0078915367 4.95061839215\n",
      "Iteration 700 - loss is 9.20175534307 - parameters are 2.00399178704 8.00603321334 4.95028907885\n",
      "Iteration 800 - loss is 7.15402653277 - parameters are 2.00516131557 8.01122747654 4.9507149556\n",
      "Iteration 900 - loss is 8.50291398454 - parameters are 2.00357718508 8.0070770761 4.95026458095\n",
      "Iteration 1000 - loss is 10.9278623489 - parameters are 2.00872675144 8.01160205495 4.95120387385\n",
      "Epoch 363\n",
      "Iteration 100 - loss is 8.60192759726 - parameters are 1.99867196369 8.00292665231 4.95009708595\n",
      "Iteration 200 - loss is 9.66998541576 - parameters are 2.00096158682 8.0029243087 4.95041217252\n",
      "Iteration 300 - loss is 7.76664581489 - parameters are 1.99907290244 8.00311812428 4.95019845509\n",
      "Iteration 400 - loss is 9.57047578577 - parameters are 2.00270680335 8.00911045858 4.95059720613\n",
      "Iteration 500 - loss is 8.75447369163 - parameters are 1.99426500215 7.99823436869 4.94949538767\n",
      "Iteration 600 - loss is 7.992713965 - parameters are 2.0055331195 8.00787557726 4.9508493074\n",
      "Iteration 700 - loss is 9.20197460552 - parameters are 2.00397609648 8.00601726562 4.95051966371\n",
      "Iteration 800 - loss is 7.15405684394 - parameters are 2.00514558236 8.01121127441 4.95094513282\n",
      "Iteration 900 - loss is 8.50302938289 - parameters are 2.00356241818 8.00706157177 4.95049450282\n",
      "Iteration 1000 - loss is 10.9271651283 - parameters are 2.00871096093 8.01158527953 4.95143327889\n",
      "Epoch 364\n",
      "Iteration 100 - loss is 8.60142408585 - parameters are 1.99865858589 8.00291234075 4.95032640268\n",
      "Iteration 200 - loss is 9.66956938007 - parameters are 2.00094632103 8.00290814255 4.95064078837\n",
      "Iteration 300 - loss is 7.76687779547 - parameters are 1.99905894091 8.00310319197 4.9504269138\n",
      "Iteration 400 - loss is 9.57096733975 - parameters are 2.00269198206 8.00909517676 4.95082524513\n",
      "Iteration 500 - loss is 8.75407334609 - parameters are 1.99425046747 7.9982193561 4.94972317652\n",
      "Iteration 600 - loss is 7.99271552151 - parameters are 2.00551763367 8.00785986886 4.95107659018\n",
      "Iteration 700 - loss is 9.20219117347 - parameters are 2.00396065286 8.00600156878 4.95074662128\n",
      "Iteration 800 - loss is 7.15408754838 - parameters are 2.00513009676 8.01119532714 4.95117168918\n",
      "Iteration 900 - loss is 8.50314380028 - parameters are 2.00354788368 8.00704631133 4.95072080783\n",
      "Iteration 1000 - loss is 10.9264796901 - parameters are 2.00869541893 8.01156876799 4.95165907522\n",
      "Epoch 365\n",
      "Iteration 100 - loss is 8.60092947825 - parameters are 1.99864541864 8.00289825433 4.95055211208\n",
      "Iteration 200 - loss is 9.6691609499 - parameters are 2.00093129547 8.00289223069 4.95086580794\n",
      "Iteration 300 - loss is 7.7671068688 - parameters are 1.99904519912 8.00308849456 4.95065177871\n",
      "Iteration 400 - loss is 9.57145192501 - parameters are 2.00267739402 8.00908013531 4.95104969693\n",
      "Iteration 500 - loss is 8.7536799434 - parameters are 1.99423616155 7.99820457968 4.9499473821\n",
      "Iteration 600 - loss is 7.99271792885 - parameters are 2.00550239154 8.00784440754 4.95130029764\n",
      "Iteration 700 - loss is 9.20240506579 - parameters are 2.00394545229 8.00598611886 4.95097000866\n",
      "Iteration 800 - loss is 7.15411861272 - parameters are 2.00511485487 8.01117963073 4.95139468167\n",
      "Iteration 900 - loss is 8.5032572261 - parameters are 2.00353357794 8.00703129095 4.95094355294\n",
      "Iteration 1000 - loss is 10.9258058232 - parameters are 2.00868012152 8.01155251617 4.95188131964\n",
      "Epoch 366\n",
      "Iteration 100 - loss is 8.60044360362 - parameters are 1.99863245864 8.00288438951 4.95077427096\n",
      "Iteration 200 - loss is 9.66875997241 - parameters are 2.00091650637 8.00287656909 4.95108728782\n",
      "Iteration 300 - loss is 7.76733305749 - parameters are 1.99903167361 8.00307402834 4.95087310637\n",
      "Iteration 400 - loss is 9.57192962743 - parameters are 2.00266303556 8.00906533045 4.95127061798\n",
      "Iteration 500 - loss is 8.75329335411 - parameters are 1.99422208077 7.9981900357 4.95016806082\n",
      "Iteration 600 - loss is 7.99272114632 - parameters are 2.00548738926 8.00782918941 4.95152048609\n",
      "Iteration 700 - loss is 9.20261630177 - parameters are 2.00393049095 8.00597091198 4.95118988207\n",
      "Iteration 800 - loss is 7.15415000501 - parameters are 2.00509985285 8.01116418122 4.95161416639\n",
      "Iteration 900 - loss is 8.50336965074 - parameters are 2.00351949733 8.00701650685 4.95116279418\n",
      "Iteration 1000 - loss is 10.9251433209 - parameters are 2.00866506484 8.01153651999 4.95210006807\n",
      "Epoch 367\n",
      "Iteration 100 - loss is 8.59996629476 - parameters are 1.99861970261 8.00287074279 4.95099293519\n",
      "Iteration 200 - loss is 9.6683662982 - parameters are 2.00090195 8.00286115384 4.95130528375\n",
      "Iteration 300 - loss is 7.76755638451 - parameters are 1.99901836097 8.00305978969 4.95109095247\n",
      "Iteration 400 - loss is 9.57240053226 - parameters are 2.00264890306 8.00905075846 4.95148806388\n",
      "Iteration 500 - loss is 8.75291345148 - parameters are 1.9942082216 7.99817572051 4.95038526819\n",
      "Iteration 600 - loss is 7.9927251347 - parameters are 2.00547262308 8.00781421065 4.9517372109\n",
      "Iteration 700 - loss is 9.20282490111 - parameters are 2.00391576507 8.00595594431 4.95140629681\n",
      "Iteration 800 - loss is 7.15418169457 - parameters are 2.00508508691 8.01114897472 4.95183019857\n",
      "Iteration 900 - loss is 8.50348106551 - parameters are 2.00350563832 8.0070019553 4.9513785867\n",
      "Iteration 1000 - loss is 10.9244919804 - parameters are 2.00865024511 8.01152077541 4.95231537554\n",
      "Epoch 368\n",
      "Iteration 100 - loss is 8.59949738804 - parameters are 1.99860714735 8.00285731075 4.95120815979\n",
      "Iteration 200 - loss is 9.66797978124 - parameters are 2.0008876227 8.00284598104 4.95151985055\n",
      "Iteration 300 - loss is 7.76777687317 - parameters are 1.99900525785 8.00304577501 4.95130537182\n",
      "Iteration 400 - loss is 9.57286472411 - parameters are 2.00263499295 8.00903641567 4.95170208931\n",
      "Iteration 500 - loss is 8.75254011134 - parameters are 1.99419458054 7.9981616305 4.95059905886\n",
      "Iteration 600 - loss is 7.99272985619 - parameters are 2.00545808925 8.00779946749 4.95195052661\n",
      "Iteration 700 - loss is 9.20303088391 - parameters are 2.00390127093 8.00594121208 4.95161930732\n",
      "Iteration 800 - loss is 7.15421365205 - parameters are 2.00507055334 8.01113400743 4.95204283253\n",
      "Iteration 900 - loss is 8.50359146264 - parameters are 2.00349199741 8.00698763266 4.95159098479\n",
      "Iteration 1000 - loss is 10.9238516031 - parameters are 2.00863565859 8.01150527849 4.95252729622\n",
      "Epoch 369\n",
      "Iteration 100 - loss is 8.5990367233 - parameters are 1.99859478968 8.00284409001 4.9514199989\n",
      "Iteration 200 - loss is 9.66760027876 - parameters are 2.00087352086 8.00283104688 4.95173104222\n",
      "Iteration 300 - loss is 7.76799454709 - parameters are 1.99899236095 8.00303198079 4.95151641835\n",
      "Iteration 400 - loss is 9.57332228699 - parameters are 2.00262130175 8.00902229847 4.95191274812\n",
      "Iteration 500 - loss is 8.7521732121 - parameters are 1.99418115415 7.99814776213 4.95080948661\n",
      "Iteration 600 - loss is 7.99273527444 - parameters are 2.00544378413 8.00778495623 4.95216048686\n",
      "Iteration 700 - loss is 9.2032342706 - parameters are 2.00388700489 8.0059267116 4.95182896719\n",
      "Iteration 800 - loss is 7.1542458493 - parameters are 2.00505624848 8.01111927556 4.95225212178\n",
      "Iteration 900 - loss is 8.50370083519 - parameters are 2.00347857116 8.00697353531 4.95180004188\n",
      "Iteration 1000 - loss is 10.9232219938 - parameters are 2.0086213016 8.01149002532 4.9527358834\n",
      "Epoch 370\n",
      "Iteration 100 - loss is 8.59858414378 - parameters are 1.99858262649 8.00283107723 4.95162850581\n",
      "Iteration 200 - loss is 9.66722765118 - parameters are 2.00085964092 8.00281634762 4.95193891187\n",
      "Iteration 300 - loss is 7.76820943019 - parameters are 1.99897966702 8.00301840355 4.95172414516\n",
      "Iteration 400 - loss is 9.57377330424 - parameters are 2.00260782599 8.00900840332 4.95212009331\n",
      "Iteration 500 - loss is 8.75181263464 - parameters are 1.99416793906 7.99813411191 4.95101660438\n",
      "Iteration 600 - loss is 7.9927413544 - parameters are 2.00542970411 8.0077706732 4.95236714449\n",
      "Iteration 700 - loss is 9.20343508195 - parameters are 2.00387296335 8.00591243921 4.95203532916\n",
      "Iteration 800 - loss is 7.15427825937 - parameters are 2.00504216873 8.01110477541 4.95245811897\n",
      "Iteration 900 - loss is 8.50380917708 - parameters are 2.00346535621 8.0069596597 4.95200581055\n",
      "Iteration 1000 - loss is 10.9226029614 - parameters are 2.00860717054 8.01147501207 4.95294118957\n",
      "Epoch 371\n",
      "Iteration 100 - loss is 8.59813949603 - parameters are 1.99857065473 8.00281826916 4.95183373296\n",
      "Iteration 200 - loss is 9.66686176203 - parameters are 2.00084597939 8.00280187954 4.9521435118\n",
      "Iteration 300 - loss is 7.76842154663 - parameters are 1.99896717286 8.00300503987 4.95192860448\n",
      "Iteration 400 - loss is 9.57421785854 - parameters are 2.00259456228 8.00899472672 4.95232417703\n",
      "Iteration 500 - loss is 8.75145826226 - parameters are 1.99415493192 7.99812067641 4.95122046425\n",
      "Iteration 600 - loss is 7.99274806235 - parameters are 2.00541584565 8.00775661483 4.95257055146\n",
      "Iteration 700 - loss is 9.20363333901 - parameters are 2.00385914277 8.00589839133 4.95223844513\n",
      "Iteration 800 - loss is 7.15431085647 - parameters are 2.00502831054 8.01109050334 4.95266087589\n",
      "Iteration 900 - loss is 8.50391648299 - parameters are 2.0034523492 8.00694600236 4.95220834257\n",
      "Iteration 1000 - loss is 10.9219943184 - parameters are 2.00859326184 8.01146023495 4.95314326635\n",
      "Epoch 372\n",
      "Iteration 100 - loss is 8.59770262983 - parameters are 1.99855887137 8.00280566255 4.95203573199\n",
      "Iteration 200 - loss is 9.66650247788 - parameters are 2.00083253283 8.00278763902 4.95234489346\n",
      "Iteration 300 - loss is 7.76863092081 - parameters are 1.99895487533 8.0029918864 4.95212984777\n",
      "Iteration 400 - loss is 9.57465603191 - parameters are 2.00258150729 8.00898126522 4.95252505061\n",
      "Iteration 500 - loss is 8.75110998066 - parameters are 1.99414212948 7.99810745225 4.95142111751\n",
      "Iteration 600 - loss is 7.99275536582 - parameters are 2.00540220526 8.00774277758 4.95277075895\n",
      "Iteration 700 - loss is 9.20382906312 - parameters are 2.00384553968 8.00588456441 4.9524383662\n",
      "Iteration 800 - loss is 7.15434361589 - parameters are 2.00501467041 8.01107645575 4.95286044357\n",
      "Iteration 900 - loss is 8.50402274839 - parameters are 2.00343954688 8.00693255984 4.95240768887\n",
      "Iteration 1000 - loss is 10.9213958809 - parameters are 2.008579572 8.01144569027 4.95334216459\n",
      "Epoch 373\n",
      "Iteration 100 - loss is 8.59727339815 - parameters are 1.99854727345 8.00279325425 4.95223455369\n",
      "Iteration 200 - loss is 9.66614966825 - parameters are 2.00081929786 8.00277362247 4.95254310751\n",
      "Iteration 300 - loss is 7.76883757734 - parameters are 1.99894277131 8.00297893982 4.95232792562\n",
      "Iteration 400 - loss is 9.57508790569 - parameters are 2.00256865772 8.00896801545 4.95272276458\n",
      "Iteration 500 - loss is 8.75076767785 - parameters are 1.9941295285 7.9980944361 4.95161861463\n",
      "Iteration 600 - loss is 7.99276323355 - parameters are 2.00538877949 8.00772915795 4.95296781731\n",
      "Iteration 700 - loss is 9.20402227588 - parameters are 2.00383215064 8.00587095498 4.95263514265\n",
      "Iteration 800 - loss is 7.15437651403 - parameters are 2.00500124492 8.01106262912 4.95305687219\n",
      "Iteration 900 - loss is 8.50412796943 - parameters are 2.00342694601 8.00691932876 4.9526038996\n",
      "Iteration 1000 - loss is 10.9208074687 - parameters are 2.00856609757 8.01143137434 4.95353793431\n",
      "Epoch 374\n",
      "Iteration 100 - loss is 8.596851657 - parameters are 1.99853585804 8.00278104113 4.95243024808\n",
      "Iteration 200 - loss is 9.66580320554 - parameters are 2.00080627113 8.00275982636 4.95273820381\n",
      "Iteration 300 - loss is 7.76904154104 - parameters are 1.99893085778 8.00296619688 4.95252288786\n",
      "Iteration 400 - loss is 9.57551356054 - parameters are 2.00255601035 8.00895497408 4.95291736866\n",
      "Iteration 500 - loss is 8.75043124411 - parameters are 1.99411712581 7.99808162468 4.95181300528\n",
      "Iteration 600 - loss is 7.99277163547 - parameters are 2.00537556498 8.00771575254 4.95316177611\n",
      "Iteration 700 - loss is 9.2042129991 - parameters are 2.0038189723 8.00585755962 4.95282882398\n",
      "Iteration 800 - loss is 7.15440952828 - parameters are 2.00498803068 8.01104901997 4.95325021115\n",
      "Iteration 900 - loss is 8.50423214299 - parameters are 2.00341454343 8.0069063058 4.95279702411\n",
      "Iteration 1000 - loss is 10.9202289047 - parameters are 2.00855283516 8.01141728359 4.95373062474\n",
      "Epoch 375\n",
      "Iteration 100 - loss is 8.59643726544 - parameters are 1.99852462227 8.00276902011 4.95262286437\n",
      "Iteration 200 - loss is 9.66546296498 - parameters are 2.00079344938 8.00274624724 4.95293023142\n",
      "Iteration 300 - loss is 7.76924283687 - parameters are 1.99891913172 8.00295365438 4.95271478354\n",
      "Iteration 400 - loss is 9.57593307642 - parameters are 2.00254356198 8.00894213781 4.95310891181\n",
      "Iteration 500 - loss is 8.75010057192 - parameters are 1.99410491828 7.99806901478 4.95200433835\n",
      "Iteration 600 - loss is 7.99278054264 - parameters are 2.00536255839 8.00770255797 4.95335268412\n",
      "Iteration 700 - loss is 9.20440125483 - parameters are 2.00380600131 8.00584437496 4.9530194589\n",
      "Iteration 800 - loss is 7.15444263703 - parameters are 2.00497502437 8.01103562486 4.9534405091\n",
      "Iteration 900 - loss is 8.50433526659 - parameters are 2.00340233601 8.00689348767 4.95298711097\n",
      "Iteration 1000 - loss is 10.9196600155 - parameters are 2.00853978143 8.01140341446 4.95392028436\n",
      "Epoch 376\n",
      "Iteration 100 - loss is 8.59603008543 - parameters are 1.99851356331 8.00275718819 4.95281245101\n",
      "Iteration 200 - loss is 9.66512882452 - parameters are 2.00078082937 8.00273288168 4.95311923864\n",
      "Iteration 300 - loss is 7.76944148997 - parameters are 1.99890759018 8.00294130916 4.9529036609\n",
      "Iteration 400 - loss is 9.57634653259 - parameters are 2.00253130948 8.00892950344 4.95329744219\n",
      "Iteration 500 - loss is 8.74977555596 - parameters are 1.99409290284 7.99805660322 4.95219266197\n",
      "Iteration 600 - loss is 7.9927899272 - parameters are 2.00534975644 8.00768957092 4.95354058937\n",
      "Iteration 700 - loss is 9.20458706526 - parameters are 2.00379323443 8.00583139768 4.95320709534\n",
      "Iteration 800 - loss is 7.15447581965 - parameters are 2.00496222272 8.01102244045 4.95362781387\n",
      "Iteration 900 - loss is 8.50443733838 - parameters are 2.00339032067 8.00688087116 4.95317420799\n",
      "Iteration 1000 - loss is 10.9191006309 - parameters are 2.0085269331 8.01138976346 4.95410696085\n",
      "Epoch 377\n",
      "Iteration 100 - loss is 8.59562998185 - parameters are 1.99850267837 8.00274554237 4.95299905568\n",
      "Iteration 200 - loss is 9.66480066481 - parameters are 2.00076840793 8.00271972632 4.95330527302\n",
      "Iteration 300 - loss is 7.76963752559 - parameters are 1.99889623026 8.00292915811 4.95308956746\n",
      "Iteration 400 - loss is 9.5767540076 - parameters are 2.00251924977 8.00891706777 4.95348300723\n",
      "Iteration 500 - loss is 8.74945609299 - parameters are 1.99408107647 7.99804438689 4.9523780235\n",
      "Iteration 600 - loss is 7.99279976239 - parameters are 2.00533715593 8.00767678813 4.9537255391\n",
      "Iteration 700 - loss is 9.2047704528 - parameters are 2.00378066844 8.00581862452 4.95339178051\n",
      "Iteration 800 - loss is 7.15450905641 - parameters are 2.00494962248 8.0110094634 4.95381217259\n",
      "Iteration 900 - loss is 8.50453835712 - parameters are 2.00337849439 8.00686845309 4.95335836222\n",
      "Iteration 1000 - loss is 10.9185505839 - parameters are 2.00851428692 8.01137632717 4.95429070118\n",
      "Epoch 378\n",
      "Iteration 100 - loss is 8.59523682236 - parameters are 1.99849196472 8.00273407973 4.95318272532\n",
      "Iteration 200 - loss is 9.66447836908 - parameters are 2.00075618193 8.00270677787 4.95348838132\n",
      "Iteration 300 - loss is 7.7698309691 - parameters are 1.9988850491 8.00291719819 4.95327254996\n",
      "Iteration 400 - loss is 9.57715557928 - parameters are 2.00250737981 8.00890482768 4.95366565358\n",
      "Iteration 500 - loss is 8.74914208187 - parameters are 1.99406943619 7.9980323627 4.95256046955\n",
      "Iteration 600 - loss is 7.99281002243 - parameters are 2.00532475367 8.00766420638 4.95390757984\n",
      "Iteration 700 - loss is 9.20495143998 - parameters are 2.00376830017 8.00580605227 4.95357356085\n",
      "Iteration 800 - loss is 7.15454232849 - parameters are 2.00493722051 8.01099669045 4.95399363161\n",
      "Iteration 900 - loss is 8.50463832214 - parameters are 2.00336685419 8.00685623034 4.95353961998\n",
      "Iteration 1000 - loss is 10.9180097108 - parameters are 2.00850183972 8.0113631022 4.95447155154\n",
      "Epoch 379\n",
      "Iteration 100 - loss is 8.59485047734 - parameters are 1.99848141965 8.00272279739 4.95336350611\n",
      "Iteration 200 - loss is 9.66416182314 - parameters are 2.00074414828 8.00269403305 4.95366860961\n",
      "Iteration 300 - loss is 7.77002184596 - parameters are 1.99887404387 8.00290542637 4.95345265443\n",
      "Iteration 400 - loss is 9.57755132477 - parameters are 2.00249569661 8.0088927801 4.95384542719\n",
      "Iteration 500 - loss is 8.74883342346 - parameters are 1.99405797907 7.99802052764 4.952740046\n",
      "Iteration 600 - loss is 7.99282068255 - parameters are 2.00531254654 8.00765182251 4.95408675736\n",
      "Iteration 700 - loss is 9.20513004947 - parameters are 2.0037561265 8.00579367776 4.95375248207\n",
      "Iteration 800 - loss is 7.1545756179 - parameters are 2.00492501367 8.0109841184 4.95417223657\n",
      "Iteration 900 - loss is 8.50473723332 - parameters are 2.00335539715 8.00684419984 4.95371802684\n",
      "Iteration 1000 - loss is 10.9174778508 - parameters are 2.00848958836 8.01135008522 4.95464955742\n",
      "Epoch 380\n",
      "Iteration 100 - loss is 8.59447081989 - parameters are 1.99847104051 8.00271169251 4.95354144351\n",
      "Iteration 200 - loss is 9.66385091526 - parameters are 2.00073230397 8.00268148867 4.9538460032\n",
      "Iteration 300 - loss is 7.77021018171 - parameters are 1.99886321182 8.00289383971 4.95362992616\n",
      "Iteration 400 - loss is 9.57794132046 - parameters are 2.00248419723 8.00888092199 4.95402237326\n",
      "Iteration 500 - loss is 8.74853002063 - parameters are 1.99404670222 7.99800887873 4.95291679803\n",
      "Iteration 600 - loss is 7.99283171894 - parameters are 2.00530053147 8.0076396334 4.95426311672\n",
      "Iteration 700 - loss is 9.20530630404 - parameters are 2.00374414438 8.00578149788 4.95392858917\n",
      "Iteration 800 - loss is 7.15460890751 - parameters are 2.00491299889 8.01097174409 4.95434803239\n",
      "Iteration 900 - loss is 8.50483509107 - parameters are 2.00334412037 8.00683235855 4.95389362767\n",
      "Iteration 1000 - loss is 10.9169548464 - parameters are 2.00847752976 8.01133727298 4.95482476358\n",
      "Epoch 381\n",
      "Iteration 100 - loss is 8.59409772568 - parameters are 1.99846082469 8.00270076229 4.95371658227\n",
      "Iteration 200 - loss is 9.66354553613 - parameters are 2.00072064601 8.00266914157 4.95402060671\n",
      "Iteration 300 - loss is 7.77039600195 - parameters are 1.9988525502 8.00288243529 4.95380440972\n",
      "Iteration 400 - loss is 9.57832564202 - parameters are 2.00247287878 8.00886925038 4.95419653629\n",
      "Iteration 500 - loss is 8.74823177813 - parameters are 1.9940356028 7.99799741304 4.95309077007\n",
      "Iteration 600 - loss is 7.99284310869 - parameters are 2.00528870543 8.007627636 4.95443670228\n",
      "Iteration 700 - loss is 9.20548022658 - parameters are 2.00373235079 8.00576950957 4.95410192643\n",
      "Iteration 800 - loss is 7.15464218096 - parameters are 2.00490117314 8.01095956439 4.95452106326\n",
      "Iteration 900 - loss is 8.50493189628 - parameters are 2.00333302102 8.00682070351 4.95406646663\n",
      "Iteration 1000 - loss is 10.9164405428 - parameters are 2.00846566088 8.01132466224 4.95499721408\n",
      "Epoch 382\n",
      "Iteration 100 - loss is 8.59373107297 - parameters are 1.99845076961 8.00269000399 4.95388896643\n",
      "Iteration 200 - loss is 9.66324557882 - parameters are 2.00070917147 8.00265698866 4.95419246404\n",
      "Iteration 300 - loss is 7.77057933233 - parameters are 1.99884205634 8.00287121023 4.95397614899\n",
      "Iteration 400 - loss is 9.5787043644 - parameters are 2.0024617384 8.00885776233 4.95436796008\n",
      "Iteration 500 - loss is 8.74793860267 - parameters are 1.99402467802 7.99798612768 4.95326200586\n",
      "Iteration 600 - loss is 7.9928548298 - parameters are 2.00527706545 8.00761582728 4.95460755768\n",
      "Iteration 700 - loss is 9.20565184006 - parameters are 2.00372074275 8.00575770982 4.95427253744\n",
      "Iteration 800 - loss is 7.15467542267 - parameters are 2.00488953346 8.01094757625 4.95469137271\n",
      "Iteration 900 - loss is 8.50502765035 - parameters are 2.00332209631 8.00680923177 4.95423658719\n",
      "Iteration 1000 - loss is 10.9159347884 - parameters are 2.00845397874 8.01131224983 4.95516695228\n",
      "Epoch 383\n",
      "Iteration 100 - loss is 8.5933707425 - parameters are 1.99844087274 8.0026794149 4.95405863935\n",
      "Iteration 200 - loss is 9.66295093869 - parameters are 2.00069787745 8.00264502686 4.95436161841\n",
      "Iteration 300 - loss is 7.77076019852 - parameters are 1.9988317276 8.00286016172 4.95414518717\n",
      "Iteration 400 - loss is 9.5790775618 - parameters are 2.0024507733 8.00884645495 4.95453668772\n",
      "Iteration 500 - loss is 8.74765040274 - parameters are 1.99401392512 7.99797501982 4.95343054848\n",
      "Iteration 600 - loss is 7.99286686113 - parameters are 2.00526560861 8.00760420427 4.95477572588\n",
      "Iteration 700 - loss is 9.20582116749 - parameters are 2.00370931735 8.00574609565 4.9544404651\n",
      "Iteration 800 - loss is 7.1547086178 - parameters are 2.0048780769 8.01093577666 4.95485900355\n",
      "Iteration 900 - loss is 8.50512235508 - parameters are 2.00331134348 8.00679794047 4.95440403211\n",
      "Iteration 1000 - loss is 10.9154374342 - parameters are 2.00844248039 8.01130003263 4.95533402087\n",
      "Epoch 384\n",
      "Iteration 100 - loss is 8.59301661743 - parameters are 1.9984311316 8.00266899237 4.95422564368\n",
      "Iteration 200 - loss is 9.66266151338 - parameters are 2.00068676112 8.00263325319 4.95452811235\n",
      "Iteration 300 - loss is 7.77093862622 - parameters are 1.99882156137 8.00284928699 4.95431156674\n",
      "Iteration 400 - loss is 9.57944530771 - parameters are 2.00243998071 8.0088353254 4.95470276165\n",
      "Iteration 500 - loss is 8.74736708868 - parameters are 1.99400334141 7.99796408667 4.9535964403\n",
      "Iteration 600 - loss is 7.99287918236 - parameters are 2.005254332 8.00759276406 4.95494124917\n",
      "Iteration 700 - loss is 9.20598823197 - parameters are 2.00369807171 8.00573466415 4.95460575164\n",
      "Iteration 800 - loss is 7.15474175221 - parameters are 2.00486680059 8.01092416264 4.95502399794\n",
      "Iteration 900 - loss is 8.50521601275 - parameters are 2.00330075982 8.00678682675 4.95456884351\n",
      "Iteration 1000 - loss is 10.9149483342 - parameters are 2.00843116294 8.01128800758 4.95549846185\n",
      "Epoch 385\n",
      "Iteration 100 - loss is 8.59266858332 - parameters are 1.99842154372 8.00265873376 4.95439002141\n",
      "Iteration 200 - loss is 9.66237720269 - parameters are 2.00067581967 8.00262166467 4.95469198772\n",
      "Iteration 300 - loss is 7.77111464113 - parameters are 1.99881155509 8.00283858328 4.95447532955\n",
      "Iteration 400 - loss is 9.57980767485 - parameters are 2.00242935792 8.00882437088 4.95486622363\n",
      "Iteration 500 - loss is 8.7470885726 - parameters are 1.99399292422 7.99795332547 4.95375972303\n",
      "Iteration 600 - loss is 7.99289177398 - parameters are 2.0052432328 8.00758150376 4.95510416917\n",
      "Iteration 700 - loss is 9.20615305661 - parameters are 2.003687003 8.00572341245 4.95476843861\n",
      "Iteration 800 - loss is 7.15477481248 - parameters are 2.00485570169 8.01091273128 4.95518639737\n",
      "Iteration 900 - loss is 8.50530862603 - parameters are 2.00329034268 8.00677588782 4.95473106282\n",
      "Iteration 1000 - loss is 10.9144673449 - parameters are 2.00842002355 8.01127617164 4.95566031658\n",
      "Epoch 386\n",
      "Iteration 100 - loss is 8.59232652806 - parameters are 1.99841210669 8.0026486365 4.95455181389\n",
      "Iteration 200 - loss is 9.66209790859 - parameters are 2.00066505036 8.00261025839 4.95485328574\n",
      "Iteration 300 - loss is 7.77128826893 - parameters are 1.99880170625 8.00282804792 4.95463651677\n",
      "Iteration 400 - loss is 9.58016473523 - parameters are 2.00241890225 8.00881358863 4.95502711475\n",
      "Iteration 500 - loss is 8.7468147683 - parameters are 1.99398267092 7.99794273352 4.95392043773\n",
      "Iteration 600 - loss is 7.99290461724 - parameters are 2.00523230822 8.00757042055 4.95526452684\n",
      "Iteration 700 - loss is 9.20631566456 - parameters are 2.00367610843 8.0057123377 4.95492856693\n",
      "Iteration 800 - loss is 7.1548077858 - parameters are 2.0048447774 8.0109014797 4.95534624266\n",
      "Iteration 900 - loss is 8.50540019797 - parameters are 2.00328008943 8.00676512094 4.95489073083\n",
      "Iteration 1000 - loss is 10.9139943257 - parameters are 2.0084090594 8.01126452185 4.95581962574\n",
      "Epoch 387\n",
      "Iteration 100 - loss is 8.59199034181 - parameters are 1.99840281815 8.00263869804 4.95471106178\n",
      "Iteration 200 - loss is 9.66182353512 - parameters are 2.00065445048 8.0025990315 4.95501204695\n",
      "Iteration 300 - loss is 7.7714595353 - parameters are 1.99879201237 8.00281767825 4.95479516894\n",
      "Iteration 400 - loss is 9.5805165601 - parameters are 2.00240861107 8.00880297596 4.95518547547\n",
      "Iteration 500 - loss is 8.74654559131 - parameters are 1.99397257894 7.99793230815 4.95407862481\n",
      "Iteration 600 - loss is 7.99291769415 - parameters are 2.0052215555 8.00755951165 4.95542236251\n",
      "Iteration 700 - loss is 9.20647607898 - parameters are 2.00366538526 8.00570143714 4.95508617685\n",
      "Iteration 800 - loss is 7.15484066004 - parameters are 2.00483402498 8.01089040508 4.955503574\n",
      "Iteration 900 - loss is 8.50549073199 - parameters are 2.00326999749 8.00675452339 4.95504788769\n",
      "Iteration 1000 - loss is 10.9135291385 - parameters are 2.00839826774 8.01125305527 4.95597642939\n",
      "Epoch 388\n",
      "Iteration 100 - loss is 8.59165991695 - parameters are 1.99839367574 8.0026289159 4.95486780513\n",
      "Iteration 200 - loss is 9.66155398839 - parameters are 2.00064401734 8.00258798115 4.95516831128\n",
      "Iteration 300 - loss is 7.77162846586 - parameters are 1.998782471 8.00280747167 4.95495132594\n",
      "Iteration 400 - loss is 9.58086321999 - parameters are 2.00239848179 8.00879253018 4.95534134561\n",
      "Iteration 500 - loss is 8.7462809588 - parameters are 1.99396264573 7.99792204675 4.95423432403\n",
      "Iteration 600 - loss is 7.99293098744 - parameters are 2.00521097194 8.00754877429 4.95557771586\n",
      "Iteration 700 - loss is 9.20663432303 - parameters are 2.0036548308 8.00569070801 4.95524130801\n",
      "Iteration 800 - loss is 7.15487342367 - parameters are 2.00482344171 8.01087950462 4.95565843096\n",
      "Iteration 900 - loss is 8.50558023189 - parameters are 2.00326006433 8.00674409251 4.95520257291\n",
      "Iteration 1000 - loss is 10.9130716479 - parameters are 2.00838764585 8.01124176902 4.95613076696\n",
      "Epoch 389\n",
      "Iteration 100 - loss is 8.59133514802 - parameters are 1.99838467718 8.00261928761 4.95502208335\n",
      "Iteration 200 - loss is 9.66128917647 - parameters are 2.00063374834 8.00257710459 4.95532211801\n",
      "Iteration 300 - loss is 7.7717950862 - parameters are 1.99877307975 8.00279742562 4.95510502703\n",
      "Iteration 400 - loss is 9.58120478468 - parameters are 2.00238851187 8.00878224867 4.95549476435\n",
      "Iteration 500 - loss is 8.74602078956 - parameters are 1.9939528688 7.99791194674 4.95438757456\n",
      "Iteration 600 - loss is 7.99294448054 - parameters are 2.00520055488 8.0075382058 4.95573062594\n",
      "Iteration 700 - loss is 9.20679041985 - parameters are 2.00364444238 8.00568014762 4.95539399939\n",
      "Iteration 800 - loss is 7.15490606573 - parameters are 2.00481302494 8.0108687756 4.95581085247\n",
      "Iteration 900 - loss is 8.50566870176 - parameters are 2.00325028743 8.00673382568 4.95535482538\n",
      "Iteration 1000 - loss is 10.9126217209 - parameters are 2.00837719107 8.01123066026 4.95628267725\n",
      "Epoch 390\n",
      "Iteration 100 - loss is 8.5910159317 - parameters are 1.99837582018 8.00260981075 4.95517393522\n",
      "Iteration 200 - loss is 9.66102900941 - parameters are 2.00062364089 8.00256639907 4.9554735058\n",
      "Iteration 300 - loss is 7.77195942187 - parameters are 1.99876383624 8.00278753755 4.95525631086\n",
      "Iteration 400 - loss is 9.58154132319 - parameters are 2.00237869879 8.00877212886 4.95564577027\n",
      "Iteration 500 - loss is 8.74576500394 - parameters are 1.99394324568 7.99790200557 4.9545384149\n",
      "Iteration 600 - loss is 7.99295815755 - parameters are 2.00519030169 8.00752780351 4.9558811312\n",
      "Iteration 700 - loss is 9.20694439258 - parameters are 2.00363421739 8.00566975332 4.9555442894\n",
      "Iteration 800 - loss is 7.15493857587 - parameters are 2.00480277204 8.01085821531 4.95596087685\n",
      "Iteration 900 - loss is 8.50575614603 - parameters are 2.00324066434 8.00672372031 4.95550468338\n",
      "Iteration 1000 - loss is 10.9121792268 - parameters are 2.00836690075 8.01121972621 4.95643219845\n",
      "Epoch 391\n",
      "Iteration 100 - loss is 8.59070216674 - parameters are 1.99836710254 8.00260048293 4.95532339892\n",
      "Iteration 200 - loss is 9.66077339914 - parameters are 2.00061369244 8.0025558619 4.95562251274\n",
      "Iteration 300 - loss is 7.77212149833 - parameters are 1.99875473817 8.002777805 4.95540521545\n",
      "Iteration 400 - loss is 9.58187290384 - parameters are 2.00236904008 8.00876216818 4.95579440133\n",
      "Iteration 500 - loss is 8.74551352387 - parameters are 1.99393377395 7.99789222075 4.95468688299\n",
      "Iteration 600 - loss is 7.9929720032 - parameters are 2.00518020979 8.00751756481 4.95602926948\n",
      "Iteration 700 - loss is 9.20709626431 - parameters are 2.00362415326 8.00565952249 4.95569221582\n",
      "Iteration 800 - loss is 7.15497094425 - parameters are 2.00479268044 8.01084782109 4.95610854181\n",
      "Iteration 900 - loss is 8.50584256942 - parameters are 2.00323119265 8.00671377388 4.95565218458\n",
      "Iteration 1000 - loss is 10.9117440378 - parameters are 2.00835677232 8.01120896411 4.95657936815\n",
      "Epoch 392\n",
      "Iteration 100 - loss is 8.59039375391 - parameters are 1.99835852204 8.00259130182 4.95547051203\n",
      "Iteration 200 - loss is 9.66052225944 - parameters are 2.00060390049 8.00254549043 4.95576917626\n",
      "Iteration 300 - loss is 7.77228134097 - parameters are 1.99874578322 8.00276822551 4.95555177825\n",
      "Iteration 400 - loss is 9.58219959417 - parameters are 2.00235953332 8.00875236415 4.9559406949\n",
      "Iteration 500 - loss is 8.74526627278 - parameters are 1.99392445124 7.99788258981 4.95483301616\n",
      "Iteration 600 - loss is 7.99298600287 - parameters are 2.00517027665 8.00750748712 4.95617507802\n",
      "Iteration 700 - loss is 9.20724605811 - parameters are 2.00361424746 8.00564945256 4.95583781583\n",
      "Iteration 800 - loss is 7.15500316156 - parameters are 2.0047827476 8.01083759034 4.95625388448\n",
      "Iteration 900 - loss is 8.50592797694 - parameters are 2.00322186996 8.00670398387 4.95579736606\n",
      "Iteration 1000 - loss is 10.9113160279 - parameters are 2.00834680321 8.01119837125 4.95672422336\n",
      "Epoch 393\n",
      "Iteration 100 - loss is 8.59009059598 - parameters are 1.99835007653 8.0025822651 4.95561531154\n",
      "Iteration 200 - loss is 9.66027550592 - parameters are 2.00059426258 8.00253528207 4.95591353325\n",
      "Iteration 300 - loss is 7.77243897511 - parameters are 1.99873696916 8.00275879667 4.9556960361\n",
      "Iteration 400 - loss is 9.58252146101 - parameters are 2.00235017611 8.0087427143 4.95608468775\n",
      "Iteration 500 - loss is 8.74502317558 - parameters are 1.99391527518 7.99787311034 4.95497685113\n",
      "Iteration 600 - loss is 7.99300014253 - parameters are 2.00516049977 8.00749756791 4.95631859347\n",
      "Iteration 700 - loss is 9.20739379696 - parameters are 2.00360449749 8.00563954099 4.95598112604\n",
      "Iteration 800 - loss is 7.15503521902 - parameters are 2.004772971 8.01082752048 4.95639694139\n",
      "Iteration 900 - loss is 8.50601237387 - parameters are 2.00321269392 8.00669434782 4.95594026433\n",
      "Iteration 1000 - loss is 10.9108950739 - parameters are 2.00833699093 8.01118794498 4.95686680048\n",
      "Epoch 394\n",
      "Iteration 100 - loss is 8.58979259763 - parameters are 1.9983417639 8.0025733705 4.95575783384\n",
      "Iteration 200 - loss is 9.66003305593 - parameters are 2.00058477627 8.00252523423 4.95605561999\n",
      "Iteration 300 - loss is 7.77259442598 - parameters are 1.99872829376 8.00274951612 4.95583802527\n",
      "Iteration 400 - loss is 9.58283857045 - parameters are 2.0023409661 8.00873321619 4.95622641609\n",
      "Iteration 500 - loss is 8.74478415863 - parameters are 1.99390624348 7.99786377995 4.95511842408\n",
      "Iteration 600 - loss is 7.99301440875 - parameters are 2.00515087668 8.00748780469 4.95645985192\n",
      "Iteration 700 - loss is 9.20753950382 - parameters are 2.0035949009 8.00562978531 4.95612218247\n",
      "Iteration 800 - loss is 7.15506710832 - parameters are 2.00476334821 8.01081760899 4.95653774852\n",
      "Iteration 900 - loss is 8.50609576571 - parameters are 2.00320366224 8.00668486331 4.95608091531\n",
      "Iteration 1000 - loss is 10.9104810546 - parameters are 2.00832733301 8.01117768267 4.95700713536\n",
      "Epoch 395\n",
      "Iteration 100 - loss is 8.58949966546 - parameters are 1.99833358203 8.00256461579 4.95589811476\n",
      "Iteration 200 - loss is 9.65979482858 - parameters are 2.0005754392 8.0025153444 4.95619547221\n",
      "Iteration 300 - loss is 7.77274771868 - parameters are 1.99871975484 8.00274038151 4.95597778145\n",
      "Iteration 400 - loss is 9.58315098783 - parameters are 2.00233190097 8.00872386745 4.95636591554\n",
      "Iteration 500 - loss is 8.74454914971 - parameters are 1.99389735385 7.9978545963 4.95525777058\n",
      "Iteration 600 - loss is 7.99302878865 - parameters are 2.00514140497 8.007478195 4.95659888888\n",
      "Iteration 700 - loss is 9.20768320156 - parameters are 2.00358545528 8.00562018304 4.95626102059\n",
      "Iteration 800 - loss is 7.15509882162 - parameters are 2.00475387679 8.01080785336 4.95667634125\n",
      "Iteration 900 - loss is 8.50617815823 - parameters are 2.00319477264 8.00667552796 4.95621935435\n",
      "Iteration 1000 - loss is 10.9100738509 - parameters are 2.00831782701 8.01116758175 4.95714526327\n",
      "Epoch 396\n",
      "Iteration 100 - loss is 8.58921170792 - parameters are 1.99832552888 8.00255599876 4.95603618957\n",
      "Iteration 200 - loss is 9.65956074463 - parameters are 2.000566249 8.00250561009 4.95633312506\n",
      "Iteration 300 - loss is 7.77289887824 - parameters are 1.99871135026 8.00273139057 4.95611533976\n",
      "Iteration 400 - loss is 9.58345877777 - parameters are 2.00232297843 8.00871466573 4.95650322117\n",
      "Iteration 500 - loss is 8.74431807798 - parameters are 1.99388860408 7.99784555707 4.95539492567\n",
      "Iteration 600 - loss is 7.99304326988 - parameters are 2.00513208225 8.00746873643 4.95673573929\n",
      "Iteration 700 - loss is 9.20782491299 - parameters are 2.00357615824 8.00561073179 4.95639767529\n",
      "Iteration 800 - loss is 7.15513035152 - parameters are 2.00474455436 8.01079825115 4.95681275443\n",
      "Iteration 900 - loss is 8.50625955742 - parameters are 2.00318602288 8.00666633943 4.95635561626\n",
      "Iteration 1000 - loss is 10.9096733463 - parameters are 2.00830847054 8.01115763967 4.95728121895\n",
      "Epoch 397\n",
      "Iteration 100 - loss is 8.58892863526 - parameters are 1.99831760242 8.00254751725 4.95617209297\n",
      "Iteration 200 - loss is 9.65933072653 - parameters are 2.00055720336 8.00249602886 4.95646861314\n",
      "Iteration 300 - loss is 7.77304792956 - parameters are 1.99870307789 8.00272254101 4.95625073481\n",
      "Iteration 400 - loss is 9.58376200417 - parameters are 2.00231419626 8.0087056087 4.9566383675\n",
      "Iteration 500 - loss is 8.74409087397 - parameters are 1.99387999194 7.99783666 4.95552992383\n",
      "Iteration 600 - loss is 7.99305784063 - parameters are 2.00512290618 8.0074594266 4.95687043757\n",
      "Iteration 700 - loss is 9.20796466081 - parameters are 2.00356700745 8.00560142917 4.95653218094\n",
      "Iteration 800 - loss is 7.15516169108 - parameters are 2.00473537857 8.01078879995 4.95694702235\n",
      "Iteration 900 - loss is 8.50633996946 - parameters are 2.00317741076 8.00665729539 4.95648973528\n",
      "Iteration 1000 - loss is 10.9092794261 - parameters are 2.00829926126 8.01114785394 4.95741503656\n",
      "Epoch 398\n",
      "Iteration 100 - loss is 8.58865035949 - parameters are 1.99830980065 8.00253916912 4.95630585914\n",
      "Iteration 200 - loss is 9.65910469828 - parameters are 2.00054830001 8.00248659829 4.95660197051\n",
      "Iteration 300 - loss is 7.77319489741 - parameters are 1.99869493565 8.00271383063 4.9563840006\n",
      "Iteration 400 - loss is 9.58406073017 - parameters are 2.00230555223 8.0086966941 4.95677138849\n",
      "Iteration 500 - loss is 8.74386746953 - parameters are 1.99387151528 7.99782790285 4.95566279899\n",
      "Iteration 600 - loss is 7.9930724896 - parameters are 2.00511387444 8.00745026318 4.95700301755\n",
      "Iteration 700 - loss is 9.20810246765 - parameters are 2.00355800062 8.00559227285 4.95666457133\n",
      "Iteration 800 - loss is 7.15519283375 - parameters are 2.00472634713 8.01077949737 4.95707917875\n",
      "Iteration 900 - loss is 8.50641940075 - parameters are 2.00316893411 8.00664839359 4.95662174513\n",
      "Iteration 1000 - loss is 10.9088919778 - parameters are 2.00829019683 8.01113822209 4.95754674974\n",
      "Epoch 399\n",
      "Iteration 100 - loss is 8.5883767944 - parameters are 1.99830212161 8.00253095228 4.95643752168\n",
      "Iteration 200 - loss is 9.65888258551 - parameters are 2.00053953671 8.00247731601 4.95673323069\n",
      "Iteration 300 - loss is 7.77333980644 - parameters are 1.9986869215 8.00270525722 4.95651517065\n",
      "Iteration 400 - loss is 9.58435501821 - parameters are 2.00229704417 8.00868791969 4.95690231759\n",
      "Iteration 500 - loss is 8.74364779781 - parameters are 1.99386317197 7.99781928341 4.95579358454\n",
      "Iteration 600 - loss is 7.99308720597 - parameters are 2.00510498478 8.00744124385 4.95713351258\n",
      "Iteration 700 - loss is 9.20823835604 - parameters are 2.00354913546 8.00558326052 4.95679487975\n",
      "Iteration 800 - loss is 7.15522377341 - parameters are 2.00471745775 8.01077034108 4.95720925687\n",
      "Iteration 900 - loss is 8.50649785785 - parameters are 2.0031605908 8.00663963177 4.956751679\n",
      "Iteration 1000 - loss is 10.9085108908 - parameters are 2.00828127499 8.01112874171 4.9576763916\n",
      "Epoch 400\n",
      "Iteration 100 - loss is 8.58810785542 - parameters are 1.99829456338 8.00252286466 4.95656711371\n",
      "Iteration 200 - loss is 9.65866431535 - parameters are 2.00053091126 8.0024681797 4.95686242668\n",
      "Iteration 300 - loss is 7.77348268116 - parameters are 1.99867903342 8.00269681864 4.95664427793\n",
      "Iteration 400 - loss is 9.58464493001 - parameters are 2.00228866994 8.00867928325 4.9570311877\n",
      "Iteration 500 - loss is 8.74343179325 - parameters are 1.9938549599 7.99781079953 4.95592231337\n",
      "Iteration 600 - loss is 7.99310197938 - parameters are 2.00509623494 8.00743236635 4.95726195546\n",
      "Iteration 700 - loss is 9.2083723484 - parameters are 2.00354040975 8.00557438992 4.95692313895\n",
      "Iteration 800 - loss is 7.15525450428 - parameters are 2.0047087082 8.01076132879 4.95733728938\n",
      "Iteration 900 - loss is 8.50657534751 - parameters are 2.00315237874 8.00663100774 4.95687956954\n",
      "Iteration 1000 - loss is 10.9081360569 - parameters are 2.00827249349 8.01111941041 4.95780399473\n",
      "Epoch 401\n",
      "Iteration 100 - loss is 8.58784345966 - parameters are 1.99828712404 8.00251490423 4.95669466778\n",
      "Iteration 200 - loss is 9.65844981644 - parameters are 2.00052242148 8.00245918706 4.95698959095\n",
      "Iteration 300 - loss is 7.77362354596 - parameters are 1.99867126942 8.00268851277 4.95677135489\n",
      "Iteration 400 - loss is 9.58493052655 - parameters are 2.00228042744 8.00867078262 4.95715803123\n",
      "Iteration 500 - loss is 8.74321939152 - parameters are 1.993846877 7.99780244906 4.95604901784\n",
      "Iteration 600 - loss is 7.99311679993 - parameters are 2.00508762274 8.00742362845 4.95738837846\n",
      "Iteration 700 - loss is 9.20850446704 - parameters are 2.0035318213 8.00556565881 4.95704938116\n",
      "Iteration 800 - loss is 7.155285021 - parameters are 2.00470009627 8.01075245821 4.95746330849\n",
      "Iteration 900 - loss is 8.50665187665 - parameters are 2.00314429585 8.00662251933 4.9570054489\n",
      "Iteration 1000 - loss is 10.9077673694 - parameters are 2.00826385012 8.01111022585 4.9579295912\n",
      "Epoch 402\n",
      "Iteration 100 - loss is 8.58758352586 - parameters are 1.99827980172 8.00250706899 4.95682021597\n",
      "Iteration 200 - loss is 9.65823901887 - parameters are 2.00051406523 8.00245033583 4.95711475546\n",
      "Iteration 300 - loss is 7.77376242505 - parameters are 1.99866362756 8.00268033751 4.95689643346\n",
      "Iteration 400 - loss is 9.58521186812 - parameters are 2.00227231458 8.00866241567 4.95728288004\n",
      "Iteration 500 - loss is 8.74301052951 - parameters are 1.99383892125 7.99779422991 4.95617372978\n",
      "Iteration 600 - loss is 7.99313165816 - parameters are 2.00507914599 8.00741502795 4.95751281337\n",
      "Iteration 700 - loss is 9.20863473415 - parameters are 2.00352336795 8.00555706502 4.95717363813\n",
      "Iteration 800 - loss is 7.15531531853 - parameters are 2.00469161981 8.01074372713 4.95758734585\n",
      "Iteration 900 - loss is 8.50672745231 - parameters are 2.0031363401 8.00661416441 4.95712934872\n",
      "Iteration 1000 - loss is 10.9074047238 - parameters are 2.0082553427 8.01110118572 4.95805321258\n",
      "Epoch 403\n",
      "Iteration 100 - loss is 8.58732797434 - parameters are 1.99827259459 8.00249935696 4.95694378983\n",
      "Iteration 200 - loss is 9.65803185417 - parameters are 2.00050584043 8.00244162377 4.95723795168\n",
      "Iteration 300 - loss is 7.77389934251 - parameters are 1.9986561059 8.00267229081 4.95701954509\n",
      "Iteration 400 - loss is 9.58548901429 - parameters are 2.00226432934 8.00865418028 4.95740576552\n",
      "Iteration 500 - loss is 8.7428051453 - parameters are 1.99383109065 7.99778614002 4.95629648054\n",
      "Iteration 600 - loss is 7.99314654504 - parameters are 2.00507080258 8.0074065627 4.95763529147\n",
      "Iteration 700 - loss is 9.2087631718 - parameters are 2.00351504756 8.00554860636 4.95729594109\n",
      "Iteration 800 - loss is 7.15534539218 - parameters are 2.00468327669 8.01073513335 4.95770943265\n",
      "Iteration 900 - loss is 8.5068020817 - parameters are 2.0031285095 8.00660594087 4.95725130014\n",
      "Iteration 1000 - loss is 10.9070480175 - parameters are 2.0082469691 8.01109228775 4.95817488994\n",
      "Epoch 404\n",
      "Iteration 100 - loss is 8.58707672695 - parameters are 1.99826550083 8.00249176622 4.95706542042\n",
      "Iteration 200 - loss is 9.65782825528 - parameters are 2.000497745 8.00243304871 4.95735921057\n",
      "Iteration 300 - loss is 7.77403432228 - parameters are 1.99864870256 8.00266437066 4.95714072072\n",
      "Iteration 400 - loss is 9.58576202391 - parameters are 2.0022564697 8.0086460744 4.95752671856\n",
      "Iteration 500 - loss is 8.74260317816 - parameters are 1.99382338322 7.99777817734 4.95641730099\n",
      "Iteration 600 - loss is 7.99316145192 - parameters are 2.00506259041 8.00739823056 4.95775584352\n",
      "Iteration 700 - loss is 9.20888980194 - parameters are 2.00350685805 8.00554028073 4.95741632076\n",
      "Iteration 800 - loss is 7.1553752376 - parameters are 2.00467506479 8.01072667471 4.95782959957\n",
      "Iteration 900 - loss is 8.50687577215 - parameters are 2.00312080206 8.00659784665 4.95737133381\n",
      "Iteration 1000 - loss is 10.9066971497 - parameters are 2.00823872721 8.0110835297 4.95829465386\n",
      "Epoch 405\n",
      "Iteration 100 - loss is 8.58682970708 - parameters are 1.99825851866 8.00248429484 4.95718513831\n",
      "Iteration 200 - loss is 9.65762815649 - parameters are 2.00048977689 8.00242460849 4.9574785626\n",
      "Iteration 300 - loss is 7.7741673881 - parameters are 1.99864141568 8.00265657505 4.95725999081\n",
      "Iteration 400 - loss is 9.58603095514 - parameters are 2.00224873369 8.00863809597 4.95764576956\n",
      "Iteration 500 - loss is 8.74240456848 - parameters are 1.99381579702 7.99777033988 4.95653622147\n",
      "Iteration 600 - loss is 7.99317637056 - parameters are 2.0050545074 8.00739002944 4.95787449985\n",
      "Iteration 700 - loss is 9.20901464639 - parameters are 2.00349879736 8.00553208601 4.95753480741\n",
      "Iteration 800 - loss is 7.15540485074 - parameters are 2.00466698206 8.01071834908 4.95794787681\n",
      "Iteration 900 - loss is 8.5069485311 - parameters are 2.00311321587 8.00658987972 4.95748947991\n",
      "Iteration 1000 - loss is 10.9063520212 - parameters are 2.00823061495 8.01107490937 4.95841253445\n",
      "Epoch 406\n",
      "Iteration 100 - loss is 8.5865868396 - parameters are 1.99825164631 8.00247694096 4.95730297358\n",
      "Iteration 200 - loss is 9.65743149342 - parameters are 2.00048193412 8.00241630099 4.95759603778\n",
      "Iteration 300 - loss is 7.77429856358 - parameters are 1.99863424342 8.00264890203 4.95737738533\n",
      "Iteration 400 - loss is 9.58629586543 - parameters are 2.00224111935 8.00863024301 4.95776294844\n",
      "Iteration 500 - loss is 8.74220925778 - parameters are 1.99380833015 7.99776262567 4.95665327189\n",
      "Iteration 600 - loss is 7.9931912931 - parameters are 2.00504655153 8.00738195728 4.95799129026\n",
      "Iteration 700 - loss is 9.2091377268 - parameters are 2.00349086346 8.00552402017 4.95765143082\n",
      "Iteration 800 - loss is 7.15543422786 - parameters are 2.00465902646 8.01071015437 4.95806429411\n",
      "Iteration 900 - loss is 8.50702036612 - parameters are 2.00310574899 8.00658203807 4.95760576811\n",
      "Iteration 1000 - loss is 10.906012535 - parameters are 2.0082226303 8.01106642459 4.95852856132\n",
      "Epoch 407\n",
      "Iteration 100 - loss is 8.58634805082 - parameters are 1.99824488207 8.00246970272 4.95741895587\n",
      "Iteration 200 - loss is 9.65723820301 - parameters are 2.00047421471 8.00240812412 4.95771166562\n",
      "Iteration 300 - loss is 7.77442787214 - parameters are 1.99862718398 8.00264134967 4.95749293379\n",
      "Iteration 400 - loss is 9.58655681155 - parameters are 2.00223362478 8.00862251353 4.95787828464\n",
      "Iteration 500 - loss is 8.7420171887 - parameters are 1.99380098073 7.99775503277 4.95676848167\n",
      "Iteration 600 - loss is 7.99320621203 - parameters are 2.00503872079 8.00737401206 4.95810624411\n",
      "Iteration 700 - loss is 9.20925906473 - parameters are 2.00348305435 8.00551608116 4.9577662203\n",
      "Iteration 800 - loss is 7.1554633655 - parameters are 2.004651196 8.01070208853 4.95817888072\n",
      "Iteration 900 - loss is 8.50709128487 - parameters are 2.00309839957 8.00657431974 4.95772022766\n",
      "Iteration 1000 - loss is 10.9056785956 - parameters are 2.00821477123 8.01105807323 4.95864276365\n",
      "Epoch 408\n",
      "Iteration 100 - loss is 8.58611326849 - parameters are 1.99823822422 8.00246257831 4.9575331143\n",
      "Iteration 200 - loss is 9.65704822347 - parameters are 2.0004666167 8.00240007582 4.95782547519\n",
      "Iteration 300 - loss is 7.77455533704 - parameters are 1.99862023557 8.00263391607 4.95760666523\n",
      "Iteration 400 - loss is 9.58681384956 - parameters are 2.00222624809 8.00861490559 4.95799180717\n",
      "Iteration 500 - loss is 8.7418283049 - parameters are 1.99379374691 7.99774755927 4.95688187974\n",
      "Iteration 600 - loss is 7.9932211202 - parameters are 2.00503101322 8.00736619177 4.95821939029\n",
      "Iteration 700 - loss is 9.20937868156 - parameters are 2.00347536807 8.005508267 4.95787920469\n",
      "Iteration 800 - loss is 7.1554922605 - parameters are 2.00464348869 8.01069414952 4.95829166543\n",
      "Iteration 900 - loss is 8.5071612951 - parameters are 2.00309116574 8.00656672277 4.95783288732\n",
      "Iteration 1000 - loss is 10.9053501092 - parameters are 2.00820703577 8.0110498532 4.95875517013\n",
      "Epoch 409\n",
      "Iteration 100 - loss is 8.58588242174 - parameters are 1.9982316711 8.00245556593 4.95764547758\n",
      "Iteration 200 - loss is 9.65686149424 - parameters are 2.00045913821 8.00239215408 4.9579374951\n",
      "Iteration 300 - loss is 7.77468098137 - parameters are 1.99861339647 8.00262659937 4.95771860822\n",
      "Iteration 400 - loss is 9.58706703484 - parameters are 2.00221898743 8.00860741729 4.95810354453\n",
      "Iteration 500 - loss is 8.74164255115 - parameters are 1.99378662687 7.99774020329 4.95699349462\n",
      "Iteration 600 - loss is 7.9932360108 - parameters are 2.00502342687 8.00735849445 4.95833075724\n",
      "Iteration 700 - loss is 9.20949659852 - parameters are 2.00346780268 8.00550057571 4.9579904124\n",
      "Iteration 800 - loss is 7.15552090993 - parameters are 2.00463590262 8.01068633535 4.9584026766\n",
      "Iteration 900 - loss is 8.50723040466 - parameters are 2.00308404569 8.00655924527 4.9579437754\n",
      "Iteration 1000 - loss is 10.9050269838 - parameters are 2.00819942198 8.01104176242 4.95886580902\n",
      "Epoch 410\n",
      "Iteration 100 - loss is 8.58565544105 - parameters are 1.99822522105 8.00244866383 4.95775607394\n",
      "Iteration 200 - loss is 9.656677956 - parameters are 2.00045177733 8.0023843569 4.95804775348\n",
      "Iteration 300 - loss is 7.77480482803 - parameters are 1.99860666493 8.00261939772 4.95782879092\n",
      "Iteration 400 - loss is 9.58731642211 - parameters are 2.00221184096 8.00860004673 4.95821352483\n",
      "Iteration 500 - loss is 8.74145987322 - parameters are 1.99377961882 7.99773296299 4.95710335436\n",
      "Iteration 600 - loss is 7.99325087733 - parameters are 2.00501595984 8.00735091816 4.95844037294\n",
      "Iteration 700 - loss is 9.20961283672 - parameters are 2.00346035629 8.00549300538 4.95809987136\n",
      "Iteration 800 - loss is 7.15554931115 - parameters are 2.00462843586 8.01067864406 4.95851194212\n",
      "Iteration 900 - loss is 8.50729862147 - parameters are 2.00307703763 8.00655188536 4.95805291976\n",
      "Iteration 1000 - loss is 10.9047091288 - parameters are 2.00819192794 8.01103379887 4.95897470811\n",
      "Epoch 411\n",
      "Iteration 100 - loss is 8.58543225825 - parameters are 1.99821887246 8.00244187026 4.95786493118\n",
      "Iteration 200 - loss is 9.6564975506 - parameters are 2.00044453223 8.00237668232 4.95815627806\n",
      "Iteration 300 - loss is 7.77492689973 - parameters are 1.99860003928 8.00261230932 4.95793724099\n",
      "Iteration 400 - loss is 9.58756206537 - parameters are 2.0022048069 8.00859279207 4.9583217757\n",
      "Iteration 500 - loss is 8.74128021789 - parameters are 1.993772721 7.99772583654 4.95721148656\n",
      "Iteration 600 - loss is 7.99326571361 - parameters are 2.00500861026 8.00734346101 4.95854826494\n",
      "Iteration 700 - loss is 9.20972741707 - parameters are 2.00345302702 8.00548555408 4.9582076091\n",
      "Iteration 800 - loss is 7.15557746176 - parameters are 2.00462108654 8.01067107371 4.95861948945\n",
      "Iteration 900 - loss is 8.50736595352 - parameters are 2.0030701398 8.00654464117 4.95816034784\n",
      "Iteration 1000 - loss is 10.9043964556 - parameters are 2.00818455176 8.01102596054 4.95908189478\n",
      "Epoch 412\n",
      "Iteration 100 - loss is 8.58521280647 - parameters are 1.99821262373 8.00243518352 4.95797207666\n",
      "Iteration 200 - loss is 9.65632022106 - parameters are 2.00043740108 8.00236912842 4.95826309611\n",
      "Iteration 300 - loss is 7.77504721902 - parameters are 1.99859351784 8.00260533238 4.95804398571\n",
      "Iteration 400 - loss is 9.58780401799 - parameters are 2.00219788346 8.00858565148 4.95842832433\n",
      "Iteration 500 - loss is 8.74110353294 - parameters are 1.99376593167 7.99771882216 4.9573179184\n",
      "Iteration 600 - loss is 7.99328051379 - parameters are 2.00500137627 8.00733612112 4.95865446037\n",
      "Iteration 700 - loss is 9.20984036036 - parameters are 2.00344581303 8.00547821996 4.95831365268\n",
      "Iteration 800 - loss is 7.15560535957 - parameters are 2.00461385281 8.0106636224 4.95872534562\n",
      "Iteration 900 - loss is 8.50743240885 - parameters are 2.00306335045 8.0065375109 4.95826608664\n",
      "Iteration 1000 - loss is 10.9040888768 - parameters are 2.00817729161 8.01101824546 4.95918739596\n",
      "Epoch 413\n",
      "Iteration 100 - loss is 8.5849970201 - parameters are 1.99820647328 8.00242860194 4.95807753729\n",
      "Iteration 200 - loss is 9.65614591155 - parameters are 2.00043038209 8.0023616933 4.95836823446\n",
      "Iteration 300 - loss is 7.77516580825 - parameters are 1.99858709898 8.00259846515 4.95814905189\n",
      "Iteration 400 - loss is 9.58804233265 - parameters are 2.00219106892 8.00857862317 4.95853319752\n",
      "Iteration 500 - loss is 8.74092976711 - parameters are 1.99375924913 7.99771191807 4.95742267663\n",
      "Iteration 600 - loss is 7.99329527225 - parameters are 2.00499425605 8.00732889664 4.95875898589\n",
      "Iteration 700 - loss is 9.20995168719 - parameters are 2.0034387125 8.00547100116 4.95841802875\n",
      "Iteration 800 - loss is 7.15563300264 - parameters are 2.00460673285 8.01065628826 4.95882953723\n",
      "Iteration 900 - loss is 8.50749799558 - parameters are 2.0030566679 8.00653049275 4.95837016273\n",
      "Iteration 1000 - loss is 10.9037863068 - parameters are 2.00817014563 8.0110106517 4.95929123816\n",
      "Epoch 414\n",
      "Iteration 100 - loss is 8.58478483479 - parameters are 1.99820041957 8.00242212385 4.95818133959\n",
      "Iteration 200 - loss is 9.65597456733 - parameters are 2.00042347349 8.00235437508 4.95847171955\n",
      "Iteration 300 - loss is 7.77528268957 - parameters are 1.99858078107 8.00259170591 4.95825246594\n",
      "Iteration 400 - loss is 9.58827706138 - parameters are 2.00218436156 8.00857170538 4.95863642161\n",
      "Iteration 500 - loss is 8.74075887009 - parameters are 1.99375267169 7.99770512255 4.95752578757\n",
      "Iteration 600 - loss is 7.99330998372 - parameters are 2.00498724781 8.00732178575 4.95886186779\n",
      "Iteration 700 - loss is 9.21006141802 - parameters are 2.00343172365 8.00546389588 4.95852076355\n",
      "Iteration 800 - loss is 7.15566038923 - parameters are 2.00459972488 8.01064906944 4.95893209047\n",
      "Iteration 900 - loss is 8.50756272188 - parameters are 2.00305009044 8.00652358496 4.95847260225\n",
      "Iteration 1000 - loss is 10.9034886614 - parameters are 2.00816311205 8.01100317734 4.95939344748\n",
      "Epoch 415\n",
      "Iteration 100 - loss is 8.58457618741 - parameters are 1.99819446108 8.00241574762 4.95828350964\n",
      "Iteration 200 - loss is 9.65580613476 - parameters are 2.00041667355 8.00234717194 4.95857357738\n",
      "Iteration 300 - loss is 7.77539788496 - parameters are 1.99857456254 8.00258505296 4.95835425384\n",
      "Iteration 400 - loss is 9.58850825553 - parameters are 2.00217775969 8.00856489636 4.95873802253\n",
      "Iteration 500 - loss is 8.74059079249 - parameters are 1.9937461977 7.99769843389 4.95762727713\n",
      "Iteration 600 - loss is 7.99332464314 - parameters are 2.0049803498 8.00731478668 4.95896313191\n",
      "Iteration 700 - loss is 9.21016957312 - parameters are 2.00342484472 8.00545690233 4.95862188288\n",
      "Iteration 800 - loss is 7.15568751783 - parameters are 2.00459282713 8.01064196414 4.9590330311\n",
      "Iteration 900 - loss is 8.50762659593 - parameters are 2.00304361644 8.0065167858 4.95857343096\n",
      "Iteration 1000 - loss is 10.9031958579 - parameters are 2.00815618909 8.01099582051 4.95949404961\n",
      "Epoch 416\n",
      "Iteration 100 - loss is 8.58437101603 - parameters are 1.9981885963 8.00240947167 4.95838407311\n",
      "Iteration 200 - loss is 9.65564056127 - parameters are 2.00040998055 8.00234008205 4.95867383353\n",
      "Iteration 300 - loss is 7.77551141619 - parameters are 1.99856844181 8.00257850462 4.95845444118\n",
      "Iteration 400 - loss is 9.58873596583 - parameters are 2.00217126165 8.00855819441 4.95883802584\n",
      "Iteration 500 - loss is 8.74042548585 - parameters are 1.99373982554 7.99769185041 4.95772717081\n",
      "Iteration 600 - loss is 7.99333924575 - parameters are 2.00497356028 8.00730789766 4.9590628037\n",
      "Iteration 700 - loss is 9.21027617261 - parameters are 2.00341807398 8.00545001875 4.95872141217\n",
      "Iteration 800 - loss is 7.1557143871 - parameters are 2.00458603786 8.01063497056 4.95913238449\n",
      "Iteration 900 - loss is 8.50768962599 - parameters are 2.00303724426 8.00651009354 4.95867267419\n",
      "Iteration 1000 - loss is 10.9029078153 - parameters are 2.00814937501 8.01098857937 4.95959306982\n",
      "Epoch 417\n",
      "Iteration 100 - loss is 8.58416925988 - parameters are 1.99818282377 8.0024032944 4.95848305527\n",
      "Iteration 200 - loss is 9.65547779531 - parameters are 2.00040339282 8.00233310365 4.95877251322\n",
      "Iteration 300 - loss is 7.77562330486 - parameters are 1.99856241735 8.00257205925 4.95855305312\n",
      "Iteration 400 - loss is 9.58896024235 - parameters are 2.00216486581 8.00855159783 4.95893645665\n",
      "Iteration 500 - loss is 8.74026290258 - parameters are 1.9937335536 7.99768537044 4.95782549373\n",
      "Iteration 600 - loss is 7.99335378701 - parameters are 2.00496687753 8.00730111697 4.95916090822\n",
      "Iteration 700 - loss is 9.21038123644 - parameters are 2.00341140973 8.00544324341 4.95881937641\n",
      "Iteration 800 - loss is 7.1557409959 - parameters are 2.00457935537 8.01062808695 4.9592301756\n",
      "Iteration 900 - loss is 8.50775182032 - parameters are 2.0030309723 8.00650350652 4.95877035688\n",
      "Iteration 1000 - loss is 10.9026244536 - parameters are 2.00814266809 8.01098145208 4.959690533\n",
      "Epoch 418\n",
      "Iteration 100 - loss is 8.58397085935 - parameters are 1.99817714203 8.00239721426 4.958580481\n",
      "Iteration 200 - loss is 9.65531778635 - parameters are 2.00039690869 8.00232623497 4.95886964122\n",
      "Iteration 300 - loss is 7.77573357233 - parameters are 1.99855648765 8.00256571523 4.95865011446\n",
      "Iteration 400 - loss is 9.58918113451 - parameters are 2.00215857055 8.00854510498 4.95903333969\n",
      "Iteration 500 - loss is 8.74010299598 - parameters are 1.9937273803 7.99767899238 4.95792227058\n",
      "Iteration 600 - loss is 7.99336826265 - parameters are 2.00496029989 8.00729444289 4.9592574701\n",
      "Iteration 700 - loss is 9.21048478436 - parameters are 2.00340485029 8.0054365746 4.95891580023\n",
      "Iteration 800 - loss is 7.15576734327 - parameters are 2.00457277797 8.01062131157 4.95932642902\n",
      "Iteration 900 - loss is 8.50781318721 - parameters are 2.00302479898 8.00649702308 4.95886650358\n",
      "Iteration 1000 - loss is 10.9023456945 - parameters are 2.00813606666 8.01097443686 4.95978646364\n",
      "Epoch 419\n",
      "Iteration 100 - loss is 8.58377575595 - parameters are 1.99817154965 8.00239122973 4.95867637478\n",
      "Iteration 200 - loss is 9.65516048487 - parameters are 2.00039052654 8.00231947429 4.95896524196\n",
      "Iteration 300 - loss is 7.77584223981 - parameters are 1.99855065121 8.00255947096 4.95874564957\n",
      "Iteration 400 - loss is 9.58939869112 - parameters are 2.00215237431 8.00853871422 4.95912869932\n",
      "Iteration 500 - loss is 8.7399457202 - parameters are 1.99372130409 7.9976727146 4.95801752568\n",
      "Iteration 600 - loss is 7.9933826686 - parameters are 2.00495382569 8.00728787376 4.95935251361\n",
      "Iteration 700 - loss is 9.21058683598 - parameters are 2.00339839402 8.00543001066 4.95901070786\n",
      "Iteration 800 - loss is 7.15579342843 - parameters are 2.00456630403 8.01061464274 4.95942116892\n",
      "Iteration 900 - loss is 8.507873735 - parameters are 2.00301872275 8.00649064158 4.95896113844\n",
      "Iteration 1000 - loss is 10.902071461 - parameters are 2.00812956905 8.01096753195 4.95988088584\n",
      "Epoch 420\n",
      "Iteration 100 - loss is 8.58358389227 - parameters are 1.99816604523 8.00238533931 4.9587707607\n",
      "Iteration 200 - loss is 9.65500584231 - parameters are 2.00038424476 8.00231281991 4.95905933944\n",
      "Iteration 300 - loss is 7.77594932827 - parameters are 1.99854490656 8.00255332488 4.95883968247\n",
      "Iteration 400 - loss is 9.58961296033 - parameters are 2.00214627551 8.00853242395 4.95922255949\n",
      "Iteration 500 - loss is 8.73979103023 - parameters are 1.99371532344 7.99766653554 4.95811128298\n",
      "Iteration 600 - loss is 7.99339700104 - parameters are 2.00494745332 8.00728140791 4.95944606264\n",
      "Iteration 700 - loss is 9.21068741072 - parameters are 2.00339203929 8.00542354994 4.95910412314\n",
      "Iteration 800 - loss is 7.15581925076 - parameters are 2.00455993189 8.01060807877 4.95951441912\n",
      "Iteration 900 - loss is 8.507933472 - parameters are 2.00301274208 8.00648436042 4.95905428525\n",
      "Iteration 1000 - loss is 10.9018016776 - parameters are 2.00812317363 8.01096073561 4.95997382333\n",
      "Epoch 421\n",
      "Iteration 100 - loss is 8.583395212 - parameters are 1.99816062738 8.00237954151 4.95886366248\n",
      "Iteration 200 - loss is 9.65485381105 - parameters are 2.00037806177 8.00230627016 4.95915195733\n",
      "Iteration 300 - loss is 7.77605485851 - parameters are 1.99853925226 8.00254727544 4.95893223678\n",
      "Iteration 400 - loss is 9.58982398968 - parameters are 2.00214027263 8.00852623258 4.95931494379\n",
      "Iteration 500 - loss is 8.73963888188 - parameters are 1.99370943686 7.99766045364 4.95820356602\n",
      "Iteration 600 - loss is 7.99341125635 - parameters are 2.00494118115 8.00727504373 4.9595381407\n",
      "Iteration 700 - loss is 9.21078652781 - parameters are 2.00338578449 8.0054171908 4.95919606955\n",
      "Iteration 800 - loss is 7.15584480979 - parameters are 2.00455365998 8.010601618 4.95960620304\n",
      "Iteration 900 - loss is 8.50799240657 - parameters are 2.00300685548 8.00647817804 4.9591459674\n",
      "Iteration 1000 - loss is 10.9015362699 - parameters are 2.00811687879 8.01095404613 4.96006529946\n",
      "Epoch 422\n",
      "Iteration 100 - loss is 8.58320965987 - parameters are 1.99815529474 8.00237383488 4.95895510346\n",
      "Iteration 200 - loss is 9.65470434443 - parameters are 2.00037197602 8.0022998234 4.95924311888\n",
      "Iteration 300 - loss is 7.77615885113 - parameters are 1.99853368689 8.00254132113 4.95902333576\n",
      "Iteration 400 - loss is 9.59003182611 - parameters are 2.00213436416 8.00852013857 4.95940587544\n",
      "Iteration 500 - loss is 8.73948923175 - parameters are 1.99370364285 7.99765446737 4.95829439799\n",
      "Iteration 600 - loss is 7.99342543112 - parameters are 2.00493500763 8.00726877962 4.95962877091\n",
      "Iteration 700 - loss is 9.21088420632 - parameters are 2.00337962807 8.00541093166 4.95928657019\n",
      "Iteration 800 - loss is 7.15587010522 - parameters are 2.0045474867 8.01059525883 4.95969654374\n",
      "Iteration 900 - loss is 8.50805054706 - parameters are 2.00300106145 8.00647209286 4.95923620794\n",
      "Iteration 1000 - loss is 10.9012751649 - parameters are 2.00811068294 8.01094746183 4.96015533722\n",
      "Epoch 423\n",
      "Iteration 100 - loss is 8.58302718165 - parameters are 1.99815004597 8.00236821798 4.95904510663\n",
      "Iteration 200 - loss is 9.65455739666 - parameters are 2.00036598598 8.002293478 4.95933284701\n",
      "Iteration 300 - loss is 7.77626132649 - parameters are 1.99852820905 8.00253546044 4.9591130023\n",
      "Iteration 400 - loss is 9.59023651592 - parameters are 2.0021285486 8.00851414037 4.95949537727\n",
      "Iteration 500 - loss is 8.73934203727 - parameters are 1.99369793997 7.99764857523 4.95838380173\n",
      "Iteration 600 - loss is 7.99343952213 - parameters are 2.0049289312 8.00726261401 4.95971797606\n",
      "Iteration 700 - loss is 9.21098046514 - parameters are 2.00337356847 8.00540477093 4.9593756478\n",
      "Iteration 800 - loss is 7.15589513686 - parameters are 2.00454141051 8.01058899965 4.95978546393\n",
      "Iteration 900 - loss is 8.50810790181 - parameters are 2.00299535854 8.00646610337 4.95932502955\n",
      "Iteration 1000 - loss is 10.901018291 - parameters are 2.00810458454 8.01094098107 4.96024395923\n",
      "Epoch 424\n",
      "Iteration 100 - loss is 8.58284772411 - parameters are 1.99814487975 8.0023626894 4.95913369459\n",
      "Iteration 200 - loss is 9.65441292288 - parameters are 2.00036009014 8.00228723237 4.95942116425\n",
      "Iteration 300 - loss is 7.7763623048 - parameters are 1.99852281736 8.0025296919 4.95920125893\n",
      "Iteration 400 - loss is 9.5904381048 - parameters are 2.00212282451 8.00850823648 4.95958347178\n",
      "Iteration 500 - loss is 8.7391972566 - parameters are 1.99369232678 7.99764277574 4.95847179969\n",
      "Iteration 600 - loss is 7.99345352635 - parameters are 2.00492295033 8.00725654533 4.95980577855\n",
      "Iteration 700 - loss is 9.21107532297 - parameters are 2.00336760417 8.00539870708 4.95946332476\n",
      "Iteration 800 - loss is 7.1559199047 - parameters are 2.00453542987 8.01058283888 4.95987298595\n",
      "Iteration 900 - loss is 8.50816447918 - parameters are 2.00298974533 8.00646020805 4.95941245453\n",
      "Iteration 1000 - loss is 10.9007655775 - parameters are 2.00809858204 8.01093460221 4.96033118776\n",
      "Epoch 425\n",
      "Iteration 100 - loss is 8.58267123502 - parameters are 1.99813979478 8.00235724776 4.9592208896\n",
      "Iteration 200 - loss is 9.65427087907 - parameters are 2.00035428703 8.00228108494 4.95950809281\n",
      "Iteration 300 - loss is 7.77646180602 - parameters are 1.99851751047 8.00252401407 4.95928812782\n",
      "Iteration 400 - loss is 9.59063663788 - parameters are 2.00211719043 8.00850242542 4.95967018111\n",
      "Iteration 500 - loss is 8.73905484868 - parameters are 1.99368680186 7.99763706744 4.95855841398\n",
      "Iteration 600 - loss is 7.99346744096 - parameters are 2.00491706351 8.00725057208 4.95989220045\n",
      "Iteration 700 - loss is 9.21116879834 - parameters are 2.00336173367 8.00539273857 4.9595496231\n",
      "Iteration 800 - loss is 7.15594440883 - parameters are 2.00452954329 8.01057677498 4.95995913178\n",
      "Iteration 900 - loss is 8.50822028751 - parameters are 2.00298422039 8.00645440544 4.95949850485\n",
      "Iteration 1000 - loss is 10.9005169555 - parameters are 2.00809267394 8.01092832364 4.96041704472\n",
      "Epoch 426\n",
      "Iteration 100 - loss is 8.58249766312 - parameters are 1.99813478978 8.00235189168 4.95930671357\n",
      "Iteration 200 - loss is 9.65413122207 - parameters are 2.00034857517 8.00227503417 4.95959365452\n",
      "Iteration 300 - loss is 7.77655984994 - parameters are 1.99851228704 8.00251842551 4.9593736308\n",
      "Iteration 400 - loss is 9.59083215965 - parameters are 2.00211164496 8.00849670574 4.95975552704\n",
      "Iteration 500 - loss is 8.73891477318 - parameters are 1.99368136383 7.9976314489 4.95864366636\n",
      "Iteration 600 - loss is 7.99348126329 - parameters are 2.00491126928 8.00724469275 4.95997726347\n",
      "Iteration 700 - loss is 9.21126090957 - parameters are 2.00335595549 8.00538686391 4.95963456451\n",
      "Iteration 800 - loss is 7.15596864947 - parameters are 2.00452374929 8.01057080643 4.96004392308\n",
      "Iteration 900 - loss is 8.50827533513 - parameters are 2.00297878234 8.00644869406 4.95958320214\n",
      "Iteration 1000 - loss is 10.9002723567 - parameters are 2.00808685875 8.0109221438 4.96050155168\n",
      "Epoch 427\n",
      "Iteration 100 - loss is 8.58232695809 - parameters are 1.99812986349 8.00234661982 4.95939118807\n",
      "Iteration 200 - loss is 9.65399390957 - parameters are 2.00034295314 8.00226907853 4.95967787088\n",
      "Iteration 300 - loss is 7.77665645613 - parameters are 1.99850714575 8.00251292483 4.95945778936\n",
      "Iteration 400 - loss is 9.59102471403 - parameters are 2.0021061867 8.00849107598 4.95983953101\n",
      "Iteration 500 - loss is 8.73877699053 - parameters are 1.99367601133 7.9976259187 4.95872757826\n",
      "Iteration 600 - loss is 7.99349499083 - parameters are 2.00490556616 8.00723890586 4.96006098898\n",
      "Iteration 700 - loss is 9.21135167483 - parameters are 2.00335026818 8.00538108163 4.95971817032\n",
      "Iteration 800 - loss is 7.15599262698 - parameters are 2.0045180464 8.01056493173 4.96012738115\n",
      "Iteration 900 - loss is 8.50832963037 - parameters are 2.00297342981 8.00644307249 4.95966656768\n",
      "Iteration 1000 - loss is 10.9000317144 - parameters are 2.00808113502 8.01091606112 4.96058472989\n",
      "Epoch 428\n",
      "Iteration 100 - loss is 8.58215907054 - parameters are 1.99812501468 8.00234143085 4.95947433432\n",
      "Iteration 200 - loss is 9.65385890005 - parameters are 2.00033741952 8.00226321654 4.95976076305\n",
      "Iteration 300 - loss is 7.77675164397 - parameters are 1.99850208533 8.00250751064 4.95954062464\n",
      "Iteration 400 - loss is 9.59121434435 - parameters are 2.00210081428 8.00848553474 4.95992221413\n",
      "Iteration 500 - loss is 8.73864146182 - parameters are 1.993670743 7.99762047546 4.95881017076\n",
      "Iteration 600 - loss is 7.99350862126 - parameters are 2.00489995273 8.00723320996 4.96014339802\n",
      "Iteration 700 - loss is 9.21144111211 - parameters are 2.00334467031 8.00537539026 4.95980046155\n",
      "Iteration 800 - loss is 7.1560163418 - parameters are 2.0045124332 8.0105591494 4.96020952695\n",
      "Iteration 900 - loss is 8.50838318153 - parameters are 2.00296816146 8.0064375393 4.95974862241\n",
      "Iteration 1000 - loss is 10.8997949628 - parameters are 2.00807550129 8.01091007408 4.96066660023\n",
      "Epoch 429\n",
      "Iteration 100 - loss is 8.581993952 - parameters are 1.99812024213 8.00233632347 4.95955617321\n",
      "Iteration 200 - loss is 9.6537261528 - parameters are 2.00033197293 8.00225744671 4.95984235185\n",
      "Iteration 300 - loss is 7.77684543262 - parameters are 1.99849710448 8.00250218157 4.95962215745\n",
      "Iteration 400 - loss is 9.59140109337 - parameters are 2.00209552635 8.00848008063 4.96000359717\n",
      "Iteration 500 - loss is 8.7385081489 - parameters are 1.99366555753 7.9976151178 4.95889146461\n",
      "Iteration 600 - loss is 7.99352215239 - parameters are 2.00489442758 8.00722760361 4.96022451129\n",
      "Iteration 700 - loss is 9.21152923918 - parameters are 2.00333916048 8.00536978838 4.95988145886\n",
      "Iteration 800 - loss is 7.1560397945 - parameters are 2.00450690827 8.01055345798 4.96029038112\n",
      "Iteration 900 - loss is 8.50843599689 - parameters are 2.00296297596 8.00643209312 4.95982938694\n",
      "Iteration 1000 - loss is 10.8995620376 - parameters are 2.00806995616 8.01090418118 4.96074718328\n",
      "Epoch 430\n",
      "Iteration 100 - loss is 8.5818315549 - parameters are 1.99811554463 8.00233129641 4.95963672531\n",
      "Iteration 200 - loss is 9.65359562789 - parameters are 2.00032661198 8.0022517676 4.95992265779\n",
      "Iteration 300 - loss is 7.77693784104 - parameters are 1.99849220197 8.00249693631 4.95970240827\n",
      "Iteration 400 - loss is 9.59158500328 - parameters are 2.00209032157 8.00847471227 4.96008370059\n",
      "Iteration 500 - loss is 8.73837701425 - parameters are 1.9936604536 7.99760984439 4.95897148023\n",
      "Iteration 600 - loss is 7.99353558221 - parameters are 2.00488898931 8.00722208541 4.96030434918\n",
      "Iteration 700 - loss is 9.21161607366 - parameters are 2.0033337373 8.00536427459 4.95996118261\n",
      "Iteration 800 - loss is 7.15606298575 - parameters are 2.00450147023 8.01054785606 4.96036996399\n",
      "Iteration 900 - loss is 8.5084880847 - parameters are 2.002957872 8.00642673258 4.95990888158\n",
      "Iteration 1000 - loss is 10.8993328752 - parameters are 2.00806449824 8.01089838094 4.96082649928\n",
      "Epoch 431\n",
      "Iteration 100 - loss is 8.58167183252 - parameters are 1.99811092101 8.00232634838 4.95971601084\n",
      "Iteration 200 - loss is 9.65346728616 - parameters are 2.00032133535 8.00224617779 4.96000170104\n",
      "Iteration 300 - loss is 7.777028888 - parameters are 1.99848737656 8.00249177351 4.95978139727\n",
      "Iteration 400 - loss is 9.59176611569 - parameters are 2.00208519864 8.00846942832 4.9601625445\n",
      "Iteration 500 - loss is 8.73824802107 - parameters are 1.99365542994 7.99760465389 4.95905023773\n",
      "Iteration 600 - loss is 7.99354890883 - parameters are 2.00488363657 8.00721665398 4.96038293174\n",
      "Iteration 700 - loss is 9.21170163297 - parameters are 2.0033283994 8.00535884749 4.96003965283\n",
      "Iteration 800 - loss is 7.15608591631 - parameters are 2.00449611771 8.01054234221 4.96044829553\n",
      "Iteration 900 - loss is 8.5085394532 - parameters are 2.00295284832 8.00642145632 4.95998712628\n",
      "Iteration 1000 - loss is 10.8991074133 - parameters are 2.00805912614 8.01089267189 4.96090456816\n",
      "Epoch 432\n",
      "Iteration 100 - loss is 8.58151473901 - parameters are 1.9981063701 8.00232147816 4.95979404973\n",
      "Iteration 200 - loss is 9.65334108918 - parameters are 2.00031614169 8.00224067586 4.96007950145\n",
      "Iteration 300 - loss is 7.77711859205 - parameters are 1.99848262704 8.00248669189 4.95985914429\n",
      "Iteration 400 - loss is 9.59194447167 - parameters are 2.00208015628 8.00846422745 4.96024014871\n",
      "Iteration 500 - loss is 8.73812113319 - parameters are 1.99365048528 7.99759954501 4.95912775689\n",
      "Iteration 600 - loss is 7.9935621305 - parameters are 2.004878368 8.00721130795 4.96046027872\n",
      "Iteration 700 - loss is 9.21178593435 - parameters are 2.00332314544 8.00535350572 4.96011688923\n",
      "Iteration 800 - loss is 7.15610858704 - parameters are 2.00449084936 8.01053691506 4.96052539544\n",
      "Iteration 900 - loss is 8.5085901106 - parameters are 2.00294790363 8.00641626302 4.96006414071\n",
      "Iteration 1000 - loss is 10.8988855907 - parameters are 2.00805383853 8.0108870526 4.96098140954\n",
      "Epoch 433\n",
      "Iteration 100 - loss is 8.58136022937 - parameters are 1.99810189076 8.00231668451 4.95987086159\n",
      "Iteration 200 - loss is 9.65321699928 - parameters are 2.0003110297 8.00223526043 4.96015607859\n",
      "Iteration 300 - loss is 7.77720697155 - parameters are 1.9984779522 8.00248169017 4.95993566887\n",
      "Iteration 400 - loss is 9.59212011171 - parameters are 2.00207519321 8.00845910835 4.96031653273\n",
      "Iteration 500 - loss is 8.73799631509 - parameters are 1.99364561838 7.99759451646 4.9592040572\n",
      "Iteration 600 - loss is 7.99357524561 - parameters are 2.00487318228 8.00720604597 4.96053640954\n",
      "Iteration 700 - loss is 9.21186899487 - parameters are 2.00331797411 8.00534824794 4.96019291121\n",
      "Iteration 800 - loss is 7.15613099888 - parameters are 2.00448566385 8.01053157324 4.96060128309\n",
      "Iteration 900 - loss is 8.50864006505 - parameters are 2.00294303671 8.00641115137 4.96013994422\n",
      "Iteration 1000 - loss is 10.8986673473 - parameters are 2.00804863406 8.01088152167 4.96105704271\n",
      "Epoch 434\n",
      "Iteration 100 - loss is 8.5812082594 - parameters are 1.99809748187 8.00231196624 4.95994646571\n",
      "Iteration 200 - loss is 9.65309497947 - parameters are 2.00030599811 8.00222993016 4.96023145167\n",
      "Iteration 300 - loss is 7.77729404464 - parameters are 1.99847335089 8.0024767671 4.96001099024\n",
      "Iteration 400 - loss is 9.59229307576 - parameters are 2.00207030818 8.00845406974 4.96039171574\n",
      "Iteration 500 - loss is 8.73787353189 - parameters are 1.99364082802 7.99758956697 4.95927915781\n",
      "Iteration 600 - loss is 7.99358825268 - parameters are 2.00486807811 8.00720086672 4.96061134333\n",
      "Iteration 700 - loss is 9.21195083139 - parameters are 2.0033128841 8.00534307284 4.96026773788\n",
      "Iteration 800 - loss is 7.15615315286 - parameters are 2.0044805599 8.01052631541 4.96067597753\n",
      "Iteration 900 - loss is 8.50868932471 - parameters are 2.00293824632 8.0064061201 4.96021455585\n",
      "Iteration 1000 - loss is 10.8984526238 - parameters are 2.00804351144 8.0108760777 4.96113148669\n",
      "Epoch 435\n",
      "Iteration 100 - loss is 8.58105878572 - parameters are 1.99809314231 8.00230732216 4.96002088109\n",
      "Iteration 200 - loss is 9.6529749935 - parameters are 2.00030104563 8.00222468368 4.96030563965\n",
      "Iteration 300 - loss is 7.77737982928 - parameters are 1.99846882193 8.00247192143 4.9600851273\n",
      "Iteration 400 - loss is 9.59246340325 - parameters are 2.00206549998 8.00844911035 4.96046571663\n",
      "Iteration 500 - loss is 8.73775274933 - parameters are 1.99363611299 7.99758469531 4.95935307759\n",
      "Iteration 600 - loss is 7.99360115033 - parameters are 2.0048630542 8.00719576891 4.96068509893\n",
      "Iteration 700 - loss is 9.21203146062 - parameters are 2.00330787414 8.0053379791 4.96034138804\n",
      "Iteration 800 - loss is 7.15617505008 - parameters are 2.0044755362 8.01052114026 4.96074949753\n",
      "Iteration 900 - loss is 8.50873789766 - parameters are 2.00293353126 8.00640116794 4.96028799435\n",
      "Iteration 1000 - loss is 10.8982413623 - parameters are 2.00803846937 8.01087071933 4.96120476016\n",
      "Epoch 436\n",
      "Iteration 100 - loss is 8.58091176575 - parameters are 1.99808887099 8.00230275109 4.96009412642\n",
      "Iteration 200 - loss is 9.65285700577 - parameters are 2.00029617104 8.0022195197 4.96037866116\n",
      "Iteration 300 - loss is 7.77746434322 - parameters are 1.9984643642 8.00246715195 4.9601580987\n",
      "Iteration 400 - loss is 9.59263113305 - parameters are 2.00206076739 8.00844422893 4.96053855399\n",
      "Iteration 500 - loss is 8.73763393377 - parameters are 1.99363147211 7.99757990024 4.95942583513\n",
      "Iteration 600 - loss is 7.99361393734 - parameters are 2.0048581093 8.00719075125 4.96075769485\n",
      "Iteration 700 - loss is 9.21211089905 - parameters are 2.00330294296 8.00533296546 4.96041388018\n",
      "Iteration 800 - loss is 7.15619669173 - parameters are 2.00447059151 8.01051604647 4.96082186157\n",
      "Iteration 900 - loss is 8.50878579197 - parameters are 2.00292889035 8.00639629364 4.96036027817\n",
      "Iteration 1000 - loss is 10.8980335054 - parameters are 2.0080335066 8.0108654452 4.96127688155\n",
      "Epoch 437\n",
      "Iteration 100 - loss is 8.58076715766 - parameters are 1.99808466684 8.0022982519 4.9601662201\n",
      "Iteration 200 - loss is 9.65274098138 - parameters are 2.0002913731 8.00221443691 4.96045053454\n",
      "Iteration 300 - loss is 7.777547604 - parameters are 1.99845997657 8.00246245747 4.96022992275\n",
      "Iteration 400 - loss is 9.59279630351 - parameters are 2.00205610922 8.00843942426 4.96061024612\n",
      "Iteration 500 - loss is 8.73751705214 - parameters are 1.99362690421 7.99757518057 4.95949744868\n",
      "Iteration 600 - loss is 7.99362661255 - parameters are 2.00485324215 8.00718581248 4.96082914934\n",
      "Iteration 700 - loss is 9.21218916301 - parameters are 2.00329808933 8.00532803064 4.96048523252\n",
      "Iteration 800 - loss is 7.15621807906 - parameters are 2.00446572457 8.01051103277 4.96089308782\n",
      "Iteration 900 - loss is 8.50883301565 - parameters are 2.00292432242 8.00639149597 4.96043142545\n",
      "Iteration 1000 - loss is 10.8978289972 - parameters are 2.00802862186 8.010860254 4.96134786897\n",
      "Epoch 438\n",
      "Iteration 100 - loss is 8.5806249204 - parameters are 1.99808052881 8.00229382345 4.96023718025\n",
      "Iteration 200 - loss is 9.65262688608 - parameters are 2.00028665061 8.00220943403 4.96052127785\n",
      "Iteration 300 - loss is 7.77762962897 - parameters are 1.99845565794 8.00245783679 4.96030061752\n",
      "Iteration 400 - loss is 9.59295895243 - parameters are 2.0020515243 8.00843469514 4.96068081103\n",
      "Iteration 500 - loss is 8.73740207198 - parameters are 1.99362240814 7.9975705351 4.95956793626\n",
      "Iteration 600 - loss is 7.99363917495 - parameters are 2.00484845154 8.00718095136 4.96089948035\n",
      "Iteration 700 - loss is 9.21226626865 - parameters are 2.00329331202 8.00532317341 4.96055546299\n",
      "Iteration 800 - loss is 7.15623921338 - parameters are 2.00446093417 8.0105060979 4.96096319418\n",
      "Iteration 900 - loss is 8.50887957669 - parameters are 2.00291982632 8.00638677375 4.96050145409\n",
      "Iteration 1000 - loss is 10.8976277824 - parameters are 2.00802381393 8.01085514442 4.96141774025\n",
      "Epoch 439\n",
      "Iteration 100 - loss is 8.58048501364 - parameters are 1.99807645585 8.00228946463 4.96030702469\n",
      "Iteration 200 - loss is 9.65251468625 - parameters are 2.00028200238 8.00220450981 4.96059090886\n",
      "Iteration 300 - loss is 7.77771043527 - parameters are 1.99845140722 8.00245328877 4.96037020074\n",
      "Iteration 400 - loss is 9.59311911713 - parameters are 2.00204701148 8.00843004037 4.96075026644\n",
      "Iteration 500 - loss is 8.73728896141 - parameters are 1.99361798277 7.99756596268 4.95963731556\n",
      "Iteration 600 - loss is 7.9936516236 - parameters are 2.00484373627 8.00717616667 4.96096870554\n",
      "Iteration 700 - loss is 9.21234223194 - parameters are 2.00328860983 8.00531839256 4.96062458922\n",
      "Iteration 800 - loss is 7.15626009608 - parameters are 2.00445621909 8.01050124062 4.96103219826\n",
      "Iteration 900 - loss is 8.508925483 - parameters are 2.00291540093 8.00638212577 4.96057038167\n",
      "Iteration 1000 - loss is 10.8974298068 - parameters are 2.00801908162 8.01085011518 4.96148651294\n",
      "Epoch 440\n",
      "Iteration 100 - loss is 8.58034739781 - parameters are 1.99807244694 8.00228517435 4.96037577097\n",
      "Iteration 200 - loss is 9.65240434893 - parameters are 2.00027742724 8.00219966301 4.96065944507\n",
      "Iteration 300 - loss is 7.77779003987 - parameters are 1.99844722334 8.00244881225 4.96043868992\n",
      "Iteration 400 - loss is 9.59327683439 - parameters are 2.00204256962 8.00842545878 4.96081862981\n",
      "Iteration 500 - loss is 8.73717768908 - parameters are 1.993613627 7.99756146215 4.95970560401\n",
      "Iteration 600 - loss is 7.9936639577 - parameters are 2.00483909514 8.0071714572 4.96103684231\n",
      "Iteration 700 - loss is 9.21241706865 - parameters are 2.00328398159 8.00531368687 4.96069262858\n",
      "Iteration 800 - loss is 7.15628072859 - parameters are 2.00445157817 8.01049645971 4.96110011739\n",
      "Iteration 900 - loss is 8.50897074248 - parameters are 2.00291104512 8.00637755087 4.9606382255\n",
      "Iteration 1000 - loss is 10.8972350172 - parameters are 2.00801442371 8.01084516501 4.96155420433\n",
      "Epoch 441\n",
      "Iteration 100 - loss is 8.58021203403 - parameters are 1.99806850107 8.00228095152 4.96044343636\n",
      "Iteration 200 - loss is 9.65229584174 - parameters are 2.00027292405 8.00219489241 4.96072690368\n",
      "Iteration 300 - loss is 7.7778684595 - parameters are 1.99844310526 8.00244440612 4.96050610224\n",
      "Iteration 400 - loss is 9.59343214049 - parameters are 2.00203819761 8.00842094923 4.96088591831\n",
      "Iteration 500 - loss is 8.73706822423 - parameters are 1.99360933972 7.99755703238 4.95977281876\n",
      "Iteration 600 - loss is 7.99367617649 - parameters are 2.00483452699 8.00716682178 4.96110390777\n",
      "Iteration 700 - loss is 9.21249079438 - parameters are 2.00327942613 8.00530905518 4.96075959817\n",
      "Iteration 800 - loss is 7.15630111242 - parameters are 2.00444701022 8.01049175396 4.96116696863\n",
      "Iteration 900 - loss is 8.50901536296 - parameters are 2.00290675782 8.0063730479 4.96070500264\n",
      "Iteration 1000 - loss is 10.897043361 - parameters are 2.00800983905 8.01084029267 4.96162083141\n",
      "Epoch 442\n",
      "Iteration 100 - loss is 8.58007888413 - parameters are 1.99806461726 8.00227679509 4.96051003786\n",
      "Iteration 200 - loss is 9.65218913294 - parameters are 2.00026849166 8.00219019682 4.96079330166\n",
      "Iteration 300 - loss is 7.77794571073 - parameters are 1.99843905194 8.00244006926 4.96057245465\n",
      "Iteration 400 - loss is 9.59358507121 - parameters are 2.00203389435 8.00841651058 4.96095214885\n",
      "Iteration 500 - loss is 8.73696053663 - parameters are 1.99360511986 7.99755267226 4.95983897672\n",
      "Iteration 600 - loss is 7.99368827935 - parameters are 2.00483003068 8.00716225925 4.96116991877\n",
      "Iteration 700 - loss is 9.21256342456 - parameters are 2.0032749423 8.0053044963 4.96082551481\n",
      "Iteration 800 - loss is 7.15632124911 - parameters are 2.0044425141 8.01048712221 4.96123276879\n",
      "Iteration 900 - loss is 8.50905935221 - parameters are 2.00290253793 8.00636861573 4.96077072985\n",
      "Iteration 1000 - loss is 10.8968547869 - parameters are 2.00800532649 8.01083549693 4.96168641093\n",
      "Epoch 443\n",
      "Iteration 100 - loss is 8.57994791062 - parameters are 1.99806079452 8.00227270401 4.96057559219\n",
      "Iteration 200 - loss is 9.65208419137 - parameters are 2.00026412898 8.00218557505 4.96085865567\n",
      "Iteration 300 - loss is 7.77802180991 - parameters are 1.99843506236 8.0024358006 4.96063776382\n",
      "Iteration 400 - loss is 9.59373566183 - parameters are 2.00202965876 8.00841214172 4.96101733805\n",
      "Iteration 500 - loss is 8.73685459657 - parameters are 1.99360096635 7.9975483807 4.95990409448\n",
      "Iteration 600 - loss is 7.99370026573 - parameters are 2.00482560506 8.00715776844 4.96123489189\n",
      "Iteration 700 - loss is 9.21263497443 - parameters are 2.00327052899 8.00530000911 4.96089039506\n",
      "Iteration 800 - loss is 7.15634114026 - parameters are 2.00443808868 8.01048256328 4.96129753438\n",
      "Iteration 900 - loss is 8.50910271798 - parameters are 2.00289838439 8.00636425325 4.96083542364\n",
      "Iteration 1000 - loss is 10.8966692443 - parameters are 2.00800088488 8.0108307766 4.96175095936\n",
      "Epoch 444\n",
      "Iteration 100 - loss is 8.57981907669 - parameters are 1.99805703189 8.00226867725 4.96064011582\n",
      "Iteration 200 - loss is 9.65198098643 - parameters are 2.0002598349 8.00218102595 4.96092298213\n",
      "Iteration 300 - loss is 7.77809677321 - parameters are 1.99843113551 8.00243159904 4.96070204614\n",
      "Iteration 400 - loss is 9.59388394714 - parameters are 2.00202548977 8.00840784154 4.9610815023\n",
      "Iteration 500 - loss is 8.73675037487 - parameters are 1.99359687816 7.99754415661 4.95996818841\n",
      "Iteration 600 - loss is 7.99371213514 - parameters are 2.00482124904 8.00715334825 4.96129884346\n",
      "Iteration 700 - loss is 9.21270545905 - parameters are 2.00326618507 8.00529559246 4.96095425521\n",
      "Iteration 800 - loss is 7.15636078752 - parameters are 2.00443373285 8.01047807603 4.96136128169\n",
      "Iteration 900 - loss is 8.50914546795 - parameters are 2.00289429617 8.00635995935 4.96089910028\n",
      "Iteration 1000 - loss is 10.8964866833 - parameters are 2.00799651312 8.01082613048 4.96181449291\n",
      "Epoch 445\n",
      "Iteration 100 - loss is 8.57969234619 - parameters are 1.99805332843 8.00226471381 4.96070362497\n",
      "Iteration 200 - loss is 9.65187948813 - parameters are 2.00025560834 8.00217654837 4.96098629721\n",
      "Iteration 300 - loss is 7.7781706166 - parameters are 1.99842727042 8.00242746355 4.96076531777\n",
      "Iteration 400 - loss is 9.59402996144 - parameters are 2.00202138634 8.00840360897 4.96114465772\n",
      "Iteration 500 - loss is 8.73664784287 - parameters are 1.99359285426 7.99753999893 4.96003127462\n",
      "Iteration 600 - loss is 7.9937238872 - parameters are 2.00481696152 8.00714899754 4.96136178954\n",
      "Iteration 700 - loss is 9.21277489333 - parameters are 2.00326190945 8.00529124526 4.96101711131\n",
      "Iteration 800 - loss is 7.15638019256 - parameters are 2.00442944551 8.01047365933 4.96142402671\n",
      "Iteration 900 - loss is 8.50918760973 - parameters are 2.00289027224 8.00635573297 4.96096177574\n",
      "Iteration 1000 - loss is 10.8963070551 - parameters are 2.0079922101 8.01082155741 4.96187702755\n",
      "Epoch 446\n",
      "Iteration 100 - loss is 8.57956768362 - parameters are 1.9980496832 8.00226081268 4.96076613559\n",
      "Iteration 200 - loss is 9.65177966699 - parameters are 2.00025144824 8.00217214119 4.96104861681\n",
      "Iteration 300 - loss is 7.77824335587 - parameters are 1.9984234661 8.00242339308 4.96082759461\n",
      "Iteration 400 - loss is 9.59417373858 - parameters are 2.00201734743 8.00839944295 4.96120682016\n",
      "Iteration 500 - loss is 8.7365469724 - parameters are 1.99358889363 7.99753590662 4.96009336894\n",
      "Iteration 600 - loss is 7.9937355216 - parameters are 2.00481274141 8.00714471524 4.96142374594\n",
      "Iteration 700 - loss is 9.21284329196 - parameters are 2.00325770108 8.00528696641 4.96107897914\n",
      "Iteration 800 - loss is 7.15639935712 - parameters are 2.00442522559 8.01046931207 4.96148578522\n",
      "Iteration 900 - loss is 8.50922915089 - parameters are 2.00288631158 8.00635157304 4.96102346579\n",
      "Iteration 1000 - loss is 10.8961303116 - parameters are 2.00798797474 8.01081705624 4.96193857897\n",
      "Epoch 447\n",
      "Iteration 100 - loss is 8.57944505409 - parameters are 1.9980460953 8.00225697289 4.96082766337\n",
      "Iteration 200 - loss is 9.65168149411 - parameters are 2.00024735356 8.0021678033 4.96110995658\n",
      "Iteration 300 - loss is 7.77831500659 - parameters are 1.99841972161 8.00241938661 4.96088889229\n",
      "Iteration 400 - loss is 9.59431531189 - parameters are 2.00201337203 8.00839534243 4.96126800525\n",
      "Iteration 500 - loss is 8.7364477358 - parameters are 1.99358499528 7.99753187866 4.96015448698\n",
      "Iteration 600 - loss is 7.99374703808 - parameters are 2.00480858766 8.00714050027 4.96148472823\n",
      "Iteration 700 - loss is 9.21291066949 - parameters are 2.00325355887 8.00528275483 4.96113987425\n",
      "Iteration 800 - loss is 7.15641828297 - parameters are 2.00442107203 8.01046503316 4.96154657272\n",
      "Iteration 900 - loss is 8.50927009895 - parameters are 2.0028824132 8.00634747851 4.9610841859\n",
      "Iteration 1000 - loss is 10.8959564056 - parameters are 2.00798380599 8.01081262584 4.96199916265\n",
      "Epoch 448\n",
      "Iteration 100 - loss is 8.57932442337 - parameters are 1.99804256382 8.00225319347 4.96088822379\n",
      "Iteration 200 - loss is 9.6515849411 - parameters are 2.00024332326 8.00216353361 4.96117033193\n",
      "Iteration 300 - loss is 7.77838558418 - parameters are 1.99841603599 8.00241544313 4.96094922622\n",
      "Iteration 400 - loss is 9.59445471427 - parameters are 2.00200945914 8.00839130638 4.96132822835\n",
      "Iteration 500 - loss is 8.73635010587 - parameters are 1.99358115823 7.99752791403 4.96021464408\n",
      "Iteration 600 - loss is 7.99375843649 - parameters are 2.00480449923 8.00713635157 4.96154475171\n",
      "Iteration 700 - loss is 9.21297704027 - parameters are 2.0032494818 8.00527860947 4.96119981194\n",
      "Iteration 800 - loss is 7.15643697191 - parameters are 2.00441698378 8.01046082152 4.96160640449\n",
      "Iteration 900 - loss is 8.50931046136 - parameters are 2.00287857613 8.00634344836 4.96114395135\n",
      "Iteration 1000 - loss is 10.8957852906 - parameters are 2.00797970278 8.01080826509 4.9620587938\n",
      "Epoch 449\n",
      "Iteration 100 - loss is 8.57920575781 - parameters are 1.99803908787 8.00224947347 4.96094783204\n",
      "Iteration 200 - loss is 9.65148998012 - parameters are 2.00023935633 8.00215933104 4.96122975803\n",
      "Iteration 300 - loss is 7.77845510383 - parameters are 1.99841240834 8.00241156165 4.96100861154\n",
      "Iteration 400 - loss is 9.59459197813 - parameters are 2.00200560778 8.00838733378 4.9613875046\n",
      "Iteration 500 - loss is 8.73625405589 - parameters are 1.99357738152 7.99752401173 4.96027385537\n",
      "Iteration 600 - loss is 7.9937697167 - parameters are 2.00480047508 8.00713226809 4.96160383148\n",
      "Iteration 700 - loss is 9.21304241851 - parameters are 2.00324546884 8.00527452929 4.96125880726\n",
      "Iteration 800 - loss is 7.15645542576 - parameters are 2.00441295981 8.0104566761 4.96166529556\n",
      "Iteration 900 - loss is 8.50935024552 - parameters are 2.00287479939 8.00633948158 4.96120277713\n",
      "Iteration 1000 - loss is 10.895616921 - parameters are 2.00797566409 8.0108039729 4.9621174874\n",
      "Epoch 450\n",
      "Iteration 100 - loss is 8.57908902438 - parameters are 1.99803566658 8.00224581196 4.9610065031\n",
      "Iteration 200 - loss is 9.65139658382 - parameters are 2.00023545179 8.00215519455 4.96128824981\n",
      "Iteration 300 - loss is 7.77852358057 - parameters are 1.99840883773 8.00240774119 4.96106706318\n",
      "Iteration 400 - loss is 9.59472713546 - parameters are 2.00200181698 8.00838342364 4.96144584888\n",
      "Iteration 500 - loss is 8.73615955963 - parameters are 1.99357366419 7.99752017078 4.96033213571\n",
      "Iteration 600 - loss is 7.99378087867 - parameters are 2.00479651421 8.00712824882 4.96166198237\n",
      "Iteration 700 - loss is 9.21310681822 - parameters are 2.00324151898 8.00527051325 4.96131687502\n",
      "Iteration 800 - loss is 7.1564736464 - parameters are 2.00440899912 8.01045259586 4.96172326071\n",
      "Iteration 900 - loss is 8.50938945876 - parameters are 2.00287108203 8.00633557716 4.96126067802\n",
      "Iteration 1000 - loss is 10.8954512518 - parameters are 2.00797168891 8.0107997482 4.9621752582\n",
      "Epoch 451\n",
      "Iteration 100 - loss is 8.57897419061 - parameters are 1.99803229908 8.00224220803 4.9610642517\n",
      "Iteration 200 - loss is 9.65130472536 - parameters are 2.00023160863 8.0021511231 4.96134582195\n",
      "Iteration 300 - loss is 7.77859102924 - parameters are 1.99840532326 8.00240398081 4.96112459582\n",
      "Iteration 400 - loss is 9.59486021776 - parameters are 2.00199808579 8.00837957498 4.96150327584\n",
      "Iteration 500 - loss is 8.73606659129 - parameters are 1.99357000532 7.99751639023 4.96038949974\n",
      "Iteration 600 - loss is 7.99379192242 - parameters are 2.00479261563 8.00712429274 4.96171921899\n",
      "Iteration 700 - loss is 9.21317025324 - parameters are 2.00323763124 8.00526656036 4.96137402982\n",
      "Iteration 800 - loss is 7.15649163571 - parameters are 2.00440510071 8.01044857977 4.96178031452\n",
      "Iteration 900 - loss is 8.50942810836 - parameters are 2.00286742313 8.00633173412 4.96131766858\n",
      "Iteration 1000 - loss is 10.895288239 - parameters are 2.00796777623 8.01079558992 4.9622321207\n",
      "Epoch 452\n",
      "Iteration 100 - loss is 8.57886122462 - parameters are 1.99802898454 8.00223866075 4.96112109237\n",
      "Iteration 200 - loss is 9.6512143784 - parameters are 2.00022782591 8.00214711565 4.96140248892\n",
      "Iteration 300 - loss is 7.7786574645 - parameters are 1.99840186406 8.00240027954 4.96118122391\n",
      "Iteration 400 - loss is 9.59499125611 - parameters are 2.00199441327 8.00837578682 4.96155979992\n",
      "Iteration 500 - loss is 8.73597512552 - parameters are 1.99356640398 7.99751266911 4.96044596188\n",
      "Iteration 600 - loss is 7.99380284803 - parameters are 2.00478877834 8.00712039885 4.96177555571\n",
      "Iteration 700 - loss is 9.21323273725 - parameters are 2.00323380462 8.00526266962 4.96143028602\n",
      "Iteration 800 - loss is 7.15650939562 - parameters are 2.00440126359 8.01044462682 4.9618364713\n",
      "Iteration 900 - loss is 8.50946620153 - parameters are 2.00286382176 8.00632795151 4.96137376311\n",
      "Iteration 1000 - loss is 10.8951278391 - parameters are 2.00796392508 8.01079149702 4.96228808919\n",
      "Epoch 453\n",
      "Iteration 100 - loss is 8.57875009511 - parameters are 1.99802572212 8.00223516925 4.96117703936\n",
      "Iteration 200 - loss is 9.65112551705 - parameters are 2.00022410267 8.00214317121 4.96145826496\n",
      "Iteration 300 - loss is 7.7787229008 - parameters are 1.99839845925 8.00239663647 4.96123696168\n",
      "Iteration 400 - loss is 9.59512028113 - parameters are 2.00199079849 8.00837205823 4.9616154353\n",
      "Iteration 500 - loss is 8.73588513742 - parameters are 1.99356285927 7.9975090065 4.9605015363\n",
      "Iteration 600 - loss is 7.99381365561 - parameters are 2.00478500139 8.00711656618 4.96183100669\n",
      "Iteration 700 - loss is 9.21329428376 - parameters are 2.00323003817 8.00525884004 4.96148565773\n",
      "Iteration 800 - loss is 7.15652692805 - parameters are 2.00439748681 8.01044073602 4.96189174517\n",
      "Iteration 900 - loss is 8.50950374541 - parameters are 2.00286027702 8.00632422838 4.96142897571\n",
      "Iteration 1000 - loss is 10.8949700095 - parameters are 2.00796013448 8.01078746846 4.96234317772\n",
      "Epoch 454\n",
      "Iteration 100 - loss is 8.57864077131 - parameters are 1.998022511 8.00223173264 4.96123210674\n",
      "Iteration 200 - loss is 9.65103811594 - parameters are 2.00022043797 8.00213928878 4.96151316407\n",
      "Iteration 300 - loss is 7.77878735243 - parameters are 1.99839510798 8.00239305068 4.96129182312\n",
      "Iteration 400 - loss is 9.59524732303 - parameters are 2.00198724056 8.00836838825 4.96167019597\n",
      "Iteration 500 - loss is 8.73579660252 - parameters are 1.9935593703 7.99750540147 4.96055623696\n",
      "Iteration 600 - loss is 7.99382434534 - parameters are 2.00478128383 8.00711279377 4.96188558585\n",
      "Iteration 700 - loss is 9.21335490612 - parameters are 2.00322633095 8.00525507068 4.96154015888\n",
      "Iteration 800 - loss is 7.15654423498 - parameters are 2.00439376942 8.01043690639 4.96194615001\n",
      "Iteration 900 - loss is 8.50954074711 - parameters are 2.00285678802 8.00632056377 4.96148332024\n",
      "Iteration 1000 - loss is 10.8948147083 - parameters are 2.00795640349 8.01078350325 4.96239740014\n",
      "Epoch 455\n",
      "Iteration 100 - loss is 8.578533223 - parameters are 1.99801935037 8.00222835006 4.96128630834\n",
      "Iteration 200 - loss is 9.65095215012 - parameters are 2.00021683089 8.00213546739 4.96156720004\n",
      "Iteration 300 - loss is 7.77885083351 - parameters are 1.9983918094 8.00238952126 4.96134582201\n",
      "Iteration 400 - loss is 9.59537241157 - parameters are 2.00198373856 8.00836477597 4.96172409568\n",
      "Iteration 500 - loss is 8.73570949677 - parameters are 1.99355593618 7.99750185313 4.96061007761\n",
      "Iteration 600 - loss is 7.99383491746 - parameters are 2.00477762472 8.00710908068 4.96193930691\n",
      "Iteration 700 - loss is 9.2134146175 - parameters are 2.00322268202 8.00525136058 4.96159380315\n",
      "Iteration 800 - loss is 7.15656131839 - parameters are 2.00439011048 8.01043313697 4.96199969949\n",
      "Iteration 900 - loss is 8.50957721365 - parameters are 2.00285335388 8.00631695679 4.96153681035\n",
      "Iteration 1000 - loss is 10.8946618943 - parameters are 2.00795273116 8.01077960037 4.96245077006\n",
      "Epoch 456\n",
      "Iteration 100 - loss is 8.57842742048 - parameters are 1.99801623944 8.00222502066 4.96133965777\n",
      "Iteration 200 - loss is 9.65086759513 - parameters are 2.00021328054 8.00213170608 4.96162038644\n",
      "Iteration 300 - loss is 7.77891335796 - parameters are 1.9983885627 8.00238604734 4.96139897192\n",
      "Iteration 400 - loss is 9.59549557609 - parameters are 2.00198029164 8.00836122048 4.96177714797\n",
      "Iteration 500 - loss is 8.73562379654 - parameters are 1.99355255607 7.99749836057 4.96066307176\n",
      "Iteration 600 - loss is 7.99384537225 - parameters are 2.00477402314 8.00710542595 4.96199218336\n",
      "Iteration 700 - loss is 9.2134734309 - parameters are 2.00321909046 8.00524770882 4.96164660401\n",
      "Iteration 800 - loss is 7.15657818028 - parameters are 2.00438650907 8.01042942682 4.96205240705\n",
      "Iteration 900 - loss is 8.50961315198 - parameters are 2.00284997374 8.00631340651 4.96158945948\n",
      "Iteration 1000 - loss is 10.8945115269 - parameters are 2.00794911657 8.01077575885 4.96250330089\n",
      "Epoch 457\n",
      "Iteration 100 - loss is 8.57832333461 - parameters are 1.99801317742 8.00222174362 4.96139216843\n",
      "Iteration 200 - loss is 9.65078442692 - parameters are 2.000209786 8.00212800391 4.96167273664\n",
      "Iteration 300 - loss is 7.77897493953 - parameters are 1.99838536704 8.00238262803 4.9614512862\n",
      "Iteration 400 - loss is 9.59561684552 - parameters are 2.00197689891 8.0083577209 4.96182936616\n",
      "Iteration 500 - loss is 8.7355394786 - parameters are 1.9935492291 7.99749492292 4.96071523273\n",
      "Iteration 600 - loss is 7.99385571001 - parameters are 2.0047704782 8.00710182869 4.96204422847\n",
      "Iteration 700 - loss is 9.21353135919 - parameters are 2.00321555538 8.00524411446 4.96169857473\n",
      "Iteration 800 - loss is 7.15659482265 - parameters are 2.00438296429 8.01042577499 4.96210428593\n",
      "Iteration 900 - loss is 8.50964856901 - parameters are 2.00284664674 8.00630991205 4.96164128086\n",
      "Iteration 1000 - loss is 10.8943635663 - parameters are 2.00794555882 8.01077197773 4.96255500583\n",
      "Epoch 458\n",
      "Iteration 100 - loss is 8.57822093672 - parameters are 1.99801016356 8.00221851809 4.96144385351\n",
      "Iteration 200 - loss is 9.6507026219 - parameters are 2.00020634641 8.00212435994 4.96172426379\n",
      "Iteration 300 - loss is 7.77903559179 - parameters are 1.99838222164 8.00237926248 4.961502778\n",
      "Iteration 400 - loss is 9.59573624837 - parameters are 2.00197355952 8.00835427633 4.96188076337\n",
      "Iteration 500 - loss is 8.73545652013 - parameters are 1.99354595445 7.99749153932 4.96076657362\n",
      "Iteration 600 - loss is 7.99386593112 - parameters are 2.004766989 8.00709828798 4.96209545532\n",
      "Iteration 700 - loss is 9.21358841503 - parameters are 2.00321207589 8.00524057662 4.96174972836\n",
      "Iteration 800 - loss is 7.15661124754 - parameters are 2.00437947525 8.01042218058 4.96215534917\n",
      "Iteration 900 - loss is 8.50968347157 - parameters are 2.00284337206 8.00630647253 4.96169228749\n",
      "Iteration 1000 - loss is 10.8942179732 - parameters are 2.00794205701 8.01076825606 4.96260589785\n",
      "Epoch 459\n",
      "Iteration 100 - loss is 8.57812019866 - parameters are 1.99800719708 8.00221534328 4.96149472599\n",
      "Iteration 200 - loss is 9.65062215691 - parameters are 2.00020296091 8.00212077326 4.96177498082\n",
      "Iteration 300 - loss is 7.77909532815 - parameters are 1.99837912569 8.00237594984 4.96155346023\n",
      "Iteration 400 - loss is 9.59585381273 - parameters are 2.00197027265 8.00835088592 4.96193135251\n",
      "Iteration 500 - loss is 8.73537489869 - parameters are 1.99354273129 7.99748820891 4.96081710732\n",
      "Iteration 600 - loss is 7.99387603597 - parameters are 2.00476355465 8.00709480294 4.96214587678\n",
      "Iteration 700 - loss is 9.21364461096 - parameters are 2.0032086511 8.0052370944 4.96180007775\n",
      "Iteration 800 - loss is 7.156627457 - parameters are 2.00437604107 8.01041864268 4.96220560959\n",
      "Iteration 900 - loss is 8.50971786643 - parameters are 2.00284014887 8.00630308709 4.9617424922\n",
      "Iteration 1000 - loss is 10.8940747093 - parameters are 2.00793861026 8.0107645929 4.96265598975\n",
      "Epoch 460\n",
      "Iteration 100 - loss is 8.57802109278 - parameters are 1.99800427725 8.00221221838 4.96154479865\n",
      "Iteration 200 - loss is 9.65054300918 - parameters are 2.00019962864 8.00211724297 4.96182490047\n",
      "Iteration 300 - loss is 7.77915416183 - parameters are 1.99837607842 8.00237268928 4.96160334563\n",
      "Iteration 400 - loss is 9.59596956632 - parameters are 2.00196703745 8.00834754881 4.96198114629\n",
      "Iteration 500 - loss is 8.73529459224 - parameters are 1.99353955881 7.99748493087 4.96086684653\n",
      "Iteration 600 - loss is 7.99388602501 - parameters are 2.00476017431 8.00709137269 4.96219550552\n",
      "Iteration 700 - loss is 9.21369995933 - parameters are 2.00320528017 8.00523366693 4.96184963555\n",
      "Iteration 800 - loss is 7.15664345307 - parameters are 2.00437266088 8.0104151604 4.96225507981\n",
      "Iteration 900 - loss is 8.50975176029 - parameters are 2.00283697636 8.00629975487 4.96179190758\n",
      "Iteration 1000 - loss is 10.8939337365 - parameters are 2.00793521771 8.01076098733 4.9627052941\n",
      "Epoch 461\n",
      "Iteration 100 - loss is 8.5779235919 - parameters are 1.99800140333 8.00220914261 4.96159408407\n",
      "Iteration 200 - loss is 9.65046515637 - parameters are 2.00019634876 8.00211376817 4.96187403529\n",
      "Iteration 300 - loss is 7.77921210589 - parameters are 1.99837307907 8.00236947999 4.96165244674\n",
      "Iteration 400 - loss is 9.59608353643 - parameters are 2.00196385313 8.00834426416 4.96203015721\n",
      "Iteration 500 - loss is 8.73521557911 - parameters are 1.99353643621 7.99748170437 4.96091580375\n",
      "Iteration 600 - loss is 7.99389589872 - parameters are 2.00475684712 8.00708799637 4.96224435399\n",
      "Iteration 700 - loss is 9.21375447236 - parameters are 2.00320196223 8.00523029334 4.96189841419\n",
      "Iteration 800 - loss is 7.15665923782 - parameters are 2.00436933384 8.01041173287 4.96230377227\n",
      "Iteration 900 - loss is 8.50978515978 - parameters are 2.00283385374 8.00629647504 4.96184054606\n",
      "Iteration 1000 - loss is 10.8937950178 - parameters are 2.0079318785 8.01075743845 4.96275382329\n",
      "Epoch 462\n",
      "Iteration 100 - loss is 8.57782766932 - parameters are 1.9979985746 8.0022061152 4.96164259463\n",
      "Iteration 200 - loss is 9.65038857656 - parameters are 2.00019312045 8.00211034801 4.96192239761\n",
      "Iteration 300 - loss is 7.77926917321 - parameters are 1.99837012688 8.00236632115 4.96170077588\n",
      "Iteration 400 - loss is 9.59619574997 - parameters are 2.00196071887 8.00834103116 4.96207839758\n",
      "Iteration 500 - loss is 8.73513783801 - parameters are 1.99353336271 7.99747852859 4.96096399126\n",
      "Iteration 600 - loss is 7.99390565761 - parameters are 2.00475357224 8.00708467313 4.96229243447\n",
      "Iteration 700 - loss is 9.21380816209 - parameters are 2.00319869647 8.00522697279 4.96194642595\n",
      "Iteration 800 - loss is 7.15667481331 - parameters are 2.00436605912 8.01040835923 4.96235169918\n",
      "Iteration 900 - loss is 8.50981807149 - parameters are 2.00283078021 8.00629324678 4.96188841985\n",
      "Iteration 1000 - loss is 10.8936585164 - parameters are 2.00792859179 8.01075394536 4.96280158951\n",
      "Epoch 463\n",
      "Iteration 100 - loss is 8.57773329881 - parameters are 1.99799579035 8.00220313538 4.9616903425\n",
      "Iteration 200 - loss is 9.65031324818 - parameters are 2.0001899429 8.00210698162 4.96196999958\n",
      "Iteration 300 - loss is 7.77932537651 - parameters are 1.99836722111 8.00236321198 4.96174834519\n",
      "Iteration 400 - loss is 9.59630623346 - parameters are 2.00195763389 8.00833784898 4.96212587952\n",
      "Iteration 500 - loss is 8.735061348 - parameters are 1.99353033754 7.99747540274 4.96101142117\n",
      "Iteration 600 - loss is 7.99391530222 - parameters are 2.00475034886 8.00708140213 4.96233975903\n",
      "Iteration 700 - loss is 9.21386104041 - parameters are 2.00319548206 8.00522370445 4.96199368287\n",
      "Iteration 800 - loss is 7.15669018162 - parameters are 2.00436283589 8.01040503863 4.96239887259\n",
      "Iteration 900 - loss is 8.50985050192 - parameters are 2.00282775501 8.00629006928 4.96193554097\n",
      "Iteration 1000 - loss is 10.8935241963 - parameters are 2.00792535676 8.01075050719 4.96284860475\n",
      "Epoch 464\n",
      "Iteration 100 - loss is 8.57764045459 - parameters are 1.99799304988 8.00220020242 4.96173733969\n",
      "Iteration 200 - loss is 9.65023915009 - parameters are 2.00018681532 8.00210366816 4.96201685316\n",
      "Iteration 300 - loss is 7.77938072834 - parameters are 1.99836436102 8.00236015169 4.96179516662\n",
      "Iteration 400 - loss is 9.59641501304 - parameters are 2.00195459742 8.00833471683 4.96217261495\n",
      "Iteration 500 - loss is 8.73498608851 - parameters are 1.99352735993 7.99747232604 4.96105810539\n",
      "Iteration 600 - loss is 7.99392483313 - parameters are 2.00474717615 8.00707818257 4.96238633956\n",
      "Iteration 700 - loss is 9.21391311906 - parameters are 2.00319231819 8.0052204875 4.96204019681\n",
      "Iteration 800 - loss is 7.15670534484 - parameters are 2.00435966333 8.01040177023 4.96244530435\n",
      "Iteration 900 - loss is 8.5098824575 - parameters are 2.00282477737 8.00628694172 4.96198192126\n",
      "Iteration 1000 - loss is 10.8933920222 - parameters are 2.00792217259 8.01074712307 4.96289488083\n",
      "Epoch 465\n",
      "Iteration 100 - loss is 8.57754911133 - parameters are 1.99799035249 8.00219731557 4.961783598\n",
      "Iteration 200 - loss is 9.6501662615 - parameters are 2.0001837369 8.00210040678 4.96206297011\n",
      "Iteration 300 - loss is 7.77943524109 - parameters are 1.99836154591 8.00235713951 4.96184125194\n",
      "Iteration 400 - loss is 9.59652211446 - parameters are 2.0019516087 8.00833163393 4.96221861562\n",
      "Iteration 500 - loss is 8.73491203933 - parameters are 1.99352442914 7.99746929771 4.96110405565\n",
      "Iteration 600 - loss is 7.99393425094 - parameters are 2.00474405334 8.00707501362 4.96243218776\n",
      "Iteration 700 - loss is 9.21396440964 - parameters are 2.00318920406 8.00521732112 4.96208597948\n",
      "Iteration 800 - loss is 7.15672030505 - parameters are 2.00435654066 8.01039855322 4.96249100612\n",
      "Iteration 900 - loss is 8.50991394461 - parameters are 2.00282184656 8.00628386334 4.96202757236\n",
      "Iteration 1000 - loss is 10.8932619592 - parameters are 2.00791903849 8.01074379216 4.96294042936\n",
      "Epoch 466\n",
      "Iteration 100 - loss is 8.57745924414 - parameters are 1.99798769752 8.0021944741 4.96182912904\n",
      "Iteration 200 - loss is 9.65009456201 - parameters are 2.0001807069 8.00209719668 4.96210836202\n",
      "Iteration 300 - loss is 7.77948892697 - parameters are 1.99835877506 8.00235417469 4.96188661271\n",
      "Iteration 400 - loss is 9.59662756313 - parameters are 2.00194866696 8.00832859949 4.96226389307\n",
      "Iteration 500 - loss is 8.73483918057 - parameters are 1.99352154443 7.99746631698 4.96114928348\n",
      "Iteration 600 - loss is 7.99394355628 - parameters are 2.00474097962 8.00707189449 4.96247731514\n",
      "Iteration 700 - loss is 9.21401492357 - parameters are 2.0031861389 8.00521420452 4.96213104236\n",
      "Iteration 800 - loss is 7.15673506434 - parameters are 2.00435346709 8.01039538679 4.96253598937\n",
      "Iteration 900 - loss is 8.50994496956 - parameters are 2.00281896182 8.00628083336 4.96207250575\n",
      "Iteration 1000 - loss is 10.8931339732 - parameters are 2.00791595367 8.01074051361 4.96298526178\n",
      "Epoch 467\n",
      "Iteration 100 - loss is 8.57737082857 - parameters are 1.9979850843 8.00219167731 4.96187394425\n",
      "Iteration 200 - loss is 9.65002403157 - parameters are 2.00017772453 8.00209403705 4.96215304029\n",
      "Iteration 300 - loss is 7.77954179805 - parameters are 1.99835604778 8.00235125648 4.96193126032\n",
      "Iteration 400 - loss is 9.59673138404 - parameters are 2.00194577148 8.00832561276 4.96230845868\n",
      "Iteration 500 - loss is 8.73476749269 - parameters are 1.99351870508 7.99746338313 4.96119380026\n",
      "Iteration 600 - loss is 7.99395274983 - parameters are 2.00473795423 8.00706882439 4.96252173304\n",
      "Iteration 700 - loss is 9.21406467213 - parameters are 2.00318312194 8.00521113692 4.96217539677\n",
      "Iteration 800 - loss is 7.1567496248 - parameters are 2.00435044184 8.01039227014 4.9625802654\n",
      "Iteration 900 - loss is 8.50997553858 - parameters are 2.00281612245 8.00627785102 4.9621167327\n",
      "Iteration 1000 - loss is 10.8930080304 - parameters are 2.00791291735 8.01073728661 4.96302938937\n",
      "Epoch 468\n",
      "Iteration 100 - loss is 8.57728384059 - parameters are 1.99798251216 8.00218892449 4.96191805489\n",
      "Iteration 200 - loss is 9.6499546505 - parameters are 2.00017478905 8.00209092709 4.96219701614\n",
      "Iteration 300 - loss is 7.77959386624 - parameters are 1.99835336339 8.00234838415 4.961975206\n",
      "Iteration 400 - loss is 9.59683360187 - parameters are 2.00194292153 8.00832267298 4.96235232364\n",
      "Iteration 500 - loss is 8.73469695651 - parameters are 1.99351591038 7.99746049539 4.96123761716\n",
      "Iteration 600 - loss is 7.99396183224 - parameters are 2.00473497641 8.00706580257 4.96256545261\n",
      "Iteration 700 - loss is 9.21411366647 - parameters are 2.00318015241 8.00520811755 4.96221905385\n",
      "Iteration 800 - loss is 7.15676398851 - parameters are 2.00434746416 8.01038920248 4.96262384534\n",
      "Iteration 900 - loss is 8.51000565787 - parameters are 2.00281332771 8.00627491556 4.96216026434\n",
      "Iteration 1000 - loss is 10.8928840977 - parameters are 2.00790992878 8.01073411034 4.96307282319\n",
      "Epoch 469\n",
      "Iteration 100 - loss is 8.57719825656 - parameters are 1.99797998047 8.00218621494 4.96196147203\n",
      "Iteration 200 - loss is 9.64988639946 - parameters are 2.00017189973 8.00208786603 4.96224030061\n",
      "Iteration 300 - loss is 7.77964514326 - parameters are 1.9983507212 8.00234555698 4.96201846078\n",
      "Iteration 400 - loss is 9.59693424091 - parameters are 2.00194011638 8.00831977943 4.96239549897\n",
      "Iteration 500 - loss is 8.73462755312 - parameters are 1.99351315961 7.99745765306 4.96128074518\n",
      "Iteration 600 - loss is 7.99397080424 - parameters are 2.00473204541 8.00706282825 4.96260848484\n",
      "Iteration 700 - loss is 9.21416191757 - parameters are 2.00317722957 8.00520514565 4.96226202457\n",
      "Iteration 800 - loss is 7.15677815757 - parameters are 2.0043445333 8.01038618306 4.96266674013\n",
      "Iteration 900 - loss is 8.51003533352 - parameters are 2.00281057692 8.00627202625 4.96220311158\n",
      "Iteration 1000 - loss is 10.8927621427 - parameters are 2.00790698719 8.010730984 4.96311557415\n",
      "Epoch 470\n",
      "Iteration 100 - loss is 8.5771140533 - parameters are 1.99797748858 8.002183548 4.96200420658\n",
      "Iteration 200 - loss is 9.64981925945 - parameters are 2.00016905584 8.00208485308 4.96228290458\n",
      "Iteration 300 - loss is 7.7796956407 - parameters are 1.99834812055 8.00234277426 4.96206103552\n",
      "Iteration 400 - loss is 9.5970333251 - parameters are 2.00193735534 8.00831693136 4.9624379955\n",
      "Iteration 500 - loss is 8.734559264 - parameters are 1.9935104521 7.99745485541 4.96132319515\n",
      "Iteration 600 - loss is 7.99397966654 - parameters are 2.00472916049 8.00705990069 4.96265084052\n",
      "Iteration 700 - loss is 9.21420943628 - parameters are 2.00317435269 8.00520222047 4.96230431972\n",
      "Iteration 800 - loss is 7.15679213407 - parameters are 2.00434164852 8.0103832111 4.96270896054\n",
      "Iteration 900 - loss is 8.51006457157 - parameters are 2.00280786938 8.00626918237 4.96224528519\n",
      "Iteration 1000 - loss is 10.8926421333 - parameters are 2.00790409185 8.01072790682 4.963157653\n",
      "Epoch 471\n",
      "Iteration 100 - loss is 8.57703120797 - parameters are 1.99797503587 8.00218092299 4.96204626928\n",
      "Iteration 200 - loss is 9.64975321182 - parameters are 2.00016625666 8.00208188751 4.96232483874\n",
      "Iteration 300 - loss is 7.77974537 - parameters are 1.99834556079 8.00234003528 4.96210294091\n",
      "Iteration 400 - loss is 9.59713087803 - parameters are 2.00193463771 8.00831412807 4.96247982393\n",
      "Iteration 500 - loss is 8.73449207088 - parameters are 1.99350778716 7.99745210175 4.96136497774\n",
      "Iteration 600 - loss is 7.99398841989 - parameters are 2.00472632093 8.00705701916 4.96269253031\n",
      "Iteration 700 - loss is 9.21425623329 - parameters are 2.00317152104 8.00519934128 4.96234594992\n",
      "Iteration 800 - loss is 7.15680592009 - parameters are 2.0043388091 8.01038028587 4.96275051718\n",
      "Iteration 900 - loss is 8.51009337801 - parameters are 2.00280520442 8.00626638319 4.96228679576\n",
      "Iteration 1000 - loss is 10.892524038 - parameters are 2.00790124203 8.01072487802 4.96319907031\n",
      "Epoch 472\n",
      "Iteration 100 - loss is 8.57694969817 - parameters are 1.99797262173 8.00217833924 4.96208767068\n",
      "Iteration 200 - loss is 9.64968823825 - parameters are 2.0001635015 8.00207896856 4.96236611363\n",
      "Iteration 300 - loss is 7.77979434243 - parameters are 1.99834304129 8.00233733937 4.96214418749\n",
      "Iteration 400 - loss is 9.59722692296 - parameters are 2.00193196281 8.00831136885 4.96252099474\n",
      "Iteration 500 - loss is 8.73442595583 - parameters are 1.99350516412 7.99744939138 4.96140610344\n",
      "Iteration 600 - loss is 7.99399706507 - parameters are 2.00472352602 8.00705418293 4.96273356467\n",
      "Iteration 700 - loss is 9.21430231916 - parameters are 2.00316873391 8.00519650736 4.96238692562\n",
      "Iteration 800 - loss is 7.15681951771 - parameters are 2.00433601432 8.01037740663 4.96279142048\n",
      "Iteration 900 - loss is 8.51012175875 - parameters are 2.00280258135 8.00626362803 4.96232765372\n",
      "Iteration 1000 - loss is 10.8924078259 - parameters are 2.00789843702 8.01072189683 4.96323983646\n",
      "Epoch 473\n",
      "Iteration 100 - loss is 8.57686950187 - parameters are 1.99797024555 8.00217579612 4.96212842118\n",
      "Iteration 200 - loss is 9.64962432074 - parameters are 2.00016078965 8.00207609549 4.96240673962\n",
      "Iteration 300 - loss is 7.7798425691 - parameters are 1.99834056139 8.00233468584 4.9621847856\n",
      "Iteration 400 - loss is 9.59732148279 - parameters are 2.00192932997 8.00830865301 4.96256151829\n",
      "Iteration 500 - loss is 8.73436090124 - parameters are 1.99350258232 7.99744672362 4.96144658258\n",
      "Iteration 600 - loss is 7.99400560284 - parameters are 2.00472077505 8.00705139129 4.9627739539\n",
      "Iteration 700 - loss is 9.2143477043 - parameters are 2.0031659906 8.00519371799 4.96242725713\n",
      "Iteration 800 - loss is 7.15683292902 - parameters are 2.00433326348 8.01037457265 4.96283168072\n",
      "Iteration 900 - loss is 8.51014971962 - parameters are 2.00279999952 8.00626091618 4.96236786933\n",
      "Iteration 1000 - loss is 10.8922934665 - parameters are 2.00789567612 8.01071896251 4.96327996171\n",
      "Epoch 474\n",
      "Iteration 100 - loss is 8.57679059742 - parameters are 1.99796790673 8.00217329298 4.96216853103\n",
      "Iteration 200 - loss is 9.6495614416 - parameters are 2.00015812044 8.0020732676 4.9624467269\n",
      "Iteration 300 - loss is 7.779890061 - parameters are 1.99833812049 8.00233207403 4.96222474545\n",
      "Iteration 400 - loss is 9.59741458011 - parameters are 2.00192673852 8.00830597986 4.96260140474\n",
      "Iteration 500 - loss is 8.73429688977 - parameters are 1.99350004111 7.99744409781 4.96148642533\n",
      "Iteration 600 - loss is 7.99401403402 - parameters are 2.00471806733 8.00704864353 4.96281370815\n",
      "Iteration 700 - loss is 9.214392399 - parameters are 2.00316329043 8.00519097247 4.96246695456\n",
      "Iteration 800 - loss is 7.15684615608 - parameters are 2.00433055589 8.01037178323 4.962871308\n",
      "Iteration 900 - loss is 8.51017726642 - parameters are 2.00279745829 8.00625824696 4.96240745269\n",
      "Iteration 1000 - loss is 10.8921809299 - parameters are 2.00789295862 8.01071607432 4.96331945613\n",
      "Epoch 475\n",
      "Iteration 100 - loss is 8.57671296352 - parameters are 1.99796560468 8.00217082919 4.96220801028\n",
      "Iteration 200 - loss is 9.64949958346 - parameters are 2.00015549319 8.00207048416 4.96248608552\n",
      "Iteration 300 - loss is 7.77993682893 - parameters are 1.99833571797 8.00232950328 4.96226407707\n",
      "Iteration 400 - loss is 9.59750623715 - parameters are 2.00192418782 8.00830334874 4.96264066411\n",
      "Iteration 500 - loss is 8.73423390438 - parameters are 1.99349753986 7.99744151327 4.96152564169\n",
      "Iteration 600 - loss is 7.99402235941 - parameters are 2.00471540219 8.00704593898 4.9628528374\n",
      "Iteration 700 - loss is 9.21443641338 - parameters are 2.00316063271 8.00518827012 4.96250602789\n",
      "Iteration 800 - loss is 7.15685920097 - parameters are 2.00432789088 8.01036903766 4.96291031229\n",
      "Iteration 900 - loss is 8.51020440486 - parameters are 2.00279495701 8.00625561971 4.96244641374\n",
      "Iteration 1000 - loss is 10.8920701867 - parameters are 2.00789028385 8.01071323154 4.96335832964\n",
      "Epoch 476\n",
      "Iteration 100 - loss is 8.57663657928 - parameters are 1.99796333882 8.00216840414 4.96224686887\n",
      "Iteration 200 - loss is 9.64943872925 - parameters are 2.00015290726 8.00206774449 4.96252482536\n",
      "Iteration 300 - loss is 7.77998288359 - parameters are 1.99833335322 8.00232697295 4.96230279033\n",
      "Iteration 400 - loss is 9.59759647583 - parameters are 2.00192167722 8.00830075899 4.96267930627\n",
      "Iteration 500 - loss is 8.73417192832 - parameters are 1.99349507793 7.99743896937 4.96156424151\n",
      "Iteration 600 - loss is 7.99403057984 - parameters are 2.00471277895 8.00704327694 4.96289135149\n",
      "Iteration 700 - loss is 9.21447975744 - parameters are 2.00315801678 8.00518561025 4.96254448692\n",
      "Iteration 800 - loss is 7.15687206574 - parameters are 2.00432526776 8.01036633526 4.96294870337\n",
      "Iteration 900 - loss is 8.51023114058 - parameters are 2.00279249506 8.00625303377 4.96248476226\n",
      "Iteration 1000 - loss is 10.8919612079 - parameters are 2.00788765114 8.01071043345 4.963396592\n",
      "Epoch 477\n",
      "Iteration 100 - loss is 8.57656142413 - parameters are 1.9979611086 8.00216601721 4.96228511653\n",
      "Iteration 200 - loss is 9.64937886221 - parameters are 2.00015036198 8.00206504788 4.96256295616\n",
      "Iteration 300 - loss is 7.7800282355 - parameters are 1.99833102565 8.00232448239 4.96234089497\n",
      "Iteration 400 - loss is 9.59768531774 - parameters are 2.0019192061 8.00829820995 4.96271734092\n",
      "Iteration 500 - loss is 8.73411094514 - parameters are 1.99349265472 7.99743646546 4.96160223448\n",
      "Iteration 600 - loss is 7.99403869615 - parameters are 2.00471019695 8.00704065676 4.96292926007\n",
      "Iteration 700 - loss is 9.21452244106 - parameters are 2.00315544198 8.0051829922 4.96258234133\n",
      "Iteration 800 - loss is 7.15688475244 - parameters are 2.00432268589 8.01036367534 4.96298649088\n",
      "Iteration 900 - loss is 8.51025747918 - parameters are 2.00279007182 8.00625048848 4.96252250789\n",
      "Iteration 1000 - loss is 10.8918539651 - parameters are 2.00788505981 8.01070767936 4.96343425282\n",
      "Epoch 478\n",
      "Iteration 100 - loss is 8.57648747786 - parameters are 1.99795891343 8.00216366781 4.96232276289\n",
      "Iteration 200 - loss is 9.64931996587 - parameters are 2.00014785672 8.00206239367 4.96260048748\n",
      "Iteration 300 - loss is 7.78007289504 - parameters are 1.99832873468 8.00232203099 4.96237840055\n",
      "Iteration 400 - loss is 9.59777278418 - parameters are 2.00191677383 8.00829570098 4.96275477761\n",
      "Iteration 500 - loss is 8.73405093863 - parameters are 1.9934902696 7.99743400092 4.96163963015\n",
      "Iteration 600 - loss is 7.9940467092 - parameters are 2.00470765555 8.00703807776 4.96296657268\n",
      "Iteration 700 - loss is 9.21456447396 - parameters are 2.00315290766 8.00518041531 4.96261960061\n",
      "Iteration 800 - loss is 7.15689726313 - parameters are 2.00432014461 8.01036105724 4.96302368433\n",
      "Iteration 900 - loss is 8.51028342616 - parameters are 2.00278768668 8.0062479832 4.96255966011\n",
      "Iteration 1000 - loss is 10.8917484302 - parameters are 2.00788250923 8.01070496855 4.96347132156\n",
      "Epoch 479\n",
      "Iteration 100 - loss is 8.57641472062 - parameters are 1.99795675278 8.00216135535 4.9623598174\n",
      "Iteration 200 - loss is 9.64926202405 - parameters are 2.00014539084 8.00205978118 4.96263742876\n",
      "Iteration 300 - loss is 7.78011687245 - parameters are 1.99832647973 8.00231961814 4.96241531649\n",
      "Iteration 400 - loss is 9.59785889609 - parameters are 2.0019143798 8.00829323146 4.96279162574\n",
      "Iteration 500 - loss is 8.73399189289 - parameters are 1.99348792199 7.99743157512 4.96167643791\n",
      "Iteration 600 - loss is 7.99405461986 - parameters are 2.0047051541 8.00703553931 4.96300329869\n",
      "Iteration 700 - loss is 9.21460586573 - parameters are 2.00315041319 8.00517787893 4.96265627412\n",
      "Iteration 800 - loss is 7.15690959984 - parameters are 2.00431764329 8.01035848029 4.96306029304\n",
      "Iteration 900 - loss is 8.510308987 - parameters are 2.00278533904 8.00624551731 4.96259622824\n",
      "Iteration 1000 - loss is 10.8916445757 - parameters are 2.00787999875 8.01070230037 4.96350780752\n",
      "Epoch 480\n",
      "Iteration 100 - loss is 8.57634313288 - parameters are 1.99795462611 8.00215907924 4.96239628936\n",
      "Iteration 200 - loss is 9.64920502083 - parameters are 2.00014296374 8.00205720977 4.96267378927\n",
      "Iteration 300 - loss is 7.78016017785 - parameters are 1.99832426023 8.00231724321 4.96245165206\n",
      "Iteration 400 - loss is 9.59794367414 - parameters are 2.0019120234 8.00829080076 4.96282789457\n",
      "Iteration 500 - loss is 8.73393379226 - parameters are 1.99348561128 7.99742918746 4.961712667\n",
      "Iteration 600 - loss is 7.99406242899 - parameters are 2.00470269199 8.00703304077 4.96303944731\n",
      "Iteration 700 - loss is 9.21464662585 - parameters are 2.00314795793 8.00517538243 4.96269237107\n",
      "Iteration 800 - loss is 7.15692176459 - parameters are 2.00431518129 8.01035594387 4.96309632621\n",
      "Iteration 900 - loss is 8.51033416707 - parameters are 2.00278302831 8.00624309019 4.96263222147\n",
      "Iteration 1000 - loss is 10.8915423745 - parameters are 2.00787752774 8.01069967413 4.96354371988\n",
      "Epoch 481\n",
      "Iteration 100 - loss is 8.57627269546 - parameters are 1.99795253287 8.00215683891 4.96243218793\n",
      "Iteration 200 - loss is 9.64914894062 - parameters are 2.0001405748 8.00205467878 4.96270957815\n",
      "Iteration 300 - loss is 7.78020282118 - parameters are 1.99832207563 8.00231490562 4.96248741638\n",
      "Iteration 400 - loss is 9.59802713867 - parameters are 2.00190970406 8.00828840827 4.96286359321\n",
      "Iteration 500 - loss is 8.73387662136 - parameters are 1.99348333691 7.99742683733 4.96174832652\n",
      "Iteration 600 - loss is 7.99407013748 - parameters are 2.00470026858 8.00703058151 4.96307502763\n",
      "Iteration 700 - loss is 9.21468676364 - parameters are 2.00314554128 8.00517292517 4.96272790054\n",
      "Iteration 800 - loss is 7.1569337594 - parameters are 2.00431275801 8.01035344731 4.96313179289\n",
      "Iteration 900 - loss is 8.51035897172 - parameters are 2.00278075391 8.00624070122 4.96266764884\n",
      "Iteration 1000 - loss is 10.8914418 - parameters are 2.00787509559 8.01069708918 4.96357906765\n",
      "Epoch 482\n",
      "Iteration 100 - loss is 8.57620338949 - parameters are 1.99795047254 8.00215463381 4.96246752213\n",
      "Iteration 200 - loss is 9.64909376804 - parameters are 2.00013822342 8.00205218758 4.96274480438\n",
      "Iteration 300 - loss is 7.78024481228 - parameters are 1.99831992537 8.00231260478 4.96252261844\n",
      "Iteration 400 - loss is 9.59810930974 - parameters are 2.00190742118 8.0082860534 4.96289873061\n",
      "Iteration 500 - loss is 8.73382036507 - parameters are 1.99348109829 7.99742452416 4.96178342542\n",
      "Iteration 600 - loss is 7.99407774622 - parameters are 2.00469788328 8.00702816091 4.96311004857\n",
      "Iteration 700 - loss is 9.21472628833 - parameters are 2.00314316263 8.00517050655 4.96276287143\n",
      "Iteration 800 - loss is 7.15694558628 - parameters are 2.00431037282 8.01035099001 4.96316670199\n",
      "Iteration 900 - loss is 8.5103834062 - parameters are 2.00277851527 8.00623834982 4.96270251924\n",
      "Iteration 1000 - loss is 10.891342826 - parameters are 2.00787270167 8.01069454487 4.96361385971\n",
      "Epoch 483\n",
      "Iteration 100 - loss is 8.57613519643 - parameters are 1.9979484446 8.00215246337 4.96250230083\n",
      "Iteration 200 - loss is 9.64903948803 - parameters are 2.000135909 8.00204973555 4.9627794768\n",
      "Iteration 300 - loss is 7.78028616083 - parameters are 1.99831780893 8.00231034012 4.96255726708\n",
      "Iteration 400 - loss is 9.5981902071 - parameters are 2.0019051742 8.00828373555 4.96293331561\n",
      "Iteration 500 - loss is 8.7337650085 - parameters are 1.99347889487 7.99742224735 4.96181797253\n",
      "Iteration 600 - loss is 7.99408525612 - parameters are 2.00469553547 8.00702577837 4.96314451895\n",
      "Iteration 700 - loss is 9.21476520898 - parameters are 2.00314082137 8.00516812595 4.96279729254\n",
      "Iteration 800 - loss is 7.15695724723 - parameters are 2.00430802513 8.01034857134 4.96320106227\n",
      "Iteration 900 - loss is 8.51040747572 - parameters are 2.00277631183 8.00623603538 4.96273684144\n",
      "Iteration 1000 - loss is 10.8912454268 - parameters are 2.00787034539 8.01069204056 4.96364810479\n",
      "Epoch 484\n",
      "Iteration 100 - loss is 8.57606809805 - parameters are 1.99794644855 8.00215032705 4.96253653276\n",
      "Iteration 200 - loss is 9.64898608576 - parameters are 2.00013363098 8.00204732206 4.96281360414\n",
      "Iteration 300 - loss is 7.78032687639 - parameters are 1.99831572576 8.00230811105 4.96259137101\n",
      "Iteration 400 - loss is 9.59826985021 - parameters are 2.00190296254 8.00828145414 4.96296735689\n",
      "Iteration 500 - loss is 8.73371053704 - parameters are 1.99347672609 7.99742000633 4.96185197651\n",
      "Iteration 600 - loss is 7.99409266807 - parameters are 2.00469322459 8.00702343328 4.9631784474\n",
      "Iteration 700 - loss is 9.21480353456 - parameters are 2.00313851692 8.00516578277 4.9628311725\n",
      "Iteration 800 - loss is 7.15696874423 - parameters are 2.00430571436 8.01034619069 4.96323488237\n",
      "Iteration 900 - loss is 8.51043118542 - parameters are 2.00277414303 8.00623375732 4.96277062405\n",
      "Iteration 1000 - loss is 10.8911495769 - parameters are 2.00786802615 8.01068957562 4.96368181149\n",
      "Epoch 485\n",
      "Iteration 100 - loss is 8.57600207645 - parameters are 1.99794448389 8.00214822433 4.96257022653\n",
      "Iteration 200 - loss is 9.64893354667 - parameters are 2.00013138877 8.00204494651 4.96284719494\n",
      "Iteration 300 - loss is 7.78036696838 - parameters are 1.99831367534 8.00230591704 4.96262493877\n",
      "Iteration 400 - loss is 9.59834825824 - parameters are 2.00190078566 8.00827920859 4.963000863\n",
      "Iteration 500 - loss is 8.7336569363 - parameters are 1.99347459142 7.99741780055 4.96188544591\n",
      "Iteration 600 - loss is 7.99409998299 - parameters are 2.00469095003 8.00702112506 4.96321184246\n",
      "Iteration 700 - loss is 9.21484127389 - parameters are 2.00313624871 8.00516347644 4.96286451983\n",
      "Iteration 800 - loss is 7.15698007925 - parameters are 2.00430343991 8.01034384747 4.96326817078\n",
      "Iteration 900 - loss is 8.51045454037 - parameters are 2.00277200833 8.00623151508 4.96280387556\n",
      "Iteration 1000 - loss is 10.8910552514 - parameters are 2.00786574338 8.01068714943 4.96371498829\n",
      "Epoch 486\n",
      "Iteration 100 - loss is 8.575937114 - parameters are 1.99794255011 8.00214615465 4.96260339059\n",
      "Iteration 200 - loss is 9.64888185646 - parameters are 2.00012918181 8.00204260832 4.96288025766\n",
      "Iteration 300 - loss is 7.78040644608 - parameters are 1.99831165716 8.00230375751 4.96265797881\n",
      "Iteration 400 - loss is 9.59842545009 - parameters are 2.001898643 8.00827699834 4.96303384236\n",
      "Iteration 500 - loss is 8.73360419216 - parameters are 1.9934724903 7.99741562945 4.96191838912\n",
      "Iteration 600 - loss is 7.9941072018 - parameters are 2.00468871123 8.00701885313 4.96324471251\n",
      "Iteration 700 - loss is 9.21487843569 - parameters are 2.00313401615 8.00516120636 4.9628973429\n",
      "Iteration 800 - loss is 7.15699125427 - parameters are 2.00430120123 8.01034154109 4.96330093585\n",
      "Iteration 900 - loss is 8.51047754559 - parameters are 2.00276990719 8.00622930809 4.96283660431\n",
      "Iteration 1000 - loss is 10.8909624259 - parameters are 2.0078634965 8.01068476138 4.9637476435\n",
      "Epoch 487\n",
      "Iteration 100 - loss is 8.57587319339 - parameters are 1.99794064674 8.00214411752 4.96263603327\n",
      "Iteration 200 - loss is 9.64883100105 - parameters are 2.00012700955 8.00204030688 4.9629128006\n",
      "Iteration 300 - loss is 7.78044531866 - parameters are 1.99830967071 8.00230163193 4.96269049942\n",
      "Iteration 400 - loss is 9.59850144435 - parameters are 2.00189653403 8.00827482285 4.96306630323\n",
      "Iteration 500 - loss is 8.73355229069 - parameters are 1.99347042222 7.99741349247 4.96195081444\n",
      "Iteration 600 - loss is 7.99411432542 - parameters are 2.00468650763 8.00701661691 4.9632770658\n",
      "Iteration 700 - loss is 9.21491502855 - parameters are 2.0031318187 8.00515897197 4.96292964995\n",
      "Iteration 800 - loss is 7.15700227121 - parameters are 2.00429899774 8.01033927096 4.96333318581\n",
      "Iteration 900 - loss is 8.51050020605 - parameters are 2.00276783909 8.0062271358 4.96286881853\n",
      "Iteration 1000 - loss is 10.8908710762 - parameters are 2.00786128494 8.01068241088 4.96377978534\n",
      "Epoch 488\n",
      "Iteration 100 - loss is 8.5758102976 - parameters are 1.99793877329 8.00214211241 4.96266816276\n",
      "Iteration 200 - loss is 9.64878096665 - parameters are 2.00012487144 8.00203804162 4.96294483192\n",
      "Iteration 300 - loss is 7.78048359514 - parameters are 1.9983077155 8.00229953977 4.96272250877\n",
      "Iteration 400 - loss is 9.59857625937 - parameters are 2.00189445821 8.00827268155 4.96309825379\n",
      "Iteration 500 - loss is 8.73350121825 - parameters are 1.99346838665 7.99741138909 4.96198272998\n",
      "Iteration 600 - loss is 7.99412135478 - parameters are 2.00468433868 8.00701441585 4.96330891046\n",
      "Iteration 700 - loss is 9.21495106093 - parameters are 2.0031296558 8.00515677271 4.9629614491\n",
      "Iteration 800 - loss is 7.15701313203 - parameters are 2.0042968289 8.01033703653 4.96336492877\n",
      "Iteration 900 - loss is 8.51052252662 - parameters are 2.0027658035 8.00622499766 4.96290052631\n",
      "Iteration 1000 - loss is 10.8907811786 - parameters are 2.00785910816 8.01068009733 4.96381142187\n",
      "Epoch 489\n",
      "Iteration 100 - loss is 8.5757484099 - parameters are 1.99793692929 8.00214013883 4.96269978715\n",
      "Iteration 200 - loss is 9.64873173965 - parameters are 2.00012276695 8.00203581197 4.96297635967\n",
      "Iteration 300 - loss is 7.78052128443 - parameters are 1.99830579102 8.0022974805 4.9627540149\n",
      "Iteration 400 - loss is 9.59864991319 - parameters are 2.00189241503 8.00827057392 4.96312970205\n",
      "Iteration 500 - loss is 8.73345096138 - parameters are 1.99346638309 7.99740931878 4.96201414378\n",
      "Iteration 600 - loss is 7.9941282908 - parameters are 2.00468220383 8.00701224939 4.96334025449\n",
      "Iteration 700 - loss is 9.21498654118 - parameters are 2.0031275269 8.00515460802 4.96299274833\n",
      "Iteration 800 - loss is 7.15702383863 - parameters are 2.00429469415 8.01033483722 4.9633961727\n",
      "Iteration 900 - loss is 8.51054451214 - parameters are 2.00276379992 8.00622289313 4.9629317356\n",
      "Iteration 1000 - loss is 10.8906927098 - parameters are 2.0078569656 8.01067782015 4.96384256104\n",
      "Epoch 490\n",
      "Iteration 100 - loss is 8.57568751383 - parameters are 1.99793511429 8.00213819627 4.96273091437\n",
      "Iteration 200 - loss is 9.64868330673 - parameters are 2.00012069555 8.00203361737 4.96300739177\n",
      "Iteration 300 - loss is 7.7805583953 - parameters are 1.9983038968 8.00229545361 4.96278502571\n",
      "Iteration 400 - loss is 9.59872242361 - parameters are 2.00189040398 8.00826849942 4.9631606559\n",
      "Iteration 500 - loss is 8.73340150686 - parameters are 1.99346441103 7.99740728102 4.96204506373\n",
      "Iteration 600 - loss is 7.99413513441 - parameters are 2.00468010254 8.00701011699 4.96337110575\n",
      "Iteration 700 - loss is 9.21502147755 - parameters are 2.00312543147 8.00515247737 4.9630235555\n",
      "Iteration 800 - loss is 7.15703439294 - parameters are 2.00429259297 8.01033267249 4.96342692543\n",
      "Iteration 900 - loss is 8.51056616739 - parameters are 2.00276182783 8.00622082168 4.96296245425\n",
      "Iteration 1000 - loss is 10.8906056468 - parameters are 2.00785485672 8.01067557877 4.96387321067\n",
      "Epoch 491\n",
      "Iteration 100 - loss is 8.57562759322 - parameters are 1.99793332783 8.00213628425 4.96276155223\n",
      "Iteration 200 - loss is 9.64863565477 - parameters are 2.00011865671 8.00203145728 4.96303793602\n",
      "Iteration 300 - loss is 7.78059493642 - parameters are 1.99830203236 8.00229345858 4.962815549\n",
      "Iteration 400 - loss is 9.59879380816 - parameters are 2.00188842454 8.00826645753 4.96319112313\n",
      "Iteration 500 - loss is 8.7333528417 - parameters are 1.99346246997 7.9974052753 4.96207549757\n",
      "Iteration 600 - loss is 7.99414188656 - parameters are 2.00467803429 8.00700801812 4.963401472\n",
      "Iteration 700 - loss is 9.21505587813 - parameters are 2.00312336899 8.00515038021 4.96305387835\n",
      "Iteration 800 - loss is 7.15704479685 - parameters are 2.00429052482 8.01033054179 4.9634571947\n",
      "Iteration 900 - loss is 8.51058749708 - parameters are 2.00275988675 8.00621878281 4.96299268997\n",
      "Iteration 1000 - loss is 10.890519967 - parameters are 2.007852781 8.01067337262 4.96390337845\n",
      "Epoch 492\n",
      "Iteration 100 - loss is 8.57556863216 - parameters are 1.99793156945 8.00213440229 4.96279170843\n",
      "Iteration 200 - loss is 9.64858877087 - parameters are 2.00011664993 8.00202933114 4.96306800007\n",
      "Iteration 300 - loss is 7.78063091631 - parameters are 1.99830019724 8.00229149492 4.96284559243\n",
      "Iteration 400 - loss is 9.59886408409 - parameters are 2.00188647622 8.00826444775 4.96322111138\n",
      "Iteration 500 - loss is 8.73330495312 - parameters are 1.99346055943 7.9974033011 4.96210545296\n",
      "Iteration 600 - loss is 7.99414854817 - parameters are 2.00467599856 8.00700595224 4.96343136086\n",
      "Iteration 700 - loss is 9.21508975095 - parameters are 2.00312133893 8.00514831602 4.96308372449\n",
      "Iteration 800 - loss is 7.15705505223 - parameters are 2.00428848918 8.01032844458 4.96348698811\n",
      "Iteration 900 - loss is 8.51060850586 - parameters are 2.00275797619 8.00621677598 4.96302245035\n",
      "Iteration 1000 - loss is 10.8904356483 - parameters are 2.00785073791 8.01067120116 4.96393307197\n",
      "Epoch 493\n",
      "Iteration 100 - loss is 8.57551061503 - parameters are 1.99792983872 8.00213254992 4.96282139055\n",
      "Iteration 200 - loss is 9.64854264238 - parameters are 2.00011467469 8.00202723843 4.96309759149\n",
      "Iteration 300 - loss is 7.78066634338 - parameters are 1.99829839096 8.00228956212 4.96287516355\n",
      "Iteration 400 - loss is 9.59893326842 - parameters are 2.00188455854 8.00826246956 4.96325062819\n",
      "Iteration 500 - loss is 8.73325782855 - parameters are 1.99345867893 7.99740135794 4.96213493743\n",
      "Iteration 600 - loss is 7.99415512018 - parameters are 2.00467399483 8.00700391884 4.96346077984\n",
      "Iteration 700 - loss is 9.21512310389 - parameters are 2.00311934079 8.00514628428 4.96311310142\n",
      "Iteration 800 - loss is 7.15706516095 - parameters are 2.00428648556 8.01032638035 4.96351631313\n",
      "Iteration 900 - loss is 8.51062919834 - parameters are 2.00275609567 8.00621480071 4.96305174287\n",
      "Iteration 1000 - loss is 10.8903526689 - parameters are 2.00784872695 8.01066906383 4.96396229867\n",
      "Epoch 494\n",
      "Iteration 100 - loss is 8.57545352646 - parameters are 1.99792813519 8.00213072667 4.96285060603\n",
      "Iteration 200 - loss is 9.64849725684 - parameters are 2.00011273051 8.00202517862 4.9631267177\n",
      "Iteration 300 - loss is 7.78070122593 - parameters are 1.99829661309 8.00228765971 4.96290426978\n",
      "Iteration 400 - loss is 9.59900137788 - parameters are 2.001882671 8.00826052246 4.96327968096\n",
      "Iteration 500 - loss is 8.73321145562 - parameters are 1.99345682799 7.99739944533 4.96216395837\n",
      "Iteration 600 - loss is 7.99416160353 - parameters are 2.0046720226 8.0070019174 4.96348973632\n",
      "Iteration 700 - loss is 9.21515594472 - parameters are 2.00311737406 8.00514428448 4.96314201652\n",
      "Iteration 800 - loss is 7.15707512486 - parameters are 2.00428451343 8.01032434857 4.96354517714\n",
      "Iteration 900 - loss is 8.51064957904 - parameters are 2.00275424471 8.00621285649 4.96308057488\n",
      "Iteration 1000 - loss is 10.8902710071 - parameters are 2.0078467476 8.01066696011 4.9639910659\n",
      "Epoch 495\n",
      "Iteration 100 - loss is 8.57539735132 - parameters are 1.99792645846 8.00212893208 4.96287936222\n",
      "Iteration 200 - loss is 9.64845260202 - parameters are 2.0001108169 8.00202315119 4.96315538602\n",
      "Iteration 300 - loss is 7.78073557212 - parameters are 1.99829486317 8.00228578721 4.96293291844\n",
      "Iteration 400 - loss is 9.59906842899 - parameters are 2.00188081314 8.00825860598 4.96330827699\n",
      "Iteration 500 - loss is 8.73316582219 - parameters are 1.99345500616 7.99739756279 4.96219252307\n",
      "Iteration 600 - loss is 7.99416799915 - parameters are 2.00467008138 8.00699994743 4.96351823758\n",
      "Iteration 700 - loss is 9.21518828113 - parameters are 2.00311543826 8.00514231612 4.96317047704\n",
      "Iteration 800 - loss is 7.15708494581 - parameters are 2.0042825723 8.01032234873 4.96357358737\n",
      "Iteration 900 - loss is 8.51066965245 - parameters are 2.00275242285 8.00621094283 4.96310895362\n",
      "Iteration 1000 - loss is 10.890190642 - parameters are 2.00784479937 8.01066488946 4.96401938088\n",
      "Epoch 496\n",
      "Iteration 100 - loss is 8.57534207476 - parameters are 1.99792480808 8.00212716571 4.96290766633\n",
      "Iteration 200 - loss is 9.6484086659 - parameters are 2.00010893337 8.00202115563 4.96318360364\n",
      "Iteration 300 - loss is 7.78076939002 - parameters are 1.99829314076 8.00228394415 4.9629611167\n",
      "Iteration 400 - loss is 9.59913443799 - parameters are 2.00187898449 8.00825671963 4.96333642346\n",
      "Iteration 500 - loss is 8.7331209163 - parameters are 1.99345321296 7.99739570985 4.9622206387\n",
      "Iteration 600 - loss is 7.99417430799 - parameters are 2.00466817068 8.00699800843 4.96354629077\n",
      "Iteration 700 - loss is 9.21522012066 - parameters are 2.00311353289 8.00514037871 4.96319849013\n",
      "Iteration 800 - loss is 7.15709462561 - parameters are 2.0042806617 8.01032038033 4.96360155097\n",
      "Iteration 900 - loss is 8.51068942298 - parameters are 2.00275062964 8.00620905926 4.96313688622\n",
      "Iteration 1000 - loss is 10.8901115526 - parameters are 2.00784288177 8.01066285136 4.96404725072\n",
      "Epoch 497\n",
      "Iteration 100 - loss is 8.57528768218 - parameters are 1.99792318365 8.0021254271 4.96293552547\n",
      "Iteration 200 - loss is 9.64836543664 - parameters are 2.00010707946 8.00201919145 4.96321137766\n",
      "Iteration 300 - loss is 7.78080268757 - parameters are 1.99829144543 8.00228213006 4.96298887167\n",
      "Iteration 400 - loss is 9.5991994209 - parameters are 2.00187718459 8.00825486293 4.96336412745\n",
      "Iteration 500 - loss is 8.7330767262 - parameters are 1.99345144796 7.99739388603 4.96224831234\n",
      "Iteration 600 - loss is 7.99418053097 - parameters are 2.00466629002 8.00699609991 4.96357390293\n",
      "Iteration 700 - loss is 9.21525147078 - parameters are 2.00311165747 8.00513847175 4.96322606284\n",
      "Iteration 800 - loss is 7.15710416607 - parameters are 2.00427878113 8.01031844287 4.96362907495\n",
      "Iteration 900 - loss is 8.51070889502 - parameters are 2.00274886462 8.0062072053 4.9631643797\n",
      "Iteration 1000 - loss is 10.8900337187 - parameters are 2.00784099432 8.0106608453 4.96407468243\n",
      "Epoch 498\n",
      "Iteration 100 - loss is 8.5752341592 - parameters are 1.99792158476 8.00212371583 4.96296294664\n",
      "Iteration 200 - loss is 9.64832290265 - parameters are 2.00010525469 8.00201725814 4.96323871504\n",
      "Iteration 300 - loss is 7.7808354726 - parameters are 1.99828977675 8.00228034449 4.9630161903\n",
      "Iteration 400 - loss is 9.59926339349 - parameters are 2.00187541298 8.00825303542 4.9633913959\n",
      "Iteration 500 - loss is 8.73303324032 - parameters are 1.99344971071 7.99739209089 4.96227555091\n",
      "Iteration 600 - loss is 7.99418666904 - parameters are 2.00466443893 8.00699422139 4.96360108101\n",
      "Iteration 700 - loss is 9.21528233883 - parameters are 2.00310981155 8.00513659478 4.96325320207\n",
      "Iteration 800 - loss is 7.15711356897 - parameters are 2.00427693013 8.01031653587 4.96365616623\n",
      "Iteration 900 - loss is 8.51072807285 - parameters are 2.00274712735 8.00620538048 4.96319144095\n",
      "Iteration 1000 - loss is 10.8899571199 - parameters are 2.00783913654 8.01065887078 4.96410168288\n",
      "Epoch 499\n",
      "Iteration 100 - loss is 8.5751814917 - parameters are 1.997920011 8.00212203146 4.96298993673\n",
      "Iteration 200 - loss is 9.64828105248 - parameters are 2.00010345861 8.00201535522 4.96326562265\n",
      "Iteration 300 - loss is 7.78086775282 - parameters are 1.99828813431 8.00227858699 4.96304307946\n",
      "Iteration 400 - loss is 9.59932637128 - parameters are 2.00187366923 8.00825123664 4.96341823567\n",
      "Iteration 500 - loss is 8.73299044729 - parameters are 1.99344800077 7.99739032397 4.96230236127\n",
      "Iteration 600 - loss is 7.99419272311 - parameters are 2.00466261693 8.00699237241 4.96362783183\n",
      "Iteration 700 - loss is 9.21531273206 - parameters are 2.00310799464 8.00513474731 4.96327991466\n",
      "Iteration 800 - loss is 7.1571228361 - parameters are 2.00427510823 8.01031465885 4.96368283161\n",
      "Iteration 900 - loss is 8.51074696075 - parameters are 2.00274541739 8.00620358436 4.96321807678\n",
      "Iteration 1000 - loss is 10.8898817367 - parameters are 2.00783730797 8.0106569273 4.96412825886\n",
      "Epoch 500\n",
      "Iteration 100 - loss is 8.5751296658 - parameters are 1.99791846199 8.00212037357 4.96301650251\n",
      "Iteration 200 - loss is 9.64823987494 - parameters are 2.00010169077 8.00201348222 4.96329210725\n",
      "Iteration 300 - loss is 7.78089953584 - parameters are 1.99828651769 8.00227685712 4.96306954589\n",
      "Iteration 400 - loss is 9.59938836958 - parameters are 2.0018719529 8.00824946614 4.9634446535\n",
      "Iteration 500 - loss is 8.73294833594 - parameters are 1.99344631771 7.99738858482 4.96232875015\n",
      "Iteration 600 - loss is 7.99419869413 - parameters are 2.00466082359 8.00699055249 4.96365416209\n",
      "Iteration 700 - loss is 9.2153426576 - parameters are 2.00310620629 8.00513292888 4.96330620729\n",
      "Iteration 800 - loss is 7.15713196921 - parameters are 2.00427331498 8.01031281134 4.96370907779\n",
      "Iteration 900 - loss is 8.5107655629 - parameters are 2.00274373431 8.00620181647 4.96324429386\n",
      "Iteration 1000 - loss is 10.8898075495 - parameters are 2.00783550815 8.01065501437 4.96415441704\n"
     ]
    }
   ],
   "source": [
    "p_gradient = [0, 0, 0]\n",
    "loss = 0\n",
    "\n",
    "for epoch_n in range(n_epochs):\n",
    "    print(\"Epoch\", epoch_n+1)\n",
    "    for iteration_n, (x1, x2, y) in enumerate(zip(x1_data, x2_data, y_data)):\n",
    "        # calculate output using model\n",
    "        y_predicted = p[0] * x1 + p[1] * (x2 + p[2])\n",
    "        # calculate loss\n",
    "        loss += (y_predicted - y)**2\n",
    "        # find gradients\n",
    "        p_gradient[0] += 2*(y_predicted - y) * x1\n",
    "        p_gradient[1] += 2*(y_predicted - y) * (x2 + p[2])\n",
    "        p_gradient[2] += 2*(y_predicted - y) * p[1]\n",
    "        # update parameters\n",
    "        if (iteration_n+1)%batch_size == 0:\n",
    "            p[0] -= learning_rate * p_gradient[0] / batch_size\n",
    "            p[1] -= learning_rate * p_gradient[1] / batch_size\n",
    "            p[2] -= learning_rate * p_gradient[2] / batch_size\n",
    "            # print to screen\n",
    "            print(\"Iteration\", iteration_n+1, \"- loss is\", loss / batch_size, \"- parameters are\", p[0], p[1], p[2])\n",
    "            p_gradient = [0, 0, 0]\n",
    "            loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
