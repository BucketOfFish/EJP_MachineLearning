{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generative adversarial network (GAN) is composed of a generator and classifier trained against each other. A generator is essentially a normal network run in reverse. Instead of determining the classification of a sample, it generates new samples of a given class. The generator and classifier are trained together, so that the generator produces new samples and the classifier tries to determine if each sample is \"authentic\" or generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with MNIST data again. Here we load the data and use it to initialize data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, sampler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "data = h5.File(\"../Lecture_07/Files/mnist.h5\")\n",
    "X_train = data['train']['inputs'][()].astype(np.float32)/255\n",
    "X_test = data['test']['inputs'][()].astype(np.float32)/255\n",
    "y_train = data['train']['targets'][()].astype(np.long)\n",
    "y_test = data['test']['targets'][()].astype(np.long)\n",
    "\n",
    "X_train = np.array([i.reshape(1, 28, 28) for i in X_train])\n",
    "X_test = np.array([i.reshape(1, 28, 28) for i in X_test])\n",
    "train_set = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_set = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(dataset=train_set, sampler=sampler.RandomSampler(train_set), batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset=test_set, sampler=sampler.RandomSampler(test_set), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a generator net to create new samples, and a discriminator net to tell samples apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Conv2d(1, 32, 4, 2, 1, bias=False)) # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "        #self.layers.append(nn.BatchNorm2d(32))\n",
    "        self.layers.append(nn.LeakyReLU(0.2))\n",
    "        self.layers.append(nn.Conv2d(32, 64, 4, 2, 1, bias=False))\n",
    "        self.layers.append(nn.BatchNorm2d(64))\n",
    "        self.layers.append(nn.LeakyReLU(0.2))\n",
    "        self.layers.append(nn.Conv2d(64, 1, 7, 1, 0, bias=False))\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = F.sigmoid(x.view(x.size(0), -1))\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.ConvTranspose2d(1, 64, 7, 1, 0, bias=False)) # in_channels, out_channels, kernel_size, stride=1, padding=0 \n",
    "        self.layers.append(nn.BatchNorm2d(64))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False))\n",
    "        self.layers.append(nn.BatchNorm2d(32))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.ConvTranspose2d(32, 1, 4, 2, 1, bias=False))\n",
    "        self.layers.append(nn.Tanh())\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train, and generate a set of images at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/25],[000/1200], errD: 0.0000, D(x): 0.4932, errG: 0.0000, D(G(z)): 0.7336\n",
      "[01/25],[100/1200], errD: 0.0000, D(x): 0.4937, errG: 0.0000, D(G(z)): 0.5439\n",
      "[01/25],[200/1200], errD: 0.0000, D(x): 0.5115, errG: 0.0000, D(G(z)): 0.5230\n",
      "[01/25],[300/1200], errD: 0.0000, D(x): 0.5199, errG: 0.0000, D(G(z)): 0.5073\n",
      "[01/25],[400/1200], errD: 0.0000, D(x): 0.5271, errG: 0.0000, D(G(z)): 0.5008\n",
      "[01/25],[500/1200], errD: 0.0000, D(x): 0.5244, errG: 0.0000, D(G(z)): 0.4960\n",
      "[01/25],[600/1200], errD: 0.0000, D(x): 0.5318, errG: 0.0000, D(G(z)): 0.4754\n",
      "[01/25],[700/1200], errD: 0.0000, D(x): 0.5638, errG: 0.0000, D(G(z)): 0.4822\n",
      "[01/25],[800/1200], errD: 0.0000, D(x): 0.5670, errG: 0.0000, D(G(z)): 0.4450\n",
      "[01/25],[900/1200], errD: 0.0000, D(x): 0.5489, errG: 0.0000, D(G(z)): 0.4484\n",
      "[01/25],[1000/1200], errD: 0.0000, D(x): 0.5627, errG: 0.0000, D(G(z)): 0.4297\n",
      "[01/25],[1100/1200], errD: 0.0000, D(x): 0.6154, errG: 0.0000, D(G(z)): 0.3880\n",
      "[02/25],[000/1200], errD: 0.0000, D(x): 0.5301, errG: 0.0000, D(G(z)): 0.3886\n",
      "[02/25],[100/1200], errD: 0.0000, D(x): 0.6046, errG: 0.0000, D(G(z)): 0.4713\n",
      "[02/25],[200/1200], errD: 0.0000, D(x): 0.7251, errG: 0.0000, D(G(z)): 0.2893\n",
      "[02/25],[300/1200], errD: 0.0000, D(x): 0.6902, errG: 0.0000, D(G(z)): 0.2894\n",
      "[02/25],[400/1200], errD: 0.0000, D(x): 0.5704, errG: 0.0000, D(G(z)): 0.3271\n",
      "[02/25],[500/1200], errD: 0.0000, D(x): 0.6169, errG: 0.0000, D(G(z)): 0.3132\n",
      "[02/25],[600/1200], errD: 0.0000, D(x): 0.5591, errG: 0.0000, D(G(z)): 0.3494\n",
      "[02/25],[700/1200], errD: 0.0000, D(x): 0.6369, errG: 0.0000, D(G(z)): 0.3880\n",
      "[02/25],[800/1200], errD: 0.0000, D(x): 0.6685, errG: 0.0000, D(G(z)): 0.3560\n",
      "[02/25],[900/1200], errD: 0.0000, D(x): 0.6131, errG: 0.0000, D(G(z)): 0.3596\n",
      "[02/25],[1000/1200], errD: 0.0000, D(x): 0.6324, errG: 0.0000, D(G(z)): 0.4658\n",
      "[02/25],[1100/1200], errD: 0.0000, D(x): 0.5035, errG: 0.0000, D(G(z)): 0.4145\n",
      "[03/25],[000/1200], errD: 0.0000, D(x): 0.5317, errG: 0.0000, D(G(z)): 0.4143\n",
      "[03/25],[100/1200], errD: 0.0000, D(x): 0.6201, errG: 0.0000, D(G(z)): 0.4310\n",
      "[03/25],[200/1200], errD: 0.0000, D(x): 0.6230, errG: 0.0000, D(G(z)): 0.4770\n",
      "[03/25],[300/1200], errD: 0.0000, D(x): 0.6055, errG: 0.0000, D(G(z)): 0.3626\n",
      "[03/25],[400/1200], errD: 0.0000, D(x): 0.6480, errG: 0.0000, D(G(z)): 0.3374\n",
      "[03/25],[500/1200], errD: 0.0000, D(x): 0.5180, errG: 0.0000, D(G(z)): 0.3953\n",
      "[03/25],[600/1200], errD: 0.0000, D(x): 0.6672, errG: 0.0000, D(G(z)): 0.4083\n",
      "[03/25],[700/1200], errD: 0.0000, D(x): 0.6721, errG: 0.0000, D(G(z)): 0.4826\n",
      "[03/25],[800/1200], errD: 0.0000, D(x): 0.5758, errG: 0.0000, D(G(z)): 0.4312\n",
      "[03/25],[900/1200], errD: 0.0000, D(x): 0.5469, errG: 0.0000, D(G(z)): 0.5647\n",
      "[03/25],[1000/1200], errD: 0.0000, D(x): 0.6199, errG: 0.0000, D(G(z)): 0.4658\n",
      "[03/25],[1100/1200], errD: 0.0000, D(x): 0.4818, errG: 0.0000, D(G(z)): 0.4225\n",
      "[04/25],[000/1200], errD: 0.0000, D(x): 0.6815, errG: 0.0000, D(G(z)): 0.5081\n",
      "[04/25],[100/1200], errD: 0.0000, D(x): 0.5089, errG: 0.0000, D(G(z)): 0.4455\n",
      "[04/25],[200/1200], errD: 0.0000, D(x): 0.4837, errG: 0.0000, D(G(z)): 0.5982\n",
      "[04/25],[300/1200], errD: 0.0000, D(x): 0.5678, errG: 0.0000, D(G(z)): 0.3946\n",
      "[04/25],[400/1200], errD: 0.0000, D(x): 0.5516, errG: 0.0000, D(G(z)): 0.3445\n",
      "[04/25],[500/1200], errD: 0.0000, D(x): 0.6186, errG: 0.0000, D(G(z)): 0.3860\n",
      "[04/25],[600/1200], errD: 0.0000, D(x): 0.4429, errG: 0.0000, D(G(z)): 0.4450\n",
      "[04/25],[700/1200], errD: 0.0000, D(x): 0.6239, errG: 0.0000, D(G(z)): 0.2920\n",
      "[04/25],[800/1200], errD: 0.0000, D(x): 0.5146, errG: 0.0000, D(G(z)): 0.4011\n",
      "[04/25],[900/1200], errD: 0.0000, D(x): 0.6184, errG: 0.0000, D(G(z)): 0.3942\n",
      "[04/25],[1000/1200], errD: 0.0000, D(x): 0.5856, errG: 0.0000, D(G(z)): 0.2628\n",
      "[04/25],[1100/1200], errD: 0.0000, D(x): 0.5444, errG: 0.0000, D(G(z)): 0.3909\n",
      "[05/25],[000/1200], errD: 0.0000, D(x): 0.6921, errG: 0.0000, D(G(z)): 0.4429\n",
      "[05/25],[100/1200], errD: 0.0000, D(x): 0.5223, errG: 0.0000, D(G(z)): 0.4413\n",
      "[05/25],[200/1200], errD: 0.0000, D(x): 0.6139, errG: 0.0000, D(G(z)): 0.4017\n",
      "[05/25],[300/1200], errD: 0.0000, D(x): 0.6065, errG: 0.0000, D(G(z)): 0.4045\n",
      "[05/25],[400/1200], errD: 0.0000, D(x): 0.6198, errG: 0.0000, D(G(z)): 0.4284\n",
      "[05/25],[500/1200], errD: 0.0000, D(x): 0.6636, errG: 0.0000, D(G(z)): 0.4196\n",
      "[05/25],[600/1200], errD: 0.0000, D(x): 0.7446, errG: 0.0000, D(G(z)): 0.4030\n",
      "[05/25],[700/1200], errD: 0.0000, D(x): 0.5487, errG: 0.0000, D(G(z)): 0.3700\n",
      "[05/25],[800/1200], errD: 0.0000, D(x): 0.5893, errG: 0.0000, D(G(z)): 0.3705\n",
      "[05/25],[900/1200], errD: 0.0000, D(x): 0.6695, errG: 0.0000, D(G(z)): 0.3038\n",
      "[05/25],[1000/1200], errD: 0.0000, D(x): 0.5589, errG: 0.0000, D(G(z)): 0.4622\n",
      "[05/25],[1100/1200], errD: 0.0000, D(x): 0.5195, errG: 0.0000, D(G(z)): 0.5262\n",
      "[06/25],[000/1200], errD: 0.0000, D(x): 0.5049, errG: 0.0000, D(G(z)): 0.3892\n",
      "[06/25],[100/1200], errD: 0.0000, D(x): 0.5412, errG: 0.0000, D(G(z)): 0.3040\n",
      "[06/25],[200/1200], errD: 0.0000, D(x): 0.6109, errG: 0.0000, D(G(z)): 0.3522\n",
      "[06/25],[300/1200], errD: 0.0000, D(x): 0.6255, errG: 0.0000, D(G(z)): 0.3804\n",
      "[06/25],[400/1200], errD: 0.0000, D(x): 0.6172, errG: 0.0000, D(G(z)): 0.3544\n",
      "[06/25],[500/1200], errD: 0.0000, D(x): 0.5346, errG: 0.0000, D(G(z)): 0.5557\n",
      "[06/25],[600/1200], errD: 0.0000, D(x): 0.6031, errG: 0.0000, D(G(z)): 0.4369\n",
      "[06/25],[700/1200], errD: 0.0000, D(x): 0.6704, errG: 0.0000, D(G(z)): 0.4061\n",
      "[06/25],[800/1200], errD: 0.0000, D(x): 0.5570, errG: 0.0000, D(G(z)): 0.4084\n",
      "[06/25],[900/1200], errD: 0.0000, D(x): 0.5860, errG: 0.0000, D(G(z)): 0.3719\n",
      "[06/25],[1000/1200], errD: 0.0000, D(x): 0.5517, errG: 0.0000, D(G(z)): 0.3275\n",
      "[06/25],[1100/1200], errD: 0.0000, D(x): 0.6741, errG: 0.0000, D(G(z)): 0.3774\n",
      "[07/25],[000/1200], errD: 0.0000, D(x): 0.5396, errG: 0.0000, D(G(z)): 0.3452\n",
      "[07/25],[100/1200], errD: 0.0000, D(x): 0.5646, errG: 0.0000, D(G(z)): 0.5947\n",
      "[07/25],[200/1200], errD: 0.0000, D(x): 0.6105, errG: 0.0000, D(G(z)): 0.4377\n",
      "[07/25],[300/1200], errD: 0.0000, D(x): 0.5871, errG: 0.0000, D(G(z)): 0.4506\n",
      "[07/25],[400/1200], errD: 0.0000, D(x): 0.6566, errG: 0.0000, D(G(z)): 0.4046\n",
      "[07/25],[500/1200], errD: 0.0000, D(x): 0.7227, errG: 0.0000, D(G(z)): 0.3549\n",
      "[07/25],[600/1200], errD: 0.0000, D(x): 0.5906, errG: 0.0000, D(G(z)): 0.4419\n",
      "[07/25],[700/1200], errD: 0.0000, D(x): 0.5871, errG: 0.0000, D(G(z)): 0.4893\n",
      "[07/25],[800/1200], errD: 0.0000, D(x): 0.5323, errG: 0.0000, D(G(z)): 0.4478\n",
      "[07/25],[900/1200], errD: 0.0000, D(x): 0.5339, errG: 0.0000, D(G(z)): 0.3652\n",
      "[07/25],[1000/1200], errD: 0.0000, D(x): 0.6839, errG: 0.0000, D(G(z)): 0.1892\n",
      "[07/25],[1100/1200], errD: 0.0000, D(x): 0.6133, errG: 0.0000, D(G(z)): 0.4539\n",
      "[08/25],[000/1200], errD: 0.0000, D(x): 0.6212, errG: 0.0000, D(G(z)): 0.3646\n",
      "[08/25],[100/1200], errD: 0.0000, D(x): 0.7695, errG: 0.0000, D(G(z)): 0.2831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9114a470c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattzhang/py3_kernel/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mattzhang/py3_kernel/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "\n",
    "truth_real = torch.Tensor(batch_size).fill_(1).float()\n",
    "truth_fake = torch.Tensor(batch_size).fill_(0).float()\n",
    "for epoch_n in range(n_epochs):\n",
    "    for batch_n, (x, _) in enumerate(train_loader):\n",
    "        # x is real samples, z is fake\n",
    "        noise = torch.randn(batch_size, 1, 1, 1).float()\n",
    "        z = generator(noise)\n",
    "        discriminator_real = discriminator(x)\n",
    "        discriminator_fake = discriminator(z)\n",
    "        # train discriminator\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        loss_discriminator = -torch.mean(torch.log(discriminator_real) + torch.log(1 - discriminator_fake))\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        # train generator\n",
    "        for _ in range(10):\n",
    "            noise = torch.randn(batch_size, 1, 1, 1).float()\n",
    "            z = generator(noise)\n",
    "            discriminator_fake = discriminator(z)\n",
    "            optimizer_generator.zero_grad()\n",
    "            loss_generator = -torch.mean(torch.log(discriminator_fake))\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "        if batch_n%100 == 0:\n",
    "            print('[{:02d}/{:02d}],[{:03d}/{:03d}], D(x): {:.4f}, D(G(z)): {:.4f}'.format(\n",
    "              epoch_n+1, n_epochs, batch_n, len(train_loader), discriminator_real.data.mean(dim=0)[0], discriminator_fake.data.mean(dim=0)[0]))\n",
    "\n",
    "    noise = torch.randn(batch_size, 1, 1, 1).float()\n",
    "    noise.requires_grad = False\n",
    "    z = generator(noise)\n",
    "    save_image(z.data, 'Figs/mnist-fake-{:02d}.png'.format(epoch_n+1),\n",
    "                   normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
